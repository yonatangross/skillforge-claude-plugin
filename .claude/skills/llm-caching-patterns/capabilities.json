{
  "$schema": "../../schemas/skill-capabilities.schema.json",
  "name": "llm-caching-patterns",
  "version": "1.3.0",
  "description": "Multi-level caching strategies for LLM applications - semantic caching (Redis), prompt caching (Claude native), cache hierarchies, local model considerations (Ollama), and cost optimization for 70-95% cost reduction",

  "capabilities": {
    "cache-hierarchy": {
      "keywords": ["cache hierarchy", "multi-level", "l1 l2 l3", "double caching", "cache architecture"],
      "solves": [
        "How do I design a multi-level cache system?",
        "What is double caching architecture?",
        "L1/L2/L3 cache hierarchy for LLMs",
        "Combine semantic and prompt caching"
      ],
      "reference_file": "SKILL.md#double-caching-architecture",
      "token_cost": 180
    },
    "semantic-cache": {
      "keywords": ["semantic cache", "redis", "redisvl", "vector similarity", "embedding cache"],
      "solves": [
        "How do I implement semantic caching?",
        "Redis semantic cache with embeddings",
        "Cache similar (not exact) queries",
        "Vector similarity search for caching"
      ],
      "reference_file": "SKILL.md#redis-semantic-cache-implementation",
      "token_cost": 200
    },
    "prompt-cache": {
      "keywords": ["prompt cache", "claude cache", "cache control", "cache breakpoint", "ephemeral"],
      "solves": [
        "How do I use Claude prompt caching?",
        "Set up cache breakpoints",
        "Cache system prompts and examples",
        "Reduce input token costs by 90%"
      ],
      "reference_file": "SKILL.md#prompt-caching-claude-native",
      "token_cost": 150
    },
    "similarity-threshold": {
      "keywords": ["threshold", "cosine similarity", "distance", "precision", "tuning"],
      "solves": [
        "What similarity threshold should I use?",
        "Tune cache similarity thresholds",
        "Balance precision vs recall",
        "Avoid false positive cache hits"
      ],
      "reference_file": "SKILL.md#similarity-threshold-tuning",
      "token_cost": 120
    },
    "cache-warming": {
      "keywords": ["warm cache", "preload", "golden dataset", "cache initialization"],
      "solves": [
        "How do I pre-populate the cache?",
        "Warm cache from historical data",
        "Use golden dataset for cache seeding",
        "Instant cache hit rates"
      ],
      "reference_file": "SKILL.md#cache-warming-strategy",
      "token_cost": 100
    },
    "cost-optimization": {
      "keywords": ["cost", "savings", "roi", "budget", "expense reduction", "70% savings"],
      "solves": [
        "How much can I save with caching?",
        "Calculate ROI for cache system",
        "70-95% cost reduction strategies",
        "Cost optimization patterns"
      ],
      "reference_file": "SKILL.md#cost-calculation",
      "token_cost": 130
    },
    "metadata-filtering": {
      "keywords": ["filter", "metadata", "tag", "agent type", "content type"],
      "solves": [
        "How do I filter cache by metadata?",
        "Improve cache precision with filters",
        "Agent-specific caching",
        "Content-type based filtering"
      ],
      "reference_file": "SKILL.md#metadata-filtering",
      "token_cost": 90
    },
    "quality-eviction": {
      "keywords": ["eviction", "quality score", "cache size", "ttl", "expiration"],
      "solves": [
        "How do I manage cache size?",
        "Quality-based cache eviction",
        "Keep high-quality responses",
        "TTL and expiration strategies"
      ],
      "reference_file": "SKILL.md#quality-based-eviction",
      "token_cost": 80
    },
    "adaptive-threshold": {
      "keywords": ["adaptive", "dynamic threshold", "auto-tune", "hit rate optimization"],
      "solves": [
        "How do I auto-tune similarity threshold?",
        "Dynamic threshold adjustment",
        "Optimize for target hit rate",
        "Adaptive cache configuration"
      ],
      "reference_file": "SKILL.md#dynamic-threshold-adjustment",
      "token_cost": 100
    },
    "reranking": {
      "keywords": ["rerank", "top-k", "llm rerank", "precision improvement"],
      "solves": [
        "How do I improve cache precision?",
        "LLM reranking for cache candidates",
        "Top-k candidate evaluation",
        "Two-stage retrieval"
      ],
      "reference_file": "SKILL.md#llm-reranking-optional",
      "token_cost": 110
    },
    "monitoring": {
      "keywords": ["metrics", "hit rate", "latency", "monitoring", "redisinsight"],
      "solves": [
        "How do I monitor cache performance?",
        "Track hit rates and latency",
        "RedisInsight dashboard setup",
        "Cache metrics and KPIs"
      ],
      "reference_file": "SKILL.md#monitoring-observability",
      "token_cost": 100
    },
    "local-model-caching": {
      "keywords": ["ollama", "local model", "ci caching", "free inference", "simplified cache"],
      "solves": [
        "Do I need caching with local models?",
        "Simplified caching for Ollama",
        "Cache strategy when LLM is free",
        "L1-only cache for local inference"
      ],
      "reference_file": "SKILL.md#local-model-considerations-ollama",
      "token_cost": 80
    }
  },

  "triggers": {
    "high_confidence": [
      "llm.*caching",
      "semantic.*cache",
      "redis.*cache",
      "cost.*optimization",
      "cache.*hierarchy"
    ],
    "medium_confidence": [
      "reduce.*cost",
      "cache.*llm",
      "prompt.*cache",
      "similar.*query",
      "ollama.*cache",
      "local.*model.*cache"
    ]
  },

  "integrates_with": [
    "ai-native-development",
    "langfuse-observability",
    "performance-optimization",
    "redis-patterns"
  ],

  "progressive_loading": {
    "tier_1_discovery": {
      "file": "capabilities.json",
      "tokens": 110,
      "use_when": "Initial task analysis - determine if skill is relevant"
    },
    "tier_2_overview": {
      "file": "SKILL.md",
      "tokens": 537,
      "use_when": "Skill confirmed relevant - need caching architecture and patterns"
    },
    "tier_3_specific": {
      "files": "SKILL.md#<section>",
      "tokens": "80-200 each",
      "use_when": "Need specific implementation (semantic cache, prompt cache, optimization, etc.)"
    }
  },

  "mcp_tools": {
    "documentation_lookup": {
      "tool": "context7",
      "library_ids": ["/redis/redis-py", "/anthropics/anthropic-sdk-python"],
      "use_when": "Need current Redis or Claude API patterns for caching"
    }
  }
}
