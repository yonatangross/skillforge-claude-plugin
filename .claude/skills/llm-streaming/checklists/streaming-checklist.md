# LLM Streaming Checklist

## Implementation

- [ ] Use async iterators
- [ ] Handle connection drops
- [ ] Implement timeout
- [ ] Support cancellation

## Frontend

- [ ] Display tokens as received
- [ ] Show typing indicator
- [ ] Handle reconnection
- [ ] Smooth text rendering

## Error Handling

- [ ] Detect stream errors
- [ ] Partial response recovery
- [ ] Graceful degradation
- [ ] Error logging

## Tool Calls

- [ ] Accumulate tool call chunks
- [ ] Execute after complete
- [ ] Handle multiple tools
- [ ] Resume stream after tools
