{
  "$schema": "../../schemas/skill-capabilities.schema.json",
  "name": "llm-testing",
  "version": "2.0.0",
  "description": "Testing patterns for LLM-based applications with DeepEval and RAGAS metrics",
  "capabilities": {
    "llm-response-mocking": {
      "keywords": [
        "mock LLM",
        "fake response",
        "stub LLM",
        "mock AI"
      ],
      "solves": [
        "Mock LLM responses in tests",
        "Create deterministic AI test fixtures",
        "Avoid live API calls in CI"
      ]
    },
    "async-timeout-testing": {
      "keywords": [
        "timeout",
        "async test",
        "wait for",
        "polling"
      ],
      "solves": [
        "Test async LLM operations",
        "Handle timeout scenarios",
        "Implement polling assertions"
      ]
    },
    "structured-output-validation": {
      "keywords": [
        "structured output",
        "JSON validation",
        "schema validation",
        "output format"
      ],
      "solves": [
        "Validate structured LLM output",
        "Test JSON schema compliance",
        "Assert output structure"
      ]
    },
    "deepeval-assertions": {
      "keywords": [
        "DeepEval",
        "assert_test",
        "LLMTestCase",
        "metric assertion"
      ],
      "solves": [
        "Use DeepEval for LLM assertions",
        "Implement metric-based tests",
        "Configure quality thresholds"
      ]
    },
    "golden-dataset-testing": {
      "keywords": [
        "golden dataset",
        "golden test",
        "reference output",
        "expected output"
      ],
      "solves": [
        "Test against golden datasets",
        "Compare with reference outputs",
        "Implement regression testing"
      ]
    },
    "vcr-recording": {
      "keywords": [
        "VCR",
        "cassette",
        "record",
        "replay",
        "HTTP recording"
      ],
      "solves": [
        "Record LLM API responses",
        "Replay recordings in tests",
        "Create deterministic test suites"
      ]
    }
  },
  "triggers": {
    "high_confidence": [
      "LLM.*test",
      "test.*AI",
      "DeepEval",
      "mock.*LLM"
    ],
    "medium_confidence": [
      "AI test",
      "mock LLM",
      "structured output",
      "quality gate"
    ]
  },
  "integrates_with": [
    "vcr-http-recording",
    "llm-evaluation",
    "unit-testing"
  ]
}
