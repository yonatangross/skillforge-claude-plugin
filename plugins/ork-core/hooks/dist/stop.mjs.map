{
  "version": 3,
  "sources": ["../src/types.ts", "../src/lib/common.ts", "../src/lib/calibration-engine.ts", "../src/stop/auto-remember-continuity.ts", "../src/stop/auto-save-context.ts", "../src/stop/cleanup-instance.ts", "../src/stop/context-compressor.ts", "../src/stop/full-test-suite.ts", "../src/stop/issue-work-summary.ts", "../src/stop/mem0-pre-compaction-sync.ts", "../src/stop/multi-instance-cleanup.ts", "../src/stop/security-scan-aggregator.ts", "../src/stop/session-patterns.ts", "../src/lib/session-tracker.ts", "../src/lib/user-identity.ts", "../src/lib/tool-categories.ts", "../src/stop/task-completion-check.ts", "../src/lib/task-integration.ts", "../src/lib/orchestration-state.ts", "../src/stop/calibration-persist.ts", "../src/lib/user-profile.ts", "../src/lib/decision-flow-tracker.ts", "../src/stop/session-profile-aggregator.ts", "../src/stop/session-end-tracking.ts", "../src/stop/graph-queue-sync.ts", "../src/stop/workflow-preference-learner.ts", "../src/stop/mem0-queue-sync.ts", "../src/lib/technology-registry.ts", "../src/lib/memory-writer.ts", "../src/stop/unified-dispatcher.ts", "../src/entries/stop.ts"],
  "sourcesContent": ["/**\n * TypeScript type definitions for Claude Code hooks\n * CC 2.1.9 compliant with additionalContext support\n */\n\n/**\n * Hook events supported by Claude Code\n */\nexport type HookEvent =\n  | 'PreToolUse'\n  | 'PostToolUse'\n  | 'PermissionRequest'\n  | 'UserPromptSubmit'\n  | 'SessionStart'\n  | 'SessionEnd'\n  | 'Stop'\n  | 'SubagentStart'\n  | 'SubagentStop'\n  | 'Setup'\n  | 'Notification';\n\n/**\n * Hook input envelope from Claude Code (sent via stdin as JSON)\n */\nexport interface HookInput {\n  /** The hook event type */\n  hook_event?: HookEvent;\n  /** The tool being invoked */\n  tool_name: string;\n  /** Session ID (CC 2.1.9 guarantees availability) */\n  session_id: string;\n  /** Tool-specific input parameters */\n  tool_input: ToolInput;\n  /** Tool output (PostToolUse only) */\n  tool_output?: unknown;\n  /** Tool error message if any */\n  tool_error?: string;\n  /** Tool exit code */\n  exit_code?: number;\n  /** User prompt (UserPromptSubmit only) */\n  prompt?: string;\n  /** Project directory */\n  project_dir?: string;\n\n  // SubagentStart/SubagentStop specific fields\n  /** Agent type for subagent hooks */\n  subagent_type?: string;\n  /** Agent type (alternative field name) */\n  agent_type?: string;\n  /** Agent ID */\n  agent_id?: string;\n  /** Agent output (SubagentStop) */\n  agent_output?: string;\n  /** Output (alternative field name) */\n  output?: string;\n  /** Error from subagent */\n  error?: string;\n  /** Duration in milliseconds */\n  duration_ms?: number;\n  /** Tool result \u2014 string from most hooks, object from Skill PostToolUse */\n  tool_result?: string | { is_error?: boolean; content?: string };\n\n  // Notification specific fields\n  /** Notification message */\n  message?: string;\n  /** Notification type */\n  notification_type?: string;\n}\n\n/**\n * Tool input types - union of all tool inputs\n */\nexport interface ToolInput {\n  /** Bash command (Bash tool) */\n  command?: string;\n  /** Timeout in ms (Bash tool) */\n  timeout?: number;\n  /** File path (Write/Edit/Read tools) */\n  file_path?: string;\n  /** File content (Write tool) */\n  content?: string;\n  /** Old text to replace (Edit tool) */\n  old_string?: string;\n  /** New text (Edit tool) */\n  new_string?: string;\n  /** Pattern (Glob/Grep tools) */\n  pattern?: string;\n  /** Allow additional properties */\n  [key: string]: unknown;\n}\n\n/**\n * Hook-specific output for CC 2.1.9\n */\nexport interface HookSpecificOutput {\n  /** Hook event name for context */\n  hookEventName?: 'PreToolUse' | 'PostToolUse' | 'PermissionRequest' | 'UserPromptSubmit';\n  /** Permission decision (PermissionRequest hooks) */\n  permissionDecision?: 'allow' | 'deny';\n  /** Reason for permission decision */\n  permissionDecisionReason?: string;\n  /** Additional context injected before tool execution (CC 2.1.9) */\n  additionalContext?: string;\n}\n\n/**\n * Hook result - output JSON to stdout\n * CC 2.1.7+ compliant\n */\nexport interface HookResult {\n  /** Whether to continue execution */\n  continue: boolean;\n  /** Suppress hook output from user */\n  suppressOutput?: boolean;\n  /** System message shown to user */\n  systemMessage?: string;\n  /** Reason for stopping (when continue is false) */\n  stopReason?: string;\n  /** Hook-specific output fields */\n  hookSpecificOutput?: HookSpecificOutput;\n}\n\n/**\n * Hook function signature\n */\nexport type HookFn = (input: HookInput) => Promise<HookResult> | HookResult;\n\n/**\n * Hook metadata for auto-discovery and governance\n * Co-export alongside hook functions for single-source-of-truth registration\n */\nexport interface HookMeta {\n  /** Full hook name path (e.g., 'pretool/bash/dangerous-command-blocker') */\n  name: string;\n  /** Human-readable description */\n  description: string;\n  /** Hook event type */\n  event: HookEvent;\n  /** Tool matcher patterns for hooks.json (e.g., 'Bash', 'Write|Edit') */\n  matchers?: string[];\n  /** Run asynchronously (non-blocking) */\n  async?: boolean;\n  /** Only run once per session */\n  once?: boolean;\n  /** Timeout in seconds (async hooks only) */\n  timeout?: number;\n  /** Risk category for prioritization */\n  tier?: 'security-critical' | 'data-loss' | 'quality-gate' | 'standard';\n}\n\n/**\n * Hook overrides configuration for per-project toggle/customization\n * Stored at .claude/hook-overrides.json (gitignored)\n */\nexport interface HookOverrides {\n  /** Hook names to disable entirely */\n  disabled?: string[];\n  /** Per-hook timeout overrides (seconds) */\n  timeouts?: Record<string, number>;\n}\n\n/**\n * Hook registration entry\n */\nexport interface HookRegistration {\n  /** Hook name (e.g., 'permission/auto-approve-readonly') */\n  name: string;\n  /** Hook event type */\n  event: HookEvent;\n  /** Tool matcher (string pattern or regex) */\n  matcher?: string | RegExp;\n  /** Hook implementation function */\n  fn: HookFn;\n}\n\n/**\n * Bash tool input (type guard helper)\n */\nexport interface BashToolInput extends ToolInput {\n  command: string;\n  timeout?: number;\n}\n\n/**\n * Write tool input (type guard helper)\n */\nexport interface WriteToolInput extends ToolInput {\n  file_path: string;\n  content: string;\n}\n\n/**\n * Edit tool input (type guard helper)\n */\nexport interface EditToolInput extends ToolInput {\n  file_path: string;\n  old_string: string;\n  new_string: string;\n}\n\n/**\n * Read tool input (type guard helper)\n */\nexport interface ReadToolInput extends ToolInput {\n  file_path: string;\n  offset?: number;\n  limit?: number;\n}\n\n/**\n * Type guards for tool inputs\n */\nexport function isBashInput(input: ToolInput): input is BashToolInput {\n  return typeof input.command === 'string';\n}\n\nexport function isWriteInput(input: ToolInput): input is WriteToolInput {\n  return typeof input.file_path === 'string' && typeof input.content === 'string';\n}\n\nexport function isEditInput(input: ToolInput): input is EditToolInput {\n  return (\n    typeof input.file_path === 'string' &&\n    typeof input.old_string === 'string' &&\n    typeof input.new_string === 'string'\n  );\n}\n\nexport function isReadInput(input: ToolInput): input is ReadToolInput {\n  return typeof input.file_path === 'string' && input.content === undefined;\n}\n", "/**\n * Common utilities for TypeScript hooks\n * Ported from hooks/_lib/common.sh\n */\n\nimport { appendFileSync, existsSync, statSync, renameSync, mkdirSync, readSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookResult, HookInput } from '../types.js';\n\n// -----------------------------------------------------------------------------\n// Environment and Paths\n// All functions read env vars dynamically to support testing\n// -----------------------------------------------------------------------------\n\n/**\n * Get the log directory path\n */\nexport function getLogDir(): string {\n  if (process.env.CLAUDE_PLUGIN_ROOT) {\n    return `${process.env.HOME || process.env.USERPROFILE || '/tmp'}/.claude/logs/ork`;\n  }\n  return `${getProjectDir()}/.claude/logs`;\n}\n\n/**\n * Get the project directory\n * Read dynamically to support testing\n */\nexport function getProjectDir(): string {\n  return process.env.CLAUDE_PROJECT_DIR || '.';\n}\n\n/**\n * Get the plugin root directory\n * Read dynamically to support testing\n */\nexport function getPluginRoot(): string {\n  return process.env.CLAUDE_PLUGIN_ROOT || process.env.CLAUDE_PROJECT_DIR || '.';\n}\n\n/**\n * Get the session ID\n * CC 2.1.9+ should guarantee CLAUDE_SESSION_ID availability, but we add\n * a defensive fallback to prevent hook crashes during edge cases.\n * Read dynamically to support testing.\n */\nexport function getSessionId(): string {\n  return process.env.CLAUDE_SESSION_ID || `fallback-${process.pid}-${Date.now()}`;\n}\n\n/**\n * Get cached git branch (set at session start or first call)\n * Caches result in process.env to avoid repeated execSync calls\n */\nexport function getCachedBranch(projectDir?: string): string {\n  if (process.env.ORCHESTKIT_BRANCH) {\n    return process.env.ORCHESTKIT_BRANCH;\n  }\n\n  try {\n    const branch = execSync('git branch --show-current', {\n      cwd: projectDir || getProjectDir(),\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    }).trim();\n    process.env.ORCHESTKIT_BRANCH = branch;\n    return branch;\n  } catch {\n    return 'unknown';\n  }\n}\n\n/**\n * Get log level (debug|info|warn|error, default: warn)\n */\nexport function getLogLevel(): string {\n  return process.env.ORCHESTKIT_LOG_LEVEL || 'warn';\n}\n\n/**\n * Check if should log at given level\n */\nexport function shouldLog(level: 'debug' | 'info' | 'warn' | 'error'): boolean {\n  const levels = ['debug', 'info', 'warn', 'error'];\n  return levels.indexOf(level) >= levels.indexOf(getLogLevel());\n}\n\n// -----------------------------------------------------------------------------\n// Output Helpers (CC 2.1.7+ compliant)\n// -----------------------------------------------------------------------------\n\n/**\n * Output silent success - hook completed without errors, no user-visible output\n */\nexport function outputSilentSuccess(): HookResult {\n  return { continue: true, suppressOutput: true };\n}\n\n/**\n * Output silent allow - permission hook approves silently\n */\nexport function outputSilentAllow(): HookResult {\n  return {\n    continue: true,\n    suppressOutput: true,\n    hookSpecificOutput: { permissionDecision: 'allow' },\n  };\n}\n\n/**\n * Output block - stops the operation with an error\n */\nexport function outputBlock(reason: string): HookResult {\n  return {\n    continue: false,\n    stopReason: reason,\n    hookSpecificOutput: {\n      permissionDecision: 'deny',\n      permissionDecisionReason: reason,\n    },\n  };\n}\n\n/**\n * Output with additionalContext - injects context before tool execution (CC 2.1.9)\n * For PostToolUse hooks (hookEventName optional)\n */\nexport function outputWithContext(ctx: string): HookResult {\n  return {\n    continue: true,\n    suppressOutput: true,\n    hookSpecificOutput: {\n      hookEventName: 'PostToolUse',\n      additionalContext: ctx,\n    },\n  };\n}\n\n/**\n * Output with additionalContext for UserPromptSubmit hooks (CC 2.1.9)\n * hookEventName is REQUIRED for UserPromptSubmit\n */\nexport function outputPromptContext(ctx: string): HookResult {\n  return {\n    continue: true,\n    suppressOutput: true,\n    hookSpecificOutput: {\n      hookEventName: 'UserPromptSubmit',\n      additionalContext: ctx,\n    },\n  };\n}\n\n/**\n * Output allow with additionalContext - permission hook approves with context (CC 2.1.9)\n */\nexport function outputAllowWithContext(ctx: string, systemMessage?: string): HookResult {\n  const result: HookResult = {\n    continue: true,\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      additionalContext: ctx,\n      permissionDecision: 'allow',\n    },\n  };\n\n  if (systemMessage) {\n    result.systemMessage = systemMessage;\n  } else {\n    result.suppressOutput = true;\n  }\n\n  return result;\n}\n\n/**\n * Output error message - only use when there's an actual problem\n */\nexport function outputError(message: string): HookResult {\n  return { continue: true, systemMessage: message };\n}\n\n/**\n * Output warning message - CC 2.1.7 compliant (no ANSI in JSON)\n */\nexport function outputWarning(message: string): HookResult {\n  return { continue: true, systemMessage: `\\u26a0 ${message}` };\n}\n\n/**\n * Output deny with feedback logging (CC 2.1.7)\n */\nexport function outputDeny(reason: string): HookResult {\n  return {\n    continue: false,\n    stopReason: reason,\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'deny',\n      permissionDecisionReason: reason,\n    },\n  };\n}\n\n// -----------------------------------------------------------------------------\n// Logging (with log level guard for performance)\n// -----------------------------------------------------------------------------\n\nconst LOG_ROTATION_MAX_SIZE = 200 * 1024; // 200KB\nconst PERMISSION_LOG_MAX_SIZE = 100 * 1024; // 100KB\n\n/**\n * Rotate log file if it exceeds size limit\n */\nfunction rotateLogFile(logFile: string, maxSize: number): void {\n  if (!existsSync(logFile)) return;\n\n  try {\n    const stats = statSync(logFile);\n    if (stats.size > maxSize) {\n      const rotated = `${logFile}.old.${Date.now()}`;\n      renameSync(logFile, rotated);\n    }\n  } catch {\n    // Ignore rotation errors\n  }\n}\n\n/**\n * Ensure directory exists\n */\nfunction ensureDir(dir: string): void {\n  if (!existsSync(dir)) {\n    mkdirSync(dir, { recursive: true });\n  }\n}\n\n/**\n * Log to hook log file with automatic rotation\n * Respects ORCHESTKIT_LOG_LEVEL (default: warn, skips debug logs in production)\n */\nexport function logHook(hookName: string, message: string, level: 'debug' | 'info' | 'warn' | 'error' = 'debug'): void {\n  // Skip if below log level threshold (big perf win - avoids I/O)\n  if (!shouldLog(level)) {\n    return;\n  }\n\n  const logDir = getLogDir();\n  const logFile = `${logDir}/hooks.log`;\n\n  try {\n    ensureDir(logDir);\n    rotateLogFile(logFile, LOG_ROTATION_MAX_SIZE);\n\n    const timestamp = new Date().toISOString().replace('T', ' ').slice(0, 19);\n    appendFileSync(logFile, `[${timestamp}] [${level.toUpperCase()}] [${hookName}] ${message}\\n`);\n  } catch {\n    // Ignore logging errors - don't block hook execution\n  }\n}\n\n/**\n * Log permission decision for audit trail (CC 2.1.7 feature)\n * Always logs (security audit trail) - not affected by log level\n */\nexport function logPermissionFeedback(\n  decision: 'allow' | 'deny' | 'warn',\n  reason: string,\n  input?: HookInput | Record<string, unknown>\n): void {\n  const logDir = getLogDir();\n  const logFile = `${logDir}/permission-feedback.log`;\n\n  try {\n    ensureDir(logDir);\n    rotateLogFile(logFile, PERMISSION_LOG_MAX_SIZE);\n\n    const timestamp = new Date().toISOString();\n    const toolName = (input as HookInput)?.tool_name || process.env.HOOK_TOOL_NAME || 'unknown';\n    const sessionId = (input as HookInput)?.session_id || getSessionId();\n\n    appendFileSync(\n      logFile,\n      `${timestamp} | ${decision} | ${reason} | tool=${toolName} | session=${sessionId}\\n`\n    );\n  } catch {\n    // Ignore logging errors\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Token Estimation\n// -----------------------------------------------------------------------------\n\n/**\n * Content-aware token estimation (~80% accuracy without external tokenizer).\n * Code-heavy content averages ~2.8 chars/token; prose ~3.5 chars/token.\n */\nexport function estimateTokenCount(content: string): number {\n  if (!content) return 0;\n  const codeIndicators = (content.match(/[{};()=><]/g) || []).length;\n  const codeRatio = codeIndicators / content.length;\n  const charsPerToken = codeRatio > 0.03 ? 2.8 : 3.5;\n  return Math.ceil(content.length / charsPerToken);\n}\n\n// -----------------------------------------------------------------------------\n// Budgeted Output Helpers\n// -----------------------------------------------------------------------------\n\n/**\n * Output prompt context with token budget awareness.\n * Checks if the category is over budget before injecting.\n * Falls back to silent success when budget exhausted.\n *\n * Accepts budget checker and tracker as parameters to avoid circular deps.\n * If not provided, falls back to unchecked injection.\n */\nexport function outputPromptContextBudgeted(\n  ctx: string,\n  hookName: string,\n  category: string,\n  budgetChecker?: { isOverBudget: (cat: string) => boolean },\n  tokenTracker?: { trackTokenUsage: (hook: string, cat: string, tokens: number) => void },\n): HookResult {\n  const tokens = estimateTokenCount(ctx);\n\n  if (budgetChecker && budgetChecker.isOverBudget(category)) {\n    logHook(hookName, `Budget exhausted for ${category}, suppressing ${tokens}t`);\n    return outputSilentSuccess();\n  }\n\n  if (tokenTracker) {\n    tokenTracker.trackTokenUsage(hookName, category, tokens);\n  }\n\n  return outputPromptContext(ctx);\n}\n\n// -----------------------------------------------------------------------------\n// Input Helpers\n// -----------------------------------------------------------------------------\n\n/**\n * Read hook input from stdin synchronously\n * Returns parsed JSON or empty object on failure\n */\nexport function readHookInput(): HookInput {\n  try {\n    // Read from stdin synchronously\n    const chunks: Buffer[] = [];\n    const BUFSIZE = 256;\n    const buf = Buffer.allocUnsafe(BUFSIZE);\n\n    let bytesRead: number;\n    const fd = 0; // stdin\n\n    while (true) {\n      try {\n        bytesRead = readSync(fd, buf, 0, BUFSIZE, null);\n        if (bytesRead === 0) break;\n        chunks.push(Buffer.from(buf.subarray(0, bytesRead)));\n      } catch {\n        break;\n      }\n    }\n\n    const input = Buffer.concat(chunks).toString('utf8').trim();\n    if (!input) {\n      return { tool_name: '', session_id: getSessionId(), tool_input: {} };\n    }\n\n    return JSON.parse(input);\n  } catch {\n    return { tool_name: '', session_id: getSessionId(), tool_input: {} };\n  }\n}\n\n/**\n * Get field from hook input using optional chaining\n */\nexport function getField<T>(input: HookInput, path: string): T | undefined {\n  const parts = path.replace(/^\\./, '').split('.');\n  let value: unknown = input;\n\n  for (const part of parts) {\n    if (value === null || value === undefined) return undefined;\n    value = (value as Record<string, unknown>)[part];\n  }\n\n  return value as T;\n}\n\n// -----------------------------------------------------------------------------\n// String Utilities\n// -----------------------------------------------------------------------------\n\n/**\n * Normalize command: remove line continuations and collapse whitespace\n * Prevents bypassing detection with backslash-newline tricks (CC 2.1.6 fix)\n */\nexport function normalizeCommand(command: string): string {\n  return command\n    .replace(/\\\\\\s*[\\r\\n]+/g, ' ') // Remove line continuations\n    .replace(/\\n/g, ' ') // Replace newlines with spaces\n    .replace(/\\s+/g, ' ') // Collapse whitespace\n    .trim();\n}\n\n/**\n * Escape string for use in regex\n */\nexport function escapeRegex(str: string): string {\n  return str.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\n", "/**\n * Calibration Engine - Outcome-based learning for intent classification\n * Issue #197: Agent Orchestration Layer\n *\n * Learns from agent dispatch outcomes to improve classification accuracy:\n * - Records dispatch-outcome pairs\n * - Calculates keyword-agent boost/penalty adjustments\n * - Provides calibration data for intent classifier\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { createHash } from 'node:crypto';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport type {\n  CalibrationRecord,\n  CalibrationAdjustment,\n  CalibrationData,\n  AgentOutcome,\n} from './orchestration-types.js';\n\n// -----------------------------------------------------------------------------\n// Constants\n// -----------------------------------------------------------------------------\n\n/** Maximum records to keep in calibration data */\nconst MAX_RECORDS = 500;\n\n/** Minimum samples needed before applying adjustments */\nconst MIN_SAMPLES_FOR_ADJUSTMENT = 3;\n\n/** Maximum adjustment magnitude */\nconst MAX_ADJUSTMENT = 15;\n\n/** Adjustment step per outcome */\nconst ADJUSTMENT_STEP = 3;\n\n/** Decay factor for old records (applied to adjustments) */\nconst DECAY_FACTOR = 0.9;\n\n// -----------------------------------------------------------------------------\n// File Management\n// -----------------------------------------------------------------------------\n\nfunction getCalibrationFile(): string {\n  return `${getProjectDir()}/.claude/feedback/calibration-data.json`;\n}\n\nfunction ensureDir(): void {\n  const dir = `${getProjectDir()}/.claude/feedback`;\n  if (!existsSync(dir)) {\n    try {\n      mkdirSync(dir, { recursive: true });\n    } catch {\n      // Ignore\n    }\n  }\n}\n\n/**\n * Load calibration data from file\n */\nexport function loadCalibrationData(): CalibrationData {\n  const file = getCalibrationFile();\n\n  if (existsSync(file)) {\n    try {\n      return JSON.parse(readFileSync(file, 'utf8'));\n    } catch {\n      logHook('calibration-engine', 'Failed to load calibration data, using defaults');\n    }\n  }\n\n  return {\n    schemaVersion: '1.0.0',\n    createdAt: new Date().toISOString(),\n    updatedAt: new Date().toISOString(),\n    records: [],\n    adjustments: [],\n    stats: {\n      totalDispatches: 0,\n      successRate: 0,\n      avgConfidence: 0,\n      topAgents: [],\n    },\n  };\n}\n\n/**\n * Save calibration data to file\n */\nexport function saveCalibrationData(data: CalibrationData): void {\n  ensureDir();\n  const file = getCalibrationFile();\n\n  data.updatedAt = new Date().toISOString();\n\n  try {\n    writeFileSync(file, JSON.stringify(data, null, 2));\n    logHook('calibration-engine', 'Saved calibration data');\n  } catch (err) {\n    logHook('calibration-engine', `Failed to save calibration data: ${err}`);\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Recording\n// -----------------------------------------------------------------------------\n\n/**\n * Create a hash of prompt for deduplication\n */\nexport function hashPrompt(prompt: string): string {\n  return createHash('sha256').update(prompt.toLowerCase().trim()).digest('hex').slice(0, 16);\n}\n\n/**\n * Record a dispatch outcome\n */\nexport function recordOutcome(\n  prompt: string,\n  agent: string,\n  matchedKeywords: string[],\n  confidence: number,\n  outcome: AgentOutcome,\n  durationMs?: number,\n  feedback?: 'positive' | 'negative' | 'neutral'\n): void {\n  const data = loadCalibrationData();\n\n  const record: CalibrationRecord = {\n    timestamp: new Date().toISOString(),\n    sessionId: getSessionId(),\n    agent,\n    promptHash: hashPrompt(prompt),\n    matchedKeywords,\n    dispatchConfidence: confidence,\n    outcome,\n    durationMs,\n    feedback,\n  };\n\n  data.records.push(record);\n\n  // Trim old records\n  if (data.records.length > MAX_RECORDS) {\n    data.records = data.records.slice(-MAX_RECORDS);\n  }\n\n  // Update adjustments\n  updateAdjustments(data, record);\n\n  // Update stats\n  updateStats(data);\n\n  saveCalibrationData(data);\n\n  logHook(\n    'calibration-engine',\n    `Recorded outcome: ${agent} -> ${outcome} (conf: ${confidence})`\n  );\n}\n\n// -----------------------------------------------------------------------------\n// Adjustment Calculation\n// -----------------------------------------------------------------------------\n\n/**\n * Update adjustments based on new record\n */\nfunction updateAdjustments(data: CalibrationData, record: CalibrationRecord): void {\n  const isPositive = record.outcome === 'success';\n  const isNegative = record.outcome === 'failure' || record.outcome === 'rejected';\n\n  if (!isPositive && !isNegative) {\n    // Partial outcomes don't affect adjustments\n    return;\n  }\n\n  const adjustmentDelta = isPositive ? ADJUSTMENT_STEP : -ADJUSTMENT_STEP;\n\n  for (const keyword of record.matchedKeywords) {\n    const existing = data.adjustments.find(\n      a => a.keyword === keyword && a.agent === record.agent\n    );\n\n    if (existing) {\n      // Update existing adjustment\n      existing.adjustment = Math.max(\n        -MAX_ADJUSTMENT,\n        Math.min(MAX_ADJUSTMENT, existing.adjustment + adjustmentDelta)\n      );\n      existing.sampleCount++;\n      existing.lastUpdated = new Date().toISOString();\n    } else {\n      // Create new adjustment\n      data.adjustments.push({\n        keyword,\n        agent: record.agent,\n        adjustment: adjustmentDelta,\n        sampleCount: 1,\n        lastUpdated: new Date().toISOString(),\n      });\n    }\n  }\n}\n\n/**\n * Apply decay to old adjustments\n */\nexport function applyDecay(data: CalibrationData): void {\n  const now = Date.now();\n  const dayMs = 24 * 60 * 60 * 1000;\n\n  for (const adj of data.adjustments) {\n    const age = now - new Date(adj.lastUpdated).getTime();\n    const daysOld = Math.floor(age / dayMs);\n\n    if (daysOld > 7) {\n      // Apply decay for adjustments older than 7 days\n      adj.adjustment = Math.round(adj.adjustment * DECAY_FACTOR);\n\n      // Remove zero adjustments\n      if (Math.abs(adj.adjustment) < 1) {\n        adj.adjustment = 0;\n      }\n    }\n  }\n\n  // Remove zero adjustments\n  data.adjustments = data.adjustments.filter(a => a.adjustment !== 0);\n}\n\n// -----------------------------------------------------------------------------\n// Statistics\n// -----------------------------------------------------------------------------\n\n/**\n * Update aggregate statistics\n */\nfunction updateStats(data: CalibrationData): void {\n  const records = data.records;\n  if (records.length === 0) return;\n\n  // Total dispatches\n  data.stats.totalDispatches = records.length;\n\n  // Success rate\n  const successful = records.filter(r => r.outcome === 'success').length;\n  data.stats.successRate = successful / records.length;\n\n  // Average confidence\n  const avgConf = records.reduce((sum, r) => sum + r.dispatchConfidence, 0) / records.length;\n  data.stats.avgConfidence = Math.round(avgConf);\n\n  // Top agents by count and success rate\n  const agentStats = new Map<string, { count: number; success: number }>();\n  for (const record of records) {\n    const stat = agentStats.get(record.agent) || { count: 0, success: 0 };\n    stat.count++;\n    if (record.outcome === 'success') stat.success++;\n    agentStats.set(record.agent, stat);\n  }\n\n  data.stats.topAgents = Array.from(agentStats.entries())\n    .map(([agent, stat]) => ({\n      agent,\n      count: stat.count,\n      successRate: stat.success / stat.count,\n    }))\n    .sort((a, b) => b.count - a.count)\n    .slice(0, 10);\n}\n\n// -----------------------------------------------------------------------------\n// Query Functions\n// -----------------------------------------------------------------------------\n\n/**\n * Get adjustments for intent classifier\n */\nexport function getAdjustments(): CalibrationAdjustment[] {\n  const data = loadCalibrationData();\n\n  // Only return adjustments with sufficient samples\n  return data.adjustments.filter(a => a.sampleCount >= MIN_SAMPLES_FOR_ADJUSTMENT);\n}\n\n/**\n * Get success rate for a specific agent\n */\nexport function getAgentSuccessRate(agent: string): number | null {\n  const data = loadCalibrationData();\n  const agentRecords = data.records.filter(r => r.agent === agent);\n\n  if (agentRecords.length < MIN_SAMPLES_FOR_ADJUSTMENT) {\n    return null;\n  }\n\n  const successful = agentRecords.filter(r => r.outcome === 'success').length;\n  return successful / agentRecords.length;\n}\n\n/**\n * Get calibration stats\n */\nexport function getCalibrationStats(): CalibrationData['stats'] {\n  return loadCalibrationData().stats;\n}\n\n/**\n * Check if we have enough data for meaningful calibration\n */\nexport function hasMinimalCalibrationData(): boolean {\n  const data = loadCalibrationData();\n  return data.records.length >= MIN_SAMPLES_FOR_ADJUSTMENT;\n}\n", "/**\n * Auto-Remember Continuity - Stop Hook\n * Prompts Claude to store session context before end\n *\n * Graph-First Architecture (v2.1):\n * - ALWAYS works - knowledge graph requires no configuration\n * - Primary: Store in knowledge graph (mcp__memory__*)\n * - Optional: Also sync to mem0 cloud if configured\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir } from '../lib/common.js';\n\n/**\n * Generate stop prompt for session continuity\n */\nexport function autoRememberContinuity(input: HookInput): HookResult {\n  logHook('auto-remember-continuity', 'Hook triggered');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const projectId = projectDir.split('/').pop() || 'project';\n\n  // Check if mem0 is available (by checking env var)\n  const mem0Available = !!process.env.MEM0_API_KEY;\n  const mem0Hint = mem0Available\n    ? '\\n   [Optional] Also sync to mem0 cloud with `--mem0` flag for semantic search'\n    : '';\n\n  const promptMsg = `Before ending this session, consider preserving important context in the knowledge graph:\n\n1. **Session Continuity** - If there's unfinished work or next steps:\n   \\`mcp__memory__create_entities\\` with:\n   \\`\\`\\`json\n   {\"entities\": [{\n     \"name\": \"session-${projectId}\",\n     \"entityType\": \"Session\",\n     \"observations\": [\"What was done: [...]\", \"Next steps: [...]\"]\n   }]}\n   \\`\\`\\`${mem0Hint}\n\n2. **Important Decisions** - If architectural/design decisions were made:\n   \\`mcp__memory__create_entities\\` with:\n   \\`\\`\\`json\n   {\"entities\": [{\n     \"name\": \"decision-[topic]\",\n     \"entityType\": \"Decision\",\n     \"observations\": [\"Decided: [...]\", \"Rationale: [...]\"]\n   }]}\n   \\`\\`\\`\n\n3. **Patterns Learned** - If something worked well or failed:\n   - Use \\`/remember --success \"pattern that worked\"\\`\n   - Use \\`/remember --failed \"pattern that caused issues\"\\`\n\nSkip if this was just a quick question/answer session.`;\n\n  logHook('auto-remember-continuity', 'Outputting memory prompt for session end');\n\n  return {\n    continue: true,\n    suppressOutput: true,\n    // Note: stopPrompt is handled by the CC runtime, we just return continue: true\n  };\n}\n", "/**\n * Auto-Save Context - Saves session context before stop\n * Hook: Stop\n * CC 2.1.6 Compliant - Context Protocol 2.0\n *\n * Ensures state.json always has required fields:\n * - $schema: For schema validation\n * - _meta: For attention positioning and token budgets\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\ninterface SessionState {\n  $schema: string;\n  _meta: {\n    position: string;\n    token_budget: number;\n    auto_load: string;\n    compress: string;\n    description: string;\n  };\n  session_id: string | null;\n  started: string | null;\n  last_activity: string;\n  current_task: {\n    description: string;\n    status: string;\n  };\n  next_steps: string[];\n  blockers: string[];\n}\n\n/**\n * Auto-save context on session stop\n */\nexport function autoSaveContext(input: HookInput): HookResult {\n  logHook('auto-save-context', 'Stop hook - auto-saving context (Protocol 2.0)');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const sessionDir = `${projectDir}/.claude/context/session`;\n  const sessionState = `${sessionDir}/state.json`;\n\n  // Ensure session directory exists\n  try {\n    if (!existsSync(sessionDir)) {\n      mkdirSync(sessionDir, { recursive: true });\n    }\n  } catch {\n    // Ignore directory creation errors\n  }\n\n  const timestamp = new Date().toISOString();\n\n  try {\n    if (existsSync(sessionState)) {\n      // Update existing session state\n      const content = readFileSync(sessionState, 'utf-8');\n      const state: Partial<SessionState> = JSON.parse(content);\n\n      // Ensure required fields exist\n      const updated: SessionState = {\n        $schema: state.$schema || 'context://session/v1',\n        _meta: state._meta || {\n          position: 'END',\n          token_budget: 500,\n          auto_load: 'always',\n          compress: 'on_threshold',\n          description: 'Session state and progress - ALWAYS loaded at END of context',\n        },\n        session_id: state.session_id || null,\n        started: state.started || null,\n        last_activity: timestamp,\n        current_task: state.current_task || { description: 'No active task', status: 'pending' },\n        next_steps: state.next_steps || [],\n        blockers: state.blockers || [],\n      };\n\n      writeFileSync(sessionState, JSON.stringify(updated, null, 2));\n      logHook('auto-save-context', 'Updated session state timestamp');\n    } else {\n      // Create new session state\n      const newState: SessionState = {\n        $schema: 'context://session/v1',\n        _meta: {\n          position: 'END',\n          token_budget: 500,\n          auto_load: 'always',\n          compress: 'on_threshold',\n          description: 'Session state and progress - ALWAYS loaded at END of context',\n        },\n        session_id: null,\n        started: timestamp,\n        last_activity: timestamp,\n        current_task: {\n          description: 'No active task',\n          status: 'pending',\n        },\n        next_steps: [],\n        blockers: [],\n      };\n\n      writeFileSync(sessionState, JSON.stringify(newState, null, 2));\n      logHook('auto-save-context', 'Created new session state (Protocol 2.0 compliant)');\n    }\n  } catch (error) {\n    logHook('auto-save-context', `Error saving context: ${error}`);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Cleanup Instance - Stop Hook\n * Releases all locks and unregisters instance when Claude Code exits\n * CC 2.1.6 Compliant\n *\n * Part of Multi-Worktree Coordination System\n */\n\nimport { existsSync, readFileSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Get instance ID from identity file\n */\nfunction getInstanceId(projectDir: string): string | null {\n  const idFile = `${projectDir}/.instance/id.json`;\n  try {\n    if (!existsSync(idFile)) {\n      return null;\n    }\n    const content = JSON.parse(readFileSync(idFile, 'utf-8'));\n    return content.instance_id || null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Execute SQLite command\n */\nfunction runSqlite(dbPath: string, sql: string): void {\n  try {\n    execSync(`sqlite3 \"${dbPath}\" \"${sql}\"`, {\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n  } catch {\n    // Ignore SQLite errors\n  }\n}\n\n/**\n * Cleanup instance on stop\n */\nexport function cleanupInstance(input: HookInput): HookResult {\n  const projectDir = input.project_dir || getProjectDir();\n  const dbPath = `${projectDir}/.claude/coordination/.claude.db`;\n\n  // Check if coordination is enabled\n  if (!existsSync(dbPath)) {\n    logHook('cleanup-instance', 'No coordination database, skipping cleanup');\n    return outputSilentSuccess();\n  }\n\n  // Get instance ID\n  const instanceId = getInstanceId(projectDir);\n  if (!instanceId) {\n    logHook('cleanup-instance', 'No instance ID to clean up');\n    return outputSilentSuccess();\n  }\n\n  logHook('cleanup-instance', `Cleaning up instance: ${instanceId}`);\n\n  // Release all locks held by this instance\n  logHook('cleanup-instance', 'Releasing all locks...');\n  runSqlite(dbPath, `DELETE FROM file_locks WHERE instance_id = '${instanceId}';`);\n  logHook('cleanup-instance', 'All locks released');\n\n  // Handle work claims if table exists\n  try {\n    const hasTable = execSync(\n      `sqlite3 \"${dbPath}\" \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='work_claims';\"`,\n      { encoding: 'utf8', timeout: 5000 }\n    ).trim();\n\n    if (hasTable === '1') {\n      runSqlite(\n        dbPath,\n        `UPDATE work_claims SET status = 'abandoned', completed_at = datetime('now') WHERE instance_id = '${instanceId}' AND status = 'active';`\n      );\n      logHook('cleanup-instance', 'Work claims handled');\n    }\n  } catch {\n    // Ignore table check errors\n  }\n\n  // Update instance status if table exists\n  try {\n    const hasTable = execSync(\n      `sqlite3 \"${dbPath}\" \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='instances';\"`,\n      { encoding: 'utf8', timeout: 5000 }\n    ).trim();\n\n    if (hasTable === '1') {\n      runSqlite(\n        dbPath,\n        `UPDATE instances SET status = 'terminated', last_heartbeat = datetime('now') WHERE id = '${instanceId}';`\n      );\n      logHook('cleanup-instance', 'Instance status updated to terminated');\n    }\n  } catch {\n    // Ignore table check errors\n  }\n\n  logHook('cleanup-instance', 'Multi-instance cleanup completed');\n  return outputSilentSuccess();\n}\n", "/**\n * Context Compressor - Session End Hook\n * CC 2.1.7 Compliant\n * Compresses and archives context at end of session\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n// Configuration\nconst MAX_ACTIVE_DECISIONS = 10;\n\ninterface SessionState {\n  session_id?: string;\n  [key: string]: unknown;\n}\n\ninterface DecisionsFile {\n  decisions: unknown[];\n  [key: string]: unknown;\n}\n\n/**\n * Archive current session\n */\nfunction archiveSession(contextDir: string): void {\n  const sessionFile = `${contextDir}/session/state.json`;\n  if (!existsSync(sessionFile)) {\n    logHook('context-compressor', 'No session state to archive');\n    return;\n  }\n\n  try {\n    const content = readFileSync(sessionFile, 'utf-8');\n    const session: SessionState = JSON.parse(content);\n\n    const sessionId = session.session_id || `session-${new Date().toISOString().replace(/[:.]/g, '-')}`;\n    const archiveDir = `${contextDir}/archive/sessions`;\n    mkdirSync(archiveDir, { recursive: true });\n\n    const archiveFile = `${archiveDir}/${sessionId}.json`;\n    const archived = {\n      ...session,\n      ended: new Date().toISOString(),\n      archived: true,\n    };\n\n    writeFileSync(archiveFile, JSON.stringify(archived, null, 2));\n    logHook('context-compressor', `Archived session to ${archiveFile}`);\n\n    // Reset session state\n    const resetState = {\n      $schema: 'context://session/v1',\n      _meta: { position: 'END', token_budget: 500, auto_load: 'always' },\n      session_id: null,\n      started: null,\n      current_task: null,\n      files_touched: [],\n      decisions_this_session: [],\n      blockers: [],\n      next_steps: [],\n      scratchpad: { notes: [] },\n    };\n\n    writeFileSync(sessionFile, JSON.stringify(resetState, null, 2));\n    logHook('context-compressor', 'Reset session state');\n  } catch (error) {\n    logHook('context-compressor', `Error archiving session: ${error}`);\n  }\n}\n\n/**\n * Compress old decisions\n */\nfunction compressOldDecisions(contextDir: string): void {\n  const decisionsFile = `${contextDir}/knowledge/decisions/active.json`;\n  if (!existsSync(decisionsFile)) {\n    return;\n  }\n\n  try {\n    const content = readFileSync(decisionsFile, 'utf-8');\n    const data: DecisionsFile = JSON.parse(content);\n    const decisions = data.decisions || [];\n\n    if (decisions.length <= MAX_ACTIVE_DECISIONS) {\n      return;\n    }\n\n    const archiveDir = `${contextDir}/archive/decisions`;\n    mkdirSync(archiveDir, { recursive: true });\n\n    const now = new Date();\n    const archiveFile = `${archiveDir}/${now.getFullYear()}-${String(now.getMonth() + 1).padStart(2, '0')}.json`;\n\n    // Archive old decisions\n    const toArchive = decisions.slice(0, -MAX_ACTIVE_DECISIONS);\n    writeFileSync(archiveFile, JSON.stringify(toArchive, null, 2));\n\n    // Keep only recent decisions\n    data.decisions = decisions.slice(-MAX_ACTIVE_DECISIONS);\n    writeFileSync(decisionsFile, JSON.stringify(data, null, 2));\n\n    logHook('context-compressor', `Archived ${toArchive.length} old decisions`);\n  } catch (error) {\n    logHook('context-compressor', `Error compressing decisions: ${error}`);\n  }\n}\n\n/**\n * Write compaction manifest for session resume (CC 2.1.20)\n * Provides structured context for session-context-loader to pick up\n */\nfunction writeCompactionManifest(contextDir: string): void {\n  const sessionFile = `${contextDir}/session/state.json`;\n  if (!existsSync(sessionFile)) {\n    return;\n  }\n\n  try {\n    const content = readFileSync(sessionFile, 'utf-8');\n    const session = JSON.parse(content);\n\n    const manifest = {\n      sessionId: session.session_id || 'unknown',\n      compactedAt: new Date().toISOString(),\n      keyDecisions: (session.decisions_this_session || []).slice(-5),\n      filesTouched: (session.files_touched || []).slice(-20),\n      blockers: session.blockers || [],\n      nextSteps: session.next_steps || [],\n    };\n\n    const manifestDir = `${contextDir}/session`;\n    mkdirSync(manifestDir, { recursive: true });\n    writeFileSync(`${manifestDir}/compaction-manifest.json`, JSON.stringify(manifest, null, 2));\n    logHook('context-compressor', `Wrote compaction manifest for session ${manifest.sessionId}`);\n  } catch (error) {\n    logHook('context-compressor', `Error writing compaction manifest: ${error}`);\n  }\n}\n\n/**\n * Main context compression function\n */\nexport function contextCompressor(input: HookInput): HookResult {\n  logHook('context-compressor', 'Starting end-of-session compression...');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const contextDir = `${projectDir}/context`;\n\n  writeCompactionManifest(contextDir);\n  archiveSession(contextDir);\n  compressOldDecisions(contextDir);\n\n  logHook('context-compressor', 'End-of-session compression complete');\n  return outputSilentSuccess();\n}\n", "/**\n * Full Test Suite Runner - Stop Hook\n * CC 2.1.3 Compliant - Uses 10-minute hook timeout\n *\n * Runs the complete test suite on conversation stop.\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Check if we should run tests\n */\nfunction shouldRunTests(projectDir: string): boolean {\n  const lastRunFile = `${projectDir}/.claude/hooks/logs/.last-test-run`;\n\n  // Always run if no previous run\n  if (!existsSync(lastRunFile)) {\n    return true;\n  }\n\n  // Check if any code files changed since last run\n  try {\n    const result = execSync('git diff --name-only HEAD', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n\n    if (/\\.(py|js|ts|go|rs)$/.test(result)) {\n      return true;\n    }\n  } catch {\n    // On error, run tests anyway\n    return true;\n  }\n\n  logHook('full-test-suite', 'No code changes detected, skipping tests');\n  return false;\n}\n\n/**\n * Detect project type and run appropriate tests\n */\nfunction runTests(projectDir: string, logFile: string): boolean {\n  let exitCode = 0;\n\n  // Python project (pytest)\n  if (\n    existsSync(`${projectDir}/pytest.ini`) ||\n    existsSync(`${projectDir}/pyproject.toml`) ||\n    (existsSync(`${projectDir}/tests`) && existsSync(`${projectDir}/requirements.txt`))\n  ) {\n    logHook('full-test-suite', 'Detected Python project, running pytest...');\n    try {\n      execSync('pytest --tb=short --timeout=300 -q', {\n        cwd: projectDir,\n        encoding: 'utf8',\n        timeout: 300000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  // Node.js project (npm/yarn/pnpm)\n  if (existsSync(`${projectDir}/package.json`)) {\n    logHook('full-test-suite', 'Detected Node.js project...');\n    try {\n      const packageJson = JSON.parse(readFileSync(`${projectDir}/package.json`, 'utf-8'));\n      if (packageJson.scripts?.test) {\n        logHook('full-test-suite', 'Running npm test...');\n\n        // Try different package managers\n        let cmd = 'npm test -- --passWithNoTests --watchAll=false';\n        try {\n          execSync('which pnpm', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n          cmd = 'pnpm test --passWithNoTests';\n        } catch {\n          try {\n            execSync('which yarn', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n            cmd = 'yarn test --passWithNoTests';\n          } catch {\n            // Use npm\n          }\n        }\n\n        execSync(cmd, {\n          cwd: projectDir,\n          encoding: 'utf8',\n          timeout: 300000,\n          stdio: ['pipe', 'pipe', 'pipe'],\n        });\n      }\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  // Go project\n  if (existsSync(`${projectDir}/go.mod`)) {\n    logHook('full-test-suite', 'Detected Go project, running go test...');\n    try {\n      execSync('go test -v -timeout 5m ./...', {\n        cwd: projectDir,\n        encoding: 'utf8',\n        timeout: 300000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  // Rust project\n  if (existsSync(`${projectDir}/Cargo.toml`)) {\n    logHook('full-test-suite', 'Detected Rust project, running cargo test...');\n    try {\n      execSync('cargo test', {\n        cwd: projectDir,\n        encoding: 'utf8',\n        timeout: 300000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  return exitCode === 0;\n}\n\n/**\n * Full test suite runner\n */\nexport function fullTestSuite(input: HookInput): HookResult {\n  logHook('full-test-suite', '=== Full Test Suite Started ===');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const logDir = `${projectDir}/.claude/hooks/logs`;\n\n  // Ensure log directory exists\n  try {\n    mkdirSync(logDir, { recursive: true });\n  } catch {\n    // Ignore\n  }\n\n  const logFile = `${logDir}/full-test-suite.log`;\n\n  if (!shouldRunTests(projectDir)) {\n    return outputSilentSuccess();\n  }\n\n  const passed = runTests(projectDir, logFile);\n\n  if (passed) {\n    logHook('full-test-suite', '=== All tests passed ===');\n    // Update last run file\n    try {\n      writeFileSync(`${logDir}/.last-test-run`, String(Date.now()));\n    } catch {\n      // Ignore\n    }\n  } else {\n    logHook('full-test-suite', '=== Some tests failed ===');\n    // Don't block - just log the failure\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Issue Work Summary - Stop Hook\n * Posts consolidated progress comments to GitHub issues\n *\n * CC 2.1.7 Compliant: Uses suppressOutput for silent operation\n */\n\nimport { existsSync, readFileSync, unlinkSync, rmdirSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, getSessionId, outputSilentSuccess } from '../lib/common.js';\n\ninterface IssueProgress {\n  issues: {\n    [issueNum: string]: {\n      branch: string;\n      commits: Array<{ sha: string; message: string }>;\n      tasks_completed: string[];\n    };\n  };\n}\n\n/**\n * Check if gh CLI is available and authenticated\n */\nfunction isGhAvailable(): boolean {\n  try {\n    execSync('which gh', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n    execSync('gh auth status', { encoding: 'utf8', timeout: 5000, stdio: ['pipe', 'pipe', 'pipe'] });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check if in a GitHub repository\n */\nfunction isGitHubRepo(projectDir: string): boolean {\n  try {\n    const remote = execSync('git remote get-url origin', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    return remote.includes('github');\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Generate markdown comment for an issue\n */\nfunction generateComment(issueNum: string, data: IssueProgress['issues'][string], sessionId: string): string {\n  const commits = data.commits || [];\n  if (commits.length === 0) {\n    return '';\n  }\n\n  const commitsSection = commits.map((c) => `- \\`${c.sha}\\`: ${c.message}`).join('\\n');\n  const tasksSection =\n    data.tasks_completed?.length > 0\n      ? `### Sub-tasks Completed\\n${data.tasks_completed.map((t) => `- [x] ${t}`).join('\\n')}`\n      : '';\n\n  return `## Claude Code Progress Update\n\n**Session**: \\`${sessionId.slice(0, 8)}...\\`\n**Branch**: \\`${data.branch || 'unknown'}\\`\n\n### Commits (${commits.length})\n${commitsSection}\n\n${tasksSection}\n---\n*Automated by [OrchestKit](https://github.com/yonatangross/orchestkit)*`;\n}\n\n/**\n * Post comment to GitHub issue\n */\nfunction postComment(issueNum: string, comment: string): boolean {\n  try {\n    execSync(`gh issue comment ${issueNum} --body \"${comment.replace(/\"/g, '\\\\\"')}\"`, {\n      encoding: 'utf8',\n      timeout: 30000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Issue work summary hook\n */\nexport function issueWorkSummary(input: HookInput): HookResult {\n  logHook('issue-work-summary', 'Session ending, checking for issue progress to post...');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const sessionId = input.session_id || getSessionId();\n\n  // Sanitize session ID to prevent path traversal\n  const safeSessionId = sessionId.replace(/[^a-zA-Z0-9_-]/g, '');\n  const sessionDir = `/tmp/claude-session-${safeSessionId}`;\n  const progressFile = `${sessionDir}/issue-progress.json`;\n\n  // Check if progress file exists\n  if (!existsSync(progressFile)) {\n    logHook('issue-work-summary', `No progress file found at ${progressFile}`);\n    return outputSilentSuccess();\n  }\n\n  // Check if gh CLI is available\n  if (!isGhAvailable()) {\n    logHook('issue-work-summary', 'gh CLI not available or not authenticated, skipping');\n    return outputSilentSuccess();\n  }\n\n  // Check if we're in a GitHub repo\n  if (!isGitHubRepo(projectDir)) {\n    logHook('issue-work-summary', 'Not a GitHub repository, skipping');\n    return outputSilentSuccess();\n  }\n\n  // Read progress file\n  let progressJson: IssueProgress;\n  try {\n    progressJson = JSON.parse(readFileSync(progressFile, 'utf-8'));\n  } catch {\n    logHook('issue-work-summary', 'Failed to read progress file');\n    return outputSilentSuccess();\n  }\n\n  const issues = progressJson.issues ? Object.keys(progressJson.issues) : [];\n  if (issues.length === 0) {\n    logHook('issue-work-summary', 'No issues to process');\n    return outputSilentSuccess();\n  }\n\n  // Process each issue\n  let postedCount = 0;\n  for (const issueNum of issues) {\n    const issueData = progressJson.issues[issueNum];\n    const commits = issueData.commits || [];\n\n    if (commits.length === 0) {\n      logHook('issue-work-summary', `No commits for issue #${issueNum}, skipping`);\n      continue;\n    }\n\n    // Verify issue exists\n    try {\n      execSync(`gh issue view ${issueNum} --json number`, {\n        encoding: 'utf8',\n        timeout: 10000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      logHook('issue-work-summary', `Issue #${issueNum} not found or not accessible, skipping`);\n      continue;\n    }\n\n    // Generate and post comment\n    const comment = generateComment(issueNum, issueData, sessionId);\n    if (comment && postComment(issueNum, comment)) {\n      postedCount++;\n      logHook('issue-work-summary', `Successfully posted comment to issue #${issueNum}`);\n    }\n  }\n\n  logHook('issue-work-summary', `Posted progress comments to ${postedCount} issue(s)`);\n\n  // Clean up progress file\n  try {\n    unlinkSync(progressFile);\n    // Remove session dir if empty\n    try {\n      rmdirSync(sessionDir);\n    } catch {\n      // Directory not empty, leave it\n    }\n    logHook('issue-work-summary', 'Cleaned up progress file');\n  } catch {\n    // Ignore cleanup errors\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Mem0 Pre-Compaction Sync Hook\n * Prompts Claude to save important session context to Mem0 before compaction\n *\n * Features:\n * - Graph memory support\n * - Pending pattern sync\n * - Session summaries\n * - Batch operations for efficiency\n */\n\nimport { existsSync, readFileSync, mkdirSync, appendFileSync, writeFileSync } from 'node:fs';\nimport { spawn } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, getPluginRoot, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Count pending decisions not yet synced\n */\nfunction countPendingDecisions(decisionLog: string, syncState: string): number {\n  if (!existsSync(decisionLog)) {\n    return 0;\n  }\n\n  try {\n    const decisions = JSON.parse(readFileSync(decisionLog, 'utf-8'));\n    const decisionList = decisions.decisions || [];\n\n    if (existsSync(syncState)) {\n      const state = JSON.parse(readFileSync(syncState, 'utf-8'));\n      const syncedIds = state.synced_decisions || [];\n      return decisionList.filter((d: { decision_id: string }) => !syncedIds.includes(d.decision_id)).length;\n    }\n\n    return decisionList.length;\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Count pending patterns\n */\nfunction countPendingPatterns(patternsLog: string): { count: number; patterns: unknown[] } {\n  if (!existsSync(patternsLog)) {\n    return { count: 0, patterns: [] };\n  }\n\n  try {\n    const content = readFileSync(patternsLog, 'utf-8');\n    // Try parsing as JSONL (one object per line) or single JSON\n    let patterns: unknown[];\n    try {\n      patterns = content\n        .split('\\n')\n        .filter((line) => line.trim())\n        .map((line) => JSON.parse(line));\n    } catch {\n      patterns = [JSON.parse(content)];\n    }\n\n    const pending = patterns.filter((p: any) => p.pending_sync === true);\n    return { count: pending.length, patterns: pending };\n  } catch {\n    return { count: 0, patterns: [] };\n  }\n}\n\n/**\n * Get project ID from directory\n */\nfunction getProjectId(projectDir: string): string {\n  return projectDir.split('/').pop() || 'project';\n}\n\n/**\n * Extract session state info\n */\nfunction extractSessionInfo(projectDir: string): {\n  currentTask: string;\n  blockers: string;\n  nextSteps: string;\n} {\n  let currentTask = '';\n  let blockers = '';\n  let nextSteps = '';\n\n  const sessionState = `${projectDir}/.claude/context/session/state.json`;\n  if (existsSync(sessionState)) {\n    try {\n      const state = JSON.parse(readFileSync(sessionState, 'utf-8'));\n      currentTask = state.current_task || state.task || '';\n    } catch {\n      // Ignore\n    }\n  }\n\n  const blockersLog = `${projectDir}/.claude/logs/blockers.jsonl`;\n  if (existsSync(blockersLog)) {\n    try {\n      const content = readFileSync(blockersLog, 'utf-8');\n      const lines = content\n        .split('\\n')\n        .filter((line) => line.trim())\n        .map((line) => JSON.parse(line));\n      const unresolvedBlockers = lines.filter((b) => !b.resolved).slice(-5);\n      blockers = unresolvedBlockers.map((b) => b.description || '').join('; ');\n    } catch {\n      // Ignore\n    }\n  }\n\n  return { currentTask, blockers, nextSteps };\n}\n\n/**\n * Mem0 pre-compaction sync hook\n */\nexport function mem0PreCompactionSync(input: HookInput): HookResult {\n  // Gate: Skip entirely if mem0 is not configured\n  if (!process.env.MEM0_API_KEY) {\n    logHook('mem0-pre-compaction-sync', 'Mem0 not configured (no MEM0_API_KEY), skipping');\n    return outputSilentSuccess();\n  }\n\n  const projectDir = input.project_dir || getProjectDir();\n  const pluginRoot = getPluginRoot();\n\n  const decisionLog = `${pluginRoot}/.claude/coordination/decision-log.json`;\n  const patternsLog = `${projectDir}/.claude/logs/agent-patterns.jsonl`;\n  const syncState = `${pluginRoot}/.claude/coordination/.decision-sync-state.json`;\n\n  // Count pending items\n  const decisionCount = countPendingDecisions(decisionLog, syncState);\n  const { count: patternCount, patterns: pendingPatterns } = countPendingPatterns(patternsLog);\n\n  // Extract session info\n  const { currentTask, blockers, nextSteps } = extractSessionInfo(projectDir);\n\n  // If nothing to sync, silent exit\n  if (decisionCount === 0 && patternCount === 0 && !currentTask) {\n    return outputSilentSuccess();\n  }\n\n  const projectId = getProjectId(projectDir);\n  const logFile = `${projectDir}/.claude/logs/mem0-sync.log`;\n\n  // Ensure log directory exists\n  try {\n    mkdirSync(`${projectDir}/.claude/logs`, { recursive: true });\n  } catch {\n    // Ignore\n  }\n\n  // Build summary message parts\n  const msgParts: string[] = [];\n  if (decisionCount > 0) {\n    msgParts.push(`${decisionCount} decisions to sync`);\n  }\n  if (patternCount > 0) {\n    msgParts.push(`${patternCount} agent patterns pending`);\n\n    // Extract unique agents\n    const agentSet = new Set(pendingPatterns.map((p: any) => p.agent_id || p.agent).filter(Boolean));\n    const uniqueAgents = Array.from(agentSet).slice(0, 5);\n    if (uniqueAgents.length > 0) {\n      msgParts.push(`agents: ${uniqueAgents.join(', ')}`);\n    }\n  }\n\n  const summary = msgParts.length > 0 ? msgParts.join('; ') : 'No pending items';\n\n  // Build session text\n  let summaryText = currentTask || 'Session work';\n  if (decisionCount > 0) {\n    summaryText += ` (${decisionCount} decisions made)`;\n  }\n  if (patternCount > 0) {\n    summaryText += ` (${patternCount} patterns learned)`;\n  }\n\n  let sessionText = `Session Summary: ${summaryText}`;\n  if (blockers) {\n    sessionText += ` | Blockers: ${blockers}`;\n  }\n  if (nextSteps) {\n    sessionText += ` | Next: ${nextSteps}`;\n  }\n\n  // Try auto-sync if MEM0_API_KEY is available\n  const scriptPath = `${pluginRoot}/skills/mem0-memory/scripts/crud/add-memory.py`;\n  const mem0ApiKey = process.env.MEM0_API_KEY;\n\n  let skillMsg: string;\n\n  if (existsSync(scriptPath) && mem0ApiKey) {\n    const timestamp = new Date().toISOString();\n    try {\n      appendFileSync(logFile, `[${timestamp}] Auto-sync triggered for session summary\\n`);\n    } catch {\n      // Ignore\n    }\n\n    // Execute sync in background (non-blocking)\n    const sessionMetadata = JSON.stringify({\n      type: 'session_summary',\n      status: 'in_progress',\n      project: projectId,\n      has_blockers: !!blockers,\n      has_next_steps: !!nextSteps,\n      source: 'orchestkit-plugin',\n    });\n\n    const child = spawn(\n      'python3',\n      [\n        scriptPath,\n        '--text',\n        sessionText,\n        '--user-id',\n        `${projectId}-continuity`,\n        '--metadata',\n        sessionMetadata,\n        '--enable-graph',\n      ],\n      {\n        detached: true,\n        stdio: ['ignore', 'pipe', 'pipe'],\n      }\n    );\n\n    child.on('error', (err) => {\n      const errTimestamp = new Date().toISOString();\n      try {\n        appendFileSync(logFile, `[${errTimestamp}] Sync child process error: ${err.message}\\n`);\n      } catch {\n        // Best-effort logging\n      }\n    });\n\n    child.on('close', (code) => {\n      const closeTimestamp = new Date().toISOString();\n      try {\n        if (code === 0) {\n          appendFileSync(logFile, `[${closeTimestamp}] Sync completed successfully\\n`);\n        } else {\n          appendFileSync(logFile, `[${closeTimestamp}] Sync exited with code ${code}\\n`);\n        }\n      } catch {\n        // Best-effort logging\n      }\n    });\n\n    if (child.stderr) {\n      let stderrData = '';\n      child.stderr.on('data', (chunk: Buffer) => {\n        stderrData += chunk.toString();\n      });\n      child.stderr.on('end', () => {\n        if (stderrData.trim()) {\n          const errTimestamp = new Date().toISOString();\n          try {\n            appendFileSync(logFile, `[${errTimestamp}] Sync stderr: ${stderrData.trim()}\\n`);\n          } catch {\n            // Best-effort logging\n          }\n        }\n      });\n    }\n\n    child.unref();\n\n    // Mark patterns as synced\n    if (patternCount > 0 && existsSync(patternsLog)) {\n      try {\n        const content = readFileSync(patternsLog, 'utf-8');\n        const updated = content\n          .split('\\n')\n          .filter((line) => line.trim())\n          .map((line) => {\n            const obj = JSON.parse(line);\n            obj.pending_sync = false;\n            return JSON.stringify(obj);\n          })\n          .join('\\n');\n        writeFileSync(patternsLog, updated);\n      } catch {\n        // Ignore\n      }\n    }\n\n    skillMsg = `[Mem0 Sync] Auto-synced: ${summary}`;\n  } else {\n    skillMsg = `[Mem0 Sync] ${summary} - Execute /mem0-sync to persist session context`;\n  }\n\n  logHook('mem0-pre-compaction-sync', skillMsg);\n\n  return {\n    continue: true,\n    systemMessage: skillMsg,\n  };\n}\n", "/**\n * Multi-Instance Cleanup Hook\n * Runs on session stop to release locks and update instance status\n * CC 2.1.7 Compliant: JSON output on all exit paths\n */\n\nimport { existsSync, readFileSync, unlinkSync, rmdirSync, readdirSync, rmSync } from 'node:fs';\nimport { execSync, spawn } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Execute SQLite command\n */\nfunction runSqlite(dbPath: string, sql: string): void {\n  try {\n    execSync(`sqlite3 \"${dbPath}\" \"${sql}\"`, {\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n  } catch {\n    // Ignore SQLite errors\n  }\n}\n\n/**\n * Check if table exists\n */\nfunction hasTable(dbPath: string, tableName: string): boolean {\n  try {\n    const result = execSync(\n      `sqlite3 \"${dbPath}\" \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='${tableName}';\"`,\n      { encoding: 'utf8', timeout: 5000, stdio: ['pipe', 'pipe', 'pipe'] }\n    ).trim();\n    return result === '1';\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Stop heartbeat process\n */\nfunction stopHeartbeat(instanceDir: string): void {\n  const pidFile = `${instanceDir}/heartbeat.pid`;\n  if (!existsSync(pidFile)) {\n    return;\n  }\n\n  try {\n    const pid = parseInt(readFileSync(pidFile, 'utf-8').trim(), 10);\n    try {\n      process.kill(pid, 0); // Check if process exists\n      process.kill(pid); // Kill it\n      logHook('multi-instance-cleanup', `Stopped heartbeat process (PID: ${pid})`);\n    } catch {\n      // Process doesn't exist\n    }\n    unlinkSync(pidFile);\n  } catch {\n    // Ignore errors\n  }\n}\n\n/**\n * Release all locks held by this instance\n */\nfunction releaseLocks(dbPath: string, instanceId: string): void {\n  logHook('multi-instance-cleanup', 'Releasing all locks...');\n  runSqlite(dbPath, `DELETE FROM file_locks WHERE instance_id = '${instanceId}';`);\n  logHook('multi-instance-cleanup', 'All locks released');\n}\n\n/**\n * Handle work claims\n */\nfunction handleWorkClaims(dbPath: string, instanceId: string): void {\n  logHook('multi-instance-cleanup', 'Handling work claims...');\n\n  if (hasTable(dbPath, 'work_claims')) {\n    runSqlite(\n      dbPath,\n      `UPDATE work_claims SET status = 'abandoned', completed_at = datetime('now') WHERE instance_id = '${instanceId}' AND status = 'active';`\n    );\n    logHook('multi-instance-cleanup', 'Work claims handled');\n  } else {\n    logHook('multi-instance-cleanup', 'No work_claims table, skipping');\n  }\n}\n\n/**\n * Update instance status\n */\nfunction updateInstanceStatus(dbPath: string, instanceId: string): void {\n  if (hasTable(dbPath, 'instances')) {\n    runSqlite(\n      dbPath,\n      `UPDATE instances SET status = 'terminated', last_heartbeat = datetime('now') WHERE id = '${instanceId}';`\n    );\n    logHook('multi-instance-cleanup', 'Instance status updated to terminated');\n  } else {\n    logHook('multi-instance-cleanup', 'No instances table, skipping status update');\n  }\n}\n\n/**\n * Broadcast shutdown message\n */\nfunction broadcastShutdown(dbPath: string, instanceId: string): void {\n  if (!hasTable(dbPath, 'messages')) {\n    logHook('multi-instance-cleanup', 'No messages table, skipping broadcast');\n    return;\n  }\n\n  const messageId = `msg-${Math.random().toString(36).slice(2, 18)}`;\n  const timestamp = new Date().toISOString();\n  const payload = JSON.stringify({ instance_id: instanceId, timestamp }).replace(/'/g, \"''\");\n\n  runSqlite(\n    dbPath,\n    `INSERT INTO messages (message_id, from_instance, to_instance, message_type, payload, expires_at) VALUES ('${messageId}', '${instanceId}', NULL, 'shutdown', '${payload}', datetime('now', '+1 hour'));`\n  );\n  logHook('multi-instance-cleanup', 'Shutdown broadcast sent');\n}\n\n/**\n * Cleanup instance-specific files\n */\nfunction cleanupInstanceFiles(instanceDir: string): void {\n  const filesToRemove = ['knowledge_cache.json', 'claims.json', 'session_discoveries.json'];\n\n  for (const file of filesToRemove) {\n    const filePath = `${instanceDir}/${file}`;\n    try {\n      if (existsSync(filePath)) {\n        unlinkSync(filePath);\n      }\n    } catch {\n      // Ignore\n    }\n  }\n\n  logHook('multi-instance-cleanup', 'Instance files cleaned up');\n}\n\n/**\n * Multi-instance cleanup hook\n */\nexport function multiInstanceCleanup(input: HookInput): HookResult {\n  const projectDir = input.project_dir || getProjectDir();\n  const instanceDir = `${projectDir}/.instance`;\n  const dbPath = `${projectDir}/.claude/coordination/.claude.db`;\n\n  // Check if coordination is enabled\n  if (!existsSync(dbPath)) {\n    logHook('multi-instance-cleanup', 'No coordination database, skipping cleanup');\n    return outputSilentSuccess();\n  }\n\n  // Check if we have instance identity\n  const idFile = `${instanceDir}/id.json`;\n  if (!existsSync(idFile)) {\n    logHook('multi-instance-cleanup', 'No instance identity, skipping cleanup');\n    return outputSilentSuccess();\n  }\n\n  // Get instance ID\n  let instanceId: string;\n  try {\n    const idData = JSON.parse(readFileSync(idFile, 'utf-8'));\n    instanceId = idData.instance_id;\n  } catch {\n    logHook('multi-instance-cleanup', 'Failed to read instance ID');\n    return outputSilentSuccess();\n  }\n\n  logHook('multi-instance-cleanup', `Starting multi-instance cleanup for ${instanceId}...`);\n\n  // Stop heartbeat first\n  stopHeartbeat(instanceDir);\n\n  // Release all locks\n  releaseLocks(dbPath, instanceId);\n\n  // Handle work claims\n  handleWorkClaims(dbPath, instanceId);\n\n  // Broadcast shutdown\n  broadcastShutdown(dbPath, instanceId);\n\n  // Update status\n  updateInstanceStatus(dbPath, instanceId);\n\n  // Cleanup files\n  cleanupInstanceFiles(instanceDir);\n\n  logHook('multi-instance-cleanup', '=== Cleanup Summary ===');\n  logHook('multi-instance-cleanup', `Instance: ${instanceId}`);\n  logHook('multi-instance-cleanup', 'Status: terminated');\n  logHook('multi-instance-cleanup', 'Multi-instance cleanup completed');\n\n  return outputSilentSuccess();\n}\n", "/**\n * Security Scan Aggregator - Stop Hook\n * CC 2.1.3 Compliant - Uses 10-minute hook timeout\n *\n * Runs multiple security tools in parallel and aggregates results.\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync, readdirSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\ninterface SecurityResults {\n  npmAudit: { critical: number; high: number } | null;\n  pipAudit: number | null;\n  semgrep: number | null;\n  bandit: number | null;\n  secrets: number;\n}\n\n/**\n * Run npm audit\n */\nfunction runNpmAudit(projectDir: string, resultsDir: string): { critical: number; high: number } | null {\n  if (\n    !existsSync(`${projectDir}/package.json`) ||\n    (!existsSync(`${projectDir}/package-lock.json`) &&\n      !existsSync(`${projectDir}/yarn.lock`) &&\n      !existsSync(`${projectDir}/pnpm-lock.yaml`))\n  ) {\n    return null;\n  }\n\n  logHook('security-scan', 'Running npm audit...');\n  try {\n    execSync('npm audit --json', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 120000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n  } catch (error: any) {\n    // npm audit returns non-zero on vulnerabilities, capture output\n    if (error.stdout) {\n      writeFileSync(`${resultsDir}/npm-audit.json`, error.stdout);\n      try {\n        const result = JSON.parse(error.stdout);\n        return {\n          critical: result.metadata?.vulnerabilities?.critical || 0,\n          high: result.metadata?.vulnerabilities?.high || 0,\n        };\n      } catch {\n        // Ignore parse errors\n      }\n    }\n  }\n  logHook('security-scan', 'npm audit complete');\n  return { critical: 0, high: 0 };\n}\n\n/**\n * Run pip-audit\n */\nfunction runPipAudit(projectDir: string, resultsDir: string): number | null {\n  if (!existsSync(`${projectDir}/requirements.txt`) && !existsSync(`${projectDir}/pyproject.toml`)) {\n    return null;\n  }\n\n  try {\n    execSync('which pip-audit', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n  } catch {\n    logHook('security-scan', 'pip-audit not installed, skipping');\n    return null;\n  }\n\n  logHook('security-scan', 'Running pip-audit...');\n  try {\n    const result = execSync('pip-audit --format json', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 120000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    writeFileSync(`${resultsDir}/pip-audit.json`, result);\n    const parsed = JSON.parse(result);\n    logHook('security-scan', 'pip-audit complete');\n    return Array.isArray(parsed) ? parsed.length : 0;\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Run semgrep\n */\nfunction runSemgrep(projectDir: string, resultsDir: string): number | null {\n  try {\n    execSync('which semgrep', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n  } catch {\n    logHook('security-scan', 'semgrep not installed, skipping');\n    return null;\n  }\n\n  logHook('security-scan', 'Running semgrep...');\n  try {\n    const result = execSync('semgrep --config auto --json --quiet', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 300000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    writeFileSync(`${resultsDir}/semgrep.json`, result);\n    const parsed = JSON.parse(result);\n    const highSeverity = (parsed.results || []).filter((r: any) => r.extra?.severity === 'ERROR').length;\n    logHook('security-scan', 'semgrep complete');\n    return highSeverity;\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Run bandit\n */\nfunction runBandit(projectDir: string, resultsDir: string): number | null {\n  // Check for Python files\n  try {\n    const hasPython = execSync('find . -name \"*.py\" -maxdepth 2 | head -1', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    }).trim();\n    if (!hasPython && !existsSync(`${projectDir}/backend`)) {\n      return null;\n    }\n  } catch {\n    return null;\n  }\n\n  try {\n    execSync('which bandit', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n  } catch {\n    logHook('security-scan', 'bandit not installed, skipping');\n    return null;\n  }\n\n  logHook('security-scan', 'Running bandit...');\n  try {\n    execSync(`bandit -r . -f json -o ${resultsDir}/bandit.json`, {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 120000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    logHook('security-scan', 'bandit complete');\n    return 0;\n  } catch {\n    // Bandit exits non-zero when issues found\n    return 0;\n  }\n}\n\n/**\n * Run secret detection\n */\nfunction runSecretScan(projectDir: string, resultsDir: string): number {\n  logHook('security-scan', 'Running secret detection...');\n\n  const secretPatterns = /(api[_-]?key|secret[_-]?key|password|token)\\s*[=:]\\s*[\"'][^\"']{8,}/i;\n  let secretsFound = 0;\n  const findings: Array<{ file: string; type: string }> = [];\n\n  const extensions = ['.py', '.js', '.ts', '.env'];\n\n  function scanDir(dir: string): void {\n    try {\n      const entries = readdirSync(dir, { withFileTypes: true });\n      for (const entry of entries) {\n        const fullPath = `${dir}/${entry.name}`;\n\n        // Skip node_modules and .git\n        if (entry.isDirectory()) {\n          if (!['node_modules', '.git', 'dist', 'build'].includes(entry.name)) {\n            scanDir(fullPath);\n          }\n          continue;\n        }\n\n        // Check file extension\n        if (!extensions.some((ext) => entry.name.endsWith(ext))) {\n          continue;\n        }\n\n        try {\n          const content = readFileSync(fullPath, 'utf-8');\n          if (secretPatterns.test(content)) {\n            findings.push({ file: fullPath, type: 'potential_secret' });\n            secretsFound++;\n          }\n        } catch {\n          // Ignore read errors\n        }\n      }\n    } catch {\n      // Ignore directory errors\n    }\n  }\n\n  scanDir(projectDir);\n\n  writeFileSync(\n    `${resultsDir}/secrets.json`,\n    JSON.stringify({ findings, count: secretsFound }, null, 2)\n  );\n\n  logHook('security-scan', `Secret detection complete: ${secretsFound} potential issues`);\n  return secretsFound;\n}\n\n/**\n * Aggregate results\n */\nfunction aggregateResults(resultsDir: string, results: SecurityResults): void {\n  logHook('security-scan', 'Aggregating results...');\n\n  let totalCritical = 0;\n  let totalHigh = 0;\n\n  if (results.npmAudit) {\n    totalCritical += results.npmAudit.critical;\n    totalHigh += results.npmAudit.high;\n  }\n  if (results.pipAudit !== null) {\n    totalHigh += results.pipAudit;\n  }\n  if (results.semgrep !== null) {\n    totalHigh += results.semgrep;\n  }\n\n  const scansCompleted = readdirSync(resultsDir)\n    .filter((f) => f.endsWith('.json') && !f.includes('aggregated'))\n    .map((f) => f.replace('.json', ''));\n\n  const report = {\n    timestamp: new Date().toISOString(),\n    summary: {\n      critical: totalCritical,\n      high: totalHigh,\n      medium: 0,\n    },\n    scans_completed: scansCompleted,\n  };\n\n  writeFileSync(`${resultsDir}/aggregated-report.json`, JSON.stringify(report, null, 2));\n\n  logHook('security-scan', '=== Security Scan Complete ===');\n  logHook('security-scan', `Critical: ${totalCritical}, High: ${totalHigh}`);\n\n  if (totalCritical > 0) {\n    console.error(`Security: ${totalCritical} critical, ${totalHigh} high vulnerabilities found`);\n  }\n}\n\n/**\n * Security scan aggregator hook\n */\nexport function securityScanAggregator(input: HookInput): HookResult {\n  logHook('security-scan', '=== Security Scan Started ===');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const resultsDir = `${projectDir}/.claude/hooks/logs/security`;\n\n  mkdirSync(resultsDir, { recursive: true });\n\n  const results: SecurityResults = {\n    npmAudit: null,\n    pipAudit: null,\n    semgrep: null,\n    bandit: null,\n    secrets: 0,\n  };\n\n  // Run scans (sequentially in TS to avoid complexity, but could be parallelized)\n  results.npmAudit = runNpmAudit(projectDir, resultsDir);\n  results.pipAudit = runPipAudit(projectDir, resultsDir);\n  results.semgrep = runSemgrep(projectDir, resultsDir);\n  results.bandit = runBandit(projectDir, resultsDir);\n  results.secrets = runSecretScan(projectDir, resultsDir);\n\n  // Aggregate results\n  aggregateResults(resultsDir, results);\n\n  return outputSilentSuccess();\n}\n", "/**\n * Session Patterns - Unified pattern learning at session end\n * Part of OrchestKit Plugin - Cross-Project Patterns (#48) + Best Practices (#49)\n *\n * This hook processes patterns at session end:\n * 1. Extracts workflow patterns (tool sequences, workflow types, languages)\n * 2. Merges queued patterns into learned-patterns.json\n * 3. Syncs to mem0 for cross-project learning\n * 4. Updates workflow profile for session analytics\n *\n * CC 2.1.7 Compliant: Uses suppressOutput for silent operation\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\nimport { loadSessionEvents } from '../lib/session-tracker.js';\nimport { getToolCategory } from '../lib/tool-categories.js';\n\ninterface WorkflowProfile {\n  version: string;\n  last_updated: string | null;\n  sessions_count: number;\n  workflow_types: Record<string, number>;\n  common_tool_sequences: string[];\n  dominant_languages: Record<string, number>;\n  average_tools_per_session: number;\n  average_session_duration_seconds: number;\n  tool_frequency: Record<string, number>;\n}\n\ninterface LearnedPatterns {\n  version: string;\n  updated: string;\n  patterns: Array<{\n    text: string;\n    outcome: string;\n    category: string;\n    timestamp: string;\n  }>;\n  categories: Record<string, number>;\n  stats: {\n    total: number;\n    successes: number;\n    failures: number;\n  };\n}\n\ninterface SessionMetrics {\n  tools?: Record<string, number>;\n}\n\n/**\n * Extract tool usage sequence from session metrics\n */\nfunction extractToolSequence(metricsFile: string): string {\n  if (!existsSync(metricsFile)) {\n    return '';\n  }\n\n  try {\n    const metrics: SessionMetrics = JSON.parse(readFileSync(metricsFile, 'utf-8'));\n    const tools = metrics.tools || {};\n    const sorted = Object.entries(tools)\n      .sort(([, a], [, b]) => b - a)\n      .slice(0, 10)\n      .map(([tool]) => tool);\n    return sorted.join(',');\n  } catch {\n    return '';\n  }\n}\n\n/**\n * Get total tool invocations from metrics\n */\nfunction getToolCount(metricsFile: string): number {\n  if (!existsSync(metricsFile)) {\n    return 0;\n  }\n\n  try {\n    const metrics: SessionMetrics = JSON.parse(readFileSync(metricsFile, 'utf-8'));\n    const tools = metrics.tools || {};\n    return Object.values(tools).reduce((sum, count) => sum + count, 0);\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Detect workflow type based on tool usage patterns\n */\nfunction detectWorkflowType(tools: string): string {\n  if (tools.includes('Write') && tools.includes('Bash')) {\n    if (/test|pytest|jest|vitest/i.test(tools)) {\n      return 'test-driven-development';\n    }\n  }\n\n  if (tools.includes('Read') && tools.includes('Grep')) {\n    return 'code-exploration';\n  }\n\n  if (tools.includes('Edit') && !tools.includes('Write')) {\n    return 'refactoring';\n  }\n\n  if (tools.includes('Write') && tools.includes('Read')) {\n    return 'feature-development';\n  }\n\n  if (tools.includes('Bash') && /git|gh/i.test(tools)) {\n    return 'git-operations';\n  }\n\n  return 'general';\n}\n\n/**\n * Detect dominant language from tool sequence (simplified)\n */\nfunction detectDominantLanguage(tools: string): string {\n  // In a real implementation, this would analyze file extensions from hook logs\n  // For now, return 'unknown' as we don't have file access patterns in TS\n  return 'unknown';\n}\n\n/**\n * Initialize workflow profile if needed\n */\nfunction initWorkflowProfile(profilePath: string): WorkflowProfile {\n  if (existsSync(profilePath)) {\n    try {\n      return JSON.parse(readFileSync(profilePath, 'utf-8'));\n    } catch {\n      // Fall through to create new\n    }\n  }\n\n  return {\n    version: '1.0.0',\n    last_updated: null,\n    sessions_count: 0,\n    workflow_types: {\n      'test-driven-development': 0,\n      'code-exploration': 0,\n      refactoring: 0,\n      'feature-development': 0,\n      'git-operations': 0,\n      general: 0,\n    },\n    common_tool_sequences: [],\n    dominant_languages: {\n      python: 0,\n      typescript: 0,\n      javascript: 0,\n      go: 0,\n      rust: 0,\n      unknown: 0,\n    },\n    average_tools_per_session: 0,\n    average_session_duration_seconds: 0,\n    tool_frequency: {},\n  };\n}\n\n/**\n * Update workflow profile with session data\n */\nfunction updateWorkflowProfile(\n  profilePath: string,\n  workflowType: string,\n  dominantLang: string,\n  toolCount: number,\n  toolSequence: string\n): void {\n  const profile = initWorkflowProfile(profilePath);\n  const timestamp = new Date().toISOString();\n\n  profile.last_updated = timestamp;\n  profile.sessions_count += 1;\n\n  // Update workflow type counts\n  profile.workflow_types[workflowType] = (profile.workflow_types[workflowType] || 0) + 1;\n\n  // Update dominant language counts\n  profile.dominant_languages[dominantLang] = (profile.dominant_languages[dominantLang] || 0) + 1;\n\n  // Update running averages\n  profile.average_tools_per_session =\n    (profile.average_tools_per_session * (profile.sessions_count - 1) + toolCount) / profile.sessions_count;\n\n  // Add tool sequence if meaningful\n  const sequenceTools = toolSequence.split(',').filter(Boolean);\n  if (sequenceTools.length > 2) {\n    const seqSet = new Set([toolSequence, ...profile.common_tool_sequences]);\n    profile.common_tool_sequences = Array.from(seqSet).slice(0, 20);\n  }\n\n  mkdirSync(profilePath.replace(/\\/[^/]+$/, ''), { recursive: true });\n  writeFileSync(profilePath, JSON.stringify(profile, null, 2));\n}\n\n/**\n * Initialize learned patterns file if needed\n */\nfunction initPatternsFile(patternsPath: string): LearnedPatterns {\n  if (existsSync(patternsPath)) {\n    try {\n      return JSON.parse(readFileSync(patternsPath, 'utf-8'));\n    } catch {\n      // Fall through to create new\n    }\n  }\n\n  return {\n    version: '1.0',\n    updated: '',\n    patterns: [],\n    categories: {},\n    stats: {\n      total: 0,\n      successes: 0,\n      failures: 0,\n    },\n  };\n}\n\n/**\n * Aggregate tool usage by category from session events\n * Issue #245 Phase 4: Tool Usage Tracking\n *\n * @returns Object with:\n *   - usageByCategory: { category: { tool: count } }\n *   - preferences: { category: preferredTool }\n */\nfunction aggregateToolPreferences(): {\n  usageByCategory: Record<string, Record<string, number>>;\n  preferences: Record<string, string>;\n} {\n  const usageByCategory: Record<string, Record<string, number>> = {};\n\n  try {\n    const events = loadSessionEvents();\n    const toolEvents = events.filter(e => e.event_type === 'tool_used');\n\n    for (const event of toolEvents) {\n      const toolName = event.payload.name;\n      // Get category from event payload if present, otherwise derive it\n      const category = (event.payload.input as Record<string, unknown>)?.category as string\n        || getToolCategory(toolName);\n\n      if (!usageByCategory[category]) {\n        usageByCategory[category] = {};\n      }\n      usageByCategory[category][toolName] = (usageByCategory[category][toolName] || 0) + 1;\n    }\n  } catch {\n    // Ignore errors, return empty\n  }\n\n  // Calculate preferred tool per category (most used)\n  const preferences: Record<string, string> = {};\n  for (const [category, tools] of Object.entries(usageByCategory)) {\n    const sorted = Object.entries(tools).sort(([, a], [, b]) => b - a);\n    if (sorted.length > 0) {\n      preferences[category] = sorted[0][0];\n    }\n  }\n\n  return { usageByCategory, preferences };\n}\n\n/**\n * Update workflow profile with tool preferences\n */\nfunction updateToolPreferences(projectDir: string): void {\n  const { usageByCategory, preferences } = aggregateToolPreferences();\n\n  if (Object.keys(preferences).length === 0) {\n    logHook('session-patterns', 'No tool usage to aggregate');\n    return;\n  }\n\n  // Store in a separate tool-preferences file for easy access\n  const prefsPath = `${projectDir}/.claude/feedback/tool-preferences.json`;\n\n  let existingPrefs: {\n    version: string;\n    updated: string;\n    usage_by_category: Record<string, Record<string, number>>;\n    preferences: Record<string, string>;\n    sessions_aggregated: number;\n  } = {\n    version: '1.0.0',\n    updated: '',\n    usage_by_category: {},\n    preferences: {},\n    sessions_aggregated: 0,\n  };\n\n  // Load existing if present\n  if (existsSync(prefsPath)) {\n    try {\n      existingPrefs = JSON.parse(readFileSync(prefsPath, 'utf-8'));\n    } catch {\n      // Use default\n    }\n  }\n\n  // Merge category usage (accumulate counts)\n  for (const [category, tools] of Object.entries(usageByCategory)) {\n    if (!existingPrefs.usage_by_category[category]) {\n      existingPrefs.usage_by_category[category] = {};\n    }\n    for (const [tool, count] of Object.entries(tools)) {\n      existingPrefs.usage_by_category[category][tool] =\n        (existingPrefs.usage_by_category[category][tool] || 0) + count;\n    }\n  }\n\n  // Recalculate preferences from accumulated data\n  for (const [category, tools] of Object.entries(existingPrefs.usage_by_category)) {\n    const sorted = Object.entries(tools).sort(([, a], [, b]) => b - a);\n    if (sorted.length > 0) {\n      existingPrefs.preferences[category] = sorted[0][0];\n    }\n  }\n\n  existingPrefs.updated = new Date().toISOString();\n  existingPrefs.sessions_aggregated += 1;\n\n  mkdirSync(`${projectDir}/.claude/feedback`, { recursive: true });\n  writeFileSync(prefsPath, JSON.stringify(existingPrefs, null, 2));\n\n  const prefCount = Object.keys(existingPrefs.preferences).length;\n  logHook('session-patterns', `Updated tool preferences: ${prefCount} categories`);\n}\n\n/**\n * Merge queued patterns into learned patterns file\n */\nfunction mergePatterns(projectDir: string): void {\n  const queuePath = `${projectDir}/.claude/feedback/patterns-queue.json`;\n  const patternsPath = `${projectDir}/.claude/feedback/learned-patterns.json`;\n\n  if (!existsSync(queuePath)) {\n    logHook('session-patterns', 'No patterns queue found');\n    return;\n  }\n\n  let queue: { patterns: LearnedPatterns['patterns'] };\n  try {\n    queue = JSON.parse(readFileSync(queuePath, 'utf-8'));\n  } catch {\n    logHook('session-patterns', 'Failed to parse patterns queue');\n    return;\n  }\n\n  const queueCount = queue.patterns?.length || 0;\n  if (queueCount === 0) {\n    logHook('session-patterns', 'Patterns queue is empty');\n    return;\n  }\n\n  logHook('session-patterns', `Processing ${queueCount} queued patterns...`);\n\n  const existing = initPatternsFile(patternsPath);\n  const now = new Date().toISOString();\n\n  // Merge and deduplicate patterns by text (keep most recent)\n  const allPatterns = [...existing.patterns, ...queue.patterns];\n  const patternMap = new Map<string, (typeof allPatterns)[0]>();\n  for (const p of allPatterns) {\n    patternMap.set(p.text, p);\n  }\n  const mergedPatterns = Array.from(patternMap.values());\n\n  // Calculate stats\n  const successes = mergedPatterns.filter((p) => p.outcome === 'success').length;\n  const failures = mergedPatterns.filter((p) => p.outcome === 'failed').length;\n\n  // Group by category\n  const categories: Record<string, number> = {};\n  for (const p of mergedPatterns) {\n    categories[p.category] = (categories[p.category] || 0) + 1;\n  }\n\n  const updated: LearnedPatterns = {\n    version: '1.0',\n    updated: now,\n    patterns: mergedPatterns,\n    categories,\n    stats: {\n      total: mergedPatterns.length,\n      successes,\n      failures,\n    },\n  };\n\n  mkdirSync(patternsPath.replace(/\\/[^/]+$/, ''), { recursive: true });\n  writeFileSync(patternsPath, JSON.stringify(updated, null, 2));\n  logHook('session-patterns', 'Merged patterns successfully');\n\n  // Clear the queue\n  writeFileSync(queuePath, JSON.stringify({ patterns: [] }));\n}\n\n/**\n * Session patterns hook\n */\nexport function sessionPatterns(input: HookInput): HookResult {\n  logHook('session-patterns', 'Session ending, processing patterns...');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const metricsFile = '/tmp/claude-session-metrics.json';\n  const workflowProfile = `${projectDir}/.claude/feedback/workflow-patterns.json`;\n\n  // Ensure directories exist\n  mkdirSync(`${projectDir}/.claude/feedback`, { recursive: true });\n  mkdirSync(`${projectDir}/.claude/logs`, { recursive: true });\n\n  // 1. Process workflow patterns\n  const toolCount = getToolCount(metricsFile);\n\n  if (toolCount >= 5) {\n    const toolSequence = extractToolSequence(metricsFile);\n    const workflowType = detectWorkflowType(toolSequence);\n    const dominantLang = detectDominantLanguage(toolSequence);\n\n    updateWorkflowProfile(workflowProfile, workflowType, dominantLang, toolCount, toolSequence);\n\n    logHook('session-patterns', `Workflow analyzed: type=${workflowType} lang=${dominantLang} tools=${toolCount}`);\n  } else {\n    logHook('session-patterns', `Session too short for workflow analysis (tools: ${toolCount})`);\n  }\n\n  // 2. Aggregate tool preferences by category (Phase 4)\n  updateToolPreferences(projectDir);\n\n  // 3. Merge queued patterns\n  mergePatterns(projectDir);\n\n  logHook('session-patterns', 'Pattern processing complete');\n\n  return outputSilentSuccess();\n}\n", "/**\n * Session Event Tracker\n * Logs all session events (skills, agents, hooks, decisions) with user identity.\n *\n * Events are stored per-session in JSONL format for later aggregation.\n * This enables learning user patterns across sessions.\n *\n * Storage: .claude/memory/sessions/{session_id}/events.jsonl\n */\n\nimport { existsSync, appendFileSync, mkdirSync, readFileSync } from 'node:fs';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport { getIdentityContext, type IdentityContext } from './user-identity.js';\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * Event types that can be tracked\n */\nexport type SessionEventType =\n  | 'skill_invoked'\n  | 'agent_spawned'\n  | 'hook_triggered'\n  | 'decision_made'\n  | 'preference_stated'\n  | 'problem_reported'\n  | 'solution_found'\n  | 'tool_used'\n  | 'session_start'\n  | 'session_end'\n  | 'communication_style_detected';\n\n/**\n * A single session event\n */\nexport interface SessionEvent {\n  /** Unique event ID */\n  event_id: string;\n  /** Event type */\n  event_type: SessionEventType;\n  /** Identity context (user, session, machine) */\n  identity: IdentityContext;\n  /** Event-specific payload */\n  payload: {\n    /** Name of skill/agent/hook/tool */\n    name: string;\n    /** Input data (optional, may be truncated for privacy) */\n    input?: Record<string, unknown>;\n    /** Output/result (optional, may be truncated) */\n    output?: Record<string, unknown>;\n    /** Duration in milliseconds */\n    duration_ms?: number;\n    /** Whether the event succeeded */\n    success: boolean;\n    /** Additional context */\n    context?: string;\n    /** Confidence score (for decisions) */\n    confidence?: number;\n  };\n}\n\n/**\n * Session summary (aggregated at session end)\n */\nexport interface SessionSummary {\n  session_id: string;\n  user_id: string;\n  anonymous_id: string;\n  team_id?: string;\n  start_time?: string;\n  end_time?: string;\n  duration_ms?: number;\n  event_counts: Record<SessionEventType, number>;\n  skills_used: string[];\n  agents_spawned: string[];\n  hooks_triggered: string[];\n  decisions_made: number;\n  problems_reported: number;\n  solutions_found: number;\n}\n\n// =============================================================================\n// PATHS\n// =============================================================================\n\n/** Session ID validation regex - alphanumeric, dashes, underscores only (SEC-002) */\nconst SESSION_ID_PATTERN = /^[a-zA-Z0-9_-]{1,128}$/;\n\n/**\n * Validate session ID to prevent path traversal attacks.\n * Defense-in-depth: trusted sources, but we validate at boundary anyway.\n */\nfunction isValidSessionId(sessionId: string): boolean {\n  return SESSION_ID_PATTERN.test(sessionId);\n}\n\n/**\n * Get session storage directory\n * @param sessionId - Optional session ID (defaults to env var)\n * @param projectDir - Optional project directory (defaults to env var)\n */\nfunction getSessionDir(sessionId?: string, projectDir?: string): string {\n  const sid = sessionId || getSessionId();\n  const pDir = projectDir || getProjectDir();\n  // Validate session ID to prevent path traversal (SEC-002)\n  if (!isValidSessionId(sid)) {\n    throw new Error(`Invalid session ID format`);\n  }\n  return `${pDir}/.claude/memory/sessions/${sid}`;\n}\n\n/**\n * Get events file path for a session\n */\nfunction getEventsPath(sessionId?: string, projectDir?: string): string {\n  return `${getSessionDir(sessionId, projectDir)}/events.jsonl`;\n}\n\n/**\n * Ensure session directory exists\n */\nfunction ensureSessionDir(sessionId?: string, projectDir?: string): void {\n  const dir = getSessionDir(sessionId, projectDir);\n  if (!existsSync(dir)) {\n    mkdirSync(dir, { recursive: true });\n  }\n}\n\n// =============================================================================\n// EVENT GENERATION\n// =============================================================================\n\nlet eventCounter = 0;\n\n/**\n * Generate unique event ID\n */\nfunction generateEventId(): string {\n  eventCounter++;\n  return `evt-${Date.now()}-${eventCounter}`;\n}\n\n// =============================================================================\n// EVENT TRACKING\n// =============================================================================\n\n/**\n * Track a session event\n *\n * @param eventType - Type of event\n * @param name - Name of skill/agent/hook/tool\n * @param options - Additional event options\n */\nexport function trackEvent(\n  eventType: SessionEventType,\n  name: string,\n  options: {\n    input?: Record<string, unknown>;\n    output?: Record<string, unknown>;\n    duration_ms?: number;\n    success?: boolean;\n    context?: string;\n    confidence?: number;\n  } = {}\n): void {\n  try {\n    const event: SessionEvent = {\n      event_id: generateEventId(),\n      event_type: eventType,\n      identity: getIdentityContext(),\n      payload: {\n        name,\n        input: sanitizeForStorage(options.input),\n        output: sanitizeForStorage(options.output),\n        duration_ms: options.duration_ms,\n        success: options.success ?? true,\n        context: options.context ? truncate(options.context, 500) : undefined,\n        confidence: options.confidence,\n      },\n    };\n\n    ensureSessionDir();\n    const eventsPath = getEventsPath();\n    appendFileSync(eventsPath, JSON.stringify(event) + '\\n');\n\n    logHook('session-tracker', `Tracked ${eventType}: ${name}`, 'debug');\n  } catch (error) {\n    logHook('session-tracker', `Failed to track event: ${error}`, 'warn');\n  }\n}\n\n/**\n * Track skill invocation\n */\nexport function trackSkillInvoked(\n  skillName: string,\n  args?: string,\n  success: boolean = true,\n  durationMs?: number\n): void {\n  trackEvent('skill_invoked', skillName, {\n    input: args ? { args } : undefined,\n    success,\n    duration_ms: durationMs,\n  });\n}\n\n/**\n * Track agent spawn\n */\nexport function trackAgentSpawned(\n  agentType: string,\n  prompt?: string,\n  success: boolean = true\n): void {\n  trackEvent('agent_spawned', agentType, {\n    input: prompt ? { prompt: truncate(prompt, 200) } : undefined,\n    success,\n  });\n}\n\n/**\n * Track hook triggered\n */\nexport function trackHookTriggered(\n  hookName: string,\n  success: boolean = true,\n  durationMs?: number\n): void {\n  trackEvent('hook_triggered', hookName, {\n    success,\n    duration_ms: durationMs,\n  });\n}\n\n/**\n * Track decision made\n */\nexport function trackDecisionMade(\n  decision: string,\n  rationale?: string,\n  confidence?: number\n): void {\n  trackEvent('decision_made', 'decision', {\n    context: decision,\n    input: rationale ? { rationale } : undefined,\n    confidence,\n    success: true,\n  });\n}\n\n/**\n * Track preference stated\n */\nexport function trackPreferenceStated(\n  preference: string,\n  confidence?: number\n): void {\n  trackEvent('preference_stated', 'preference', {\n    context: preference,\n    confidence,\n    success: true,\n  });\n}\n\n/**\n * Track problem reported\n */\nexport function trackProblemReported(problem: string): void {\n  trackEvent('problem_reported', 'problem', {\n    context: problem,\n    success: true,\n  });\n}\n\n/**\n * Track solution found\n */\nexport function trackSolutionFound(\n  solution: string,\n  problemId?: string,\n  confidence?: number\n): void {\n  trackEvent('solution_found', 'solution', {\n    context: solution,\n    input: problemId ? { problem_id: problemId } : undefined,\n    confidence,\n    success: true,\n  });\n}\n\n/**\n * Track tool usage\n *\n * @param toolName - Name of the tool (e.g., 'Grep', 'Read')\n * @param success - Whether the tool call succeeded\n * @param durationMs - Duration of the tool call in milliseconds\n * @param category - Tool category (e.g., 'search', 'file_read') for preference tracking\n */\nexport function trackToolUsed(\n  toolName: string,\n  success: boolean = true,\n  durationMs?: number,\n  category?: string\n): void {\n  trackEvent('tool_used', toolName, {\n    success,\n    duration_ms: durationMs,\n    input: category ? { category } : undefined,\n  });\n}\n\n/**\n * Session context captured at session start\n * Issue #245 Phase 5: Session Lifecycle Tracking\n */\nexport interface SessionContext {\n  /** Project directory path */\n  project_dir?: string;\n  /** Current git branch */\n  git_branch?: string;\n  /** Time of day category */\n  time_of_day?: 'morning' | 'afternoon' | 'evening' | 'night';\n  /** Timestamp */\n  started_at: string;\n}\n\n/**\n * Get time of day category from hour\n */\nfunction getTimeOfDay(hour: number): 'morning' | 'afternoon' | 'evening' | 'night' {\n  if (hour >= 5 && hour < 12) return 'morning';\n  if (hour >= 12 && hour < 17) return 'afternoon';\n  if (hour >= 17 && hour < 21) return 'evening';\n  return 'night';\n}\n\n/**\n * Track session start with context\n * Issue #245 Phase 5: Session Lifecycle Tracking\n *\n * @param context - Optional session context (project, branch, time)\n */\nexport function trackSessionStart(context?: Partial<SessionContext>): void {\n  const now = new Date();\n  const sessionContext: SessionContext = {\n    project_dir: context?.project_dir,\n    git_branch: context?.git_branch,\n    time_of_day: context?.time_of_day || getTimeOfDay(now.getHours()),\n    started_at: now.toISOString(),\n  };\n\n  trackEvent('session_start', 'session', {\n    success: true,\n    input: sessionContext as unknown as Record<string, unknown>,\n  });\n}\n\n/**\n * Track session end with timestamp\n * Issue #245 Phase 5: Session Lifecycle Tracking\n */\nexport function trackSessionEnd(): void {\n  trackEvent('session_end', 'session', {\n    success: true,\n    input: { ended_at: new Date().toISOString() },\n  });\n}\n\n/**\n * Track user communication style\n */\nexport function trackCommunicationStyle(\n  style: {\n    verbosity: 'terse' | 'moderate' | 'detailed';\n    interaction_type: 'question' | 'command' | 'discussion';\n    technical_level: 'beginner' | 'intermediate' | 'expert';\n  }\n): void {\n  trackEvent('communication_style_detected', 'communication', {\n    input: style as unknown as Record<string, unknown>,\n    success: true,\n  });\n}\n\n\n// =============================================================================\n// SESSION SUMMARY\n// =============================================================================\n\n/**\n * Load all events for a session\n */\nexport function loadSessionEvents(sessionId?: string): SessionEvent[] {\n  const eventsPath = getEventsPath(sessionId);\n\n  if (!existsSync(eventsPath)) {\n    return [];\n  }\n\n  try {\n    const content = readFileSync(eventsPath, 'utf8');\n    const lines = content.trim().split('\\n').filter(Boolean);\n    return lines.map(line => JSON.parse(line));\n  } catch (error) {\n    logHook('session-tracker', `Failed to load session events: ${error}`, 'warn');\n    return [];\n  }\n}\n\n/**\n * Generate session summary from events\n */\nexport function generateSessionSummary(sessionId?: string): SessionSummary {\n  const events = loadSessionEvents(sessionId);\n  const identity = getIdentityContext();\n\n  const eventCounts: Record<SessionEventType, number> = {\n    skill_invoked: 0,\n    agent_spawned: 0,\n    hook_triggered: 0,\n    decision_made: 0,\n    preference_stated: 0,\n    problem_reported: 0,\n    solution_found: 0,\n    tool_used: 0,\n    session_start: 0,\n    session_end: 0,\n    communication_style_detected: 0,\n  };\n\n  const skillsUsed = new Set<string>();\n  const agentsSpawned = new Set<string>();\n  const hooksTriggered = new Set<string>();\n\n  let startTime: string | undefined;\n  let endTime: string | undefined;\n\n  for (const event of events) {\n    eventCounts[event.event_type]++;\n\n    switch (event.event_type) {\n      case 'skill_invoked':\n        skillsUsed.add(event.payload.name);\n        break;\n      case 'agent_spawned':\n        agentsSpawned.add(event.payload.name);\n        break;\n      case 'hook_triggered':\n        hooksTriggered.add(event.payload.name);\n        break;\n      case 'session_start':\n        startTime = event.identity.timestamp;\n        break;\n      case 'session_end':\n        endTime = event.identity.timestamp;\n        break;\n    }\n  }\n\n  const durationMs =\n    startTime && endTime\n      ? new Date(endTime).getTime() - new Date(startTime).getTime()\n      : undefined;\n\n  return {\n    session_id: sessionId || identity.session_id,\n    user_id: identity.user_id,\n    anonymous_id: identity.anonymous_id,\n    team_id: identity.team_id,\n    start_time: startTime,\n    end_time: endTime,\n    duration_ms: durationMs,\n    event_counts: eventCounts,\n    skills_used: [...skillsUsed],\n    agents_spawned: [...agentsSpawned],\n    hooks_triggered: [...hooksTriggered],\n    decisions_made: eventCounts.decision_made,\n    problems_reported: eventCounts.problem_reported,\n    solutions_found: eventCounts.solution_found,\n  };\n}\n\n// =============================================================================\n// CROSS-SESSION QUERIES\n// =============================================================================\n// GAP-008/009 FIX: Removed listSessionIds() and getRecentUserSessions()\n// These functions were exported but never called by production code.\n// Cross-session queries should be handled by profile-injector if needed.\n// =============================================================================\n\n// =============================================================================\n// UTILITIES\n// =============================================================================\n\n/**\n * Truncate string to max length\n */\nfunction truncate(str: string, maxLen: number): string {\n  if (str.length <= maxLen) return str;\n  return str.slice(0, maxLen - 3) + '...';\n}\n\n/**\n * Sanitize object for storage (remove sensitive data, truncate)\n */\nfunction sanitizeForStorage(\n  obj: Record<string, unknown> | undefined\n): Record<string, unknown> | undefined {\n  if (!obj) return undefined;\n\n  const sanitized: Record<string, unknown> = {};\n  const sensitiveKeys = ['password', 'secret', 'token', 'key', 'credential', 'auth'];\n\n  for (const [key, value] of Object.entries(obj)) {\n    // Skip sensitive keys\n    if (sensitiveKeys.some(s => key.toLowerCase().includes(s))) {\n      sanitized[key] = '[REDACTED]';\n      continue;\n    }\n\n    // Truncate long strings\n    if (typeof value === 'string' && value.length > 500) {\n      sanitized[key] = truncate(value, 500);\n      continue;\n    }\n\n    // Recursively sanitize objects\n    if (typeof value === 'object' && value !== null && !Array.isArray(value)) {\n      sanitized[key] = sanitizeForStorage(value as Record<string, unknown>);\n      continue;\n    }\n\n    sanitized[key] = value;\n  }\n\n  return sanitized;\n}\n", "/**\n * User Identity System\n * Resolves and manages user identity across sessions for multi-user decision capture.\n *\n * Identity Resolution Order:\n * 1. Explicit config (.claude/.user_identity.json)\n * 2. Git config (user.email, user.name)\n * 3. Environment variables (USER, USERNAME)\n * 4. Anonymous (machine-based hash)\n *\n * Privacy: User controls what gets shared via privacy settings.\n * Storage: User profiles stored locally in .claude/memory/users/\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport { createHash } from 'node:crypto';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport * as os from 'node:os';\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * User identity source - where the identity was resolved from\n */\nexport type IdentitySource = 'config' | 'git' | 'env' | 'anonymous';\n\n/**\n * Resolved user identity\n */\nexport interface UserIdentity {\n  /** Unique user identifier (email, username, or anonymous hash) */\n  user_id: string;\n  /** Human-readable display name */\n  display_name: string;\n  /** Optional team/org identifier */\n  team_id?: string;\n  /** Machine identifier (hostname) */\n  machine_id: string;\n  /** How the identity was resolved */\n  source: IdentitySource;\n  /** Anonymous hash for global sharing (privacy-preserving) */\n  anonymous_id: string;\n  /** Email if available */\n  email?: string;\n}\n\n/**\n * User privacy settings - controls what gets shared\n */\nexport interface PrivacySettings {\n  /** Share patterns with team (same project) */\n  share_with_team: boolean;\n  /** Share patterns globally (anonymized) */\n  share_globally: boolean;\n  /** Share decisions */\n  share_decisions: boolean;\n  /** Share preferences */\n  share_preferences: boolean;\n  /** Share skill usage statistics */\n  share_skill_usage: boolean;\n  /** Share prompt content (usually false for privacy) */\n  share_prompts: boolean;\n  /** Anonymize user_id when sharing globally */\n  anonymize_globally: boolean;\n}\n\n/**\n * User identity configuration file format\n */\nexport interface UserIdentityConfig {\n  /** Explicit user ID */\n  user_id?: string;\n  /** Display name */\n  display_name?: string;\n  /** Team identifier */\n  team_id?: string;\n  /** Privacy settings */\n  privacy?: Partial<PrivacySettings>;\n}\n\n// =============================================================================\n// CONSTANTS\n// =============================================================================\n\nconst IDENTITY_CONFIG_FILE = '.claude/.user_identity.json';\nconst SALT = 'orchestkit-user-identity-v1';\n\n/** Default privacy settings (conservative) */\nconst DEFAULT_PRIVACY: PrivacySettings = {\n  share_with_team: true,\n  share_globally: false, // Opt-in\n  share_decisions: true,\n  share_preferences: true,\n  share_skill_usage: false, // Might reveal workflow\n  share_prompts: false, // Privacy sensitive\n  anonymize_globally: true,\n};\n\n// =============================================================================\n// CACHING\n// =============================================================================\n\nlet cachedIdentity: UserIdentity | null = null;\nlet cachedPrivacy: PrivacySettings | null = null;\n\n/**\n * Clear cached identity (for testing)\n */\nexport function clearIdentityCache(): void {\n  cachedIdentity = null;\n  cachedPrivacy = null;\n}\n\n// =============================================================================\n// IDENTITY RESOLUTION\n// =============================================================================\n\n/**\n * Generate anonymous hash from input\n */\nfunction generateAnonymousId(input: string): string {\n  return createHash('sha256')\n    .update(input + SALT)\n    .digest('hex')\n    .slice(0, 16);\n}\n\n/**\n * Get machine identifier\n */\nfunction getMachineId(): string {\n  try {\n    return os.hostname();\n  } catch {\n    return 'unknown-machine';\n  }\n}\n\n/**\n * Try to read explicit user config\n */\nfunction readUserConfig(projectDir: string): UserIdentityConfig | null {\n  const configPath = `${projectDir}/${IDENTITY_CONFIG_FILE}`;\n\n  if (!existsSync(configPath)) {\n    return null;\n  }\n\n  try {\n    const content = readFileSync(configPath, 'utf8');\n    return JSON.parse(content);\n  } catch (error) {\n    logHook('user-identity', `Failed to read user config: ${error}`, 'warn');\n    return null;\n  }\n}\n\n/**\n * Try to get identity from git config\n */\nfunction getGitIdentity(projectDir: string): { email?: string; name?: string } {\n  const result: { email?: string; name?: string } = {};\n\n  try {\n    result.email = execSync('git config user.email', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 2000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    }).trim();\n  } catch {\n    // Git email not configured\n  }\n\n  try {\n    result.name = execSync('git config user.name', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 2000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    }).trim();\n  } catch {\n    // Git name not configured\n  }\n\n  return result;\n}\n\n/**\n * Get identity from environment variables\n */\nfunction getEnvIdentity(): { username?: string } {\n  const username = process.env.USER || process.env.USERNAME || process.env.LOGNAME;\n  return { username };\n}\n\n/**\n * Resolve user identity using fallback chain\n *\n * Resolution order:\n * 1. Explicit config file\n * 2. Git config\n * 3. Environment username\n * 4. Anonymous (machine-based)\n */\nexport function resolveUserIdentity(projectDir?: string): UserIdentity {\n  // Return cached if available\n  if (cachedIdentity) {\n    return cachedIdentity;\n  }\n\n  const dir = projectDir || getProjectDir();\n  const machineId = getMachineId();\n\n  // 1. Try explicit config\n  const config = readUserConfig(dir);\n  if (config?.user_id) {\n    cachedIdentity = {\n      user_id: config.user_id,\n      display_name: config.display_name || config.user_id,\n      team_id: config.team_id,\n      machine_id: machineId,\n      source: 'config',\n      anonymous_id: generateAnonymousId(config.user_id),\n      email: config.user_id.includes('@') ? config.user_id : undefined,\n    };\n    logHook('user-identity', `Resolved from config: ${cachedIdentity.user_id}`, 'debug');\n    return cachedIdentity;\n  }\n\n  // 2. Try git config\n  const git = getGitIdentity(dir);\n  if (git.email) {\n    cachedIdentity = {\n      user_id: git.email,\n      display_name: git.name || git.email.split('@')[0],\n      team_id: config?.team_id,\n      machine_id: machineId,\n      source: 'git',\n      anonymous_id: generateAnonymousId(git.email),\n      email: git.email,\n    };\n    logHook('user-identity', `Resolved from git: ${cachedIdentity.user_id}`, 'debug');\n    return cachedIdentity;\n  }\n\n  // 3. Try environment\n  const env = getEnvIdentity();\n  if (env.username) {\n    const userId = `${env.username}@${machineId}`;\n    cachedIdentity = {\n      user_id: userId,\n      display_name: env.username,\n      team_id: config?.team_id,\n      machine_id: machineId,\n      source: 'env',\n      anonymous_id: generateAnonymousId(userId),\n    };\n    logHook('user-identity', `Resolved from env: ${cachedIdentity.user_id}`, 'debug');\n    return cachedIdentity;\n  }\n\n  // 4. Anonymous fallback\n  const anonId = generateAnonymousId(machineId + process.pid);\n  cachedIdentity = {\n    user_id: `anon-${anonId.slice(0, 8)}`,\n    display_name: 'Anonymous',\n    team_id: config?.team_id,\n    machine_id: machineId,\n    source: 'anonymous',\n    anonymous_id: anonId,\n  };\n  logHook('user-identity', `Resolved as anonymous: ${cachedIdentity.user_id}`, 'debug');\n  return cachedIdentity;\n}\n\n// =============================================================================\n// PRIVACY SETTINGS\n// =============================================================================\n\n/**\n * Get user's privacy settings\n */\nexport function getPrivacySettings(projectDir?: string): PrivacySettings {\n  if (cachedPrivacy) {\n    return cachedPrivacy;\n  }\n\n  const dir = projectDir || getProjectDir();\n  const config = readUserConfig(dir);\n\n  cachedPrivacy = {\n    ...DEFAULT_PRIVACY,\n    ...config?.privacy,\n  };\n\n  return cachedPrivacy;\n}\n\n/**\n * Check if user allows sharing a specific type of data\n */\nexport function canShare(\n  dataType: 'decisions' | 'preferences' | 'skill_usage' | 'prompts',\n  scope: 'team' | 'global'\n): boolean {\n  const privacy = getPrivacySettings();\n\n  // Check scope permission first\n  if (scope === 'team' && !privacy.share_with_team) return false;\n  if (scope === 'global' && !privacy.share_globally) return false;\n\n  // Check data type permission\n  switch (dataType) {\n    case 'decisions':\n      return privacy.share_decisions;\n    case 'preferences':\n      return privacy.share_preferences;\n    case 'skill_usage':\n      return privacy.share_skill_usage;\n    case 'prompts':\n      return privacy.share_prompts;\n    default:\n      return false;\n  }\n}\n\n/**\n * Get user ID for sharing (applies anonymization if needed)\n */\nexport function getUserIdForScope(scope: 'local' | 'team' | 'global'): string {\n  const identity = resolveUserIdentity();\n  const privacy = getPrivacySettings();\n\n  if (scope === 'global' && privacy.anonymize_globally) {\n    return identity.anonymous_id;\n  }\n\n  return identity.user_id;\n}\n\n// =============================================================================\n// IDENTITY PERSISTENCE\n// =============================================================================\n\n/**\n * Save user identity config (creates or updates)\n */\nexport function saveUserIdentityConfig(\n  config: UserIdentityConfig,\n  projectDir?: string\n): boolean {\n  const dir = projectDir || getProjectDir();\n  const configPath = `${dir}/${IDENTITY_CONFIG_FILE}`;\n  const configDir = `${dir}/.claude`;\n\n  try {\n    if (!existsSync(configDir)) {\n      mkdirSync(configDir, { recursive: true });\n    }\n\n    writeFileSync(configPath, JSON.stringify(config, null, 2));\n\n    // Clear cache to pick up new config\n    clearIdentityCache();\n\n    logHook('user-identity', `Saved identity config to ${configPath}`, 'info');\n    return true;\n  } catch (error) {\n    logHook('user-identity', `Failed to save identity config: ${error}`, 'error');\n    return false;\n  }\n}\n\n// =============================================================================\n// CONTEXT HELPERS\n// =============================================================================\n\n/**\n * Get full identity context for session events\n */\nexport interface IdentityContext {\n  session_id: string;\n  user_id: string;\n  anonymous_id: string;\n  team_id?: string;\n  machine_id: string;\n  identity_source: IdentitySource;\n  timestamp: string;\n}\n\n/**\n * Get identity context for tagging events\n */\nexport function getIdentityContext(): IdentityContext {\n  const identity = resolveUserIdentity();\n\n  return {\n    session_id: getSessionId(),\n    user_id: identity.user_id,\n    anonymous_id: identity.anonymous_id,\n    team_id: identity.team_id,\n    machine_id: identity.machine_id,\n    identity_source: identity.source,\n    timestamp: new Date().toISOString(),\n  };\n}\n\n/**\n * Get project-scoped user ID for mem0 storage\n * Format: {project}-{scope} (e.g., \"my-app-decisions\")\n */\nexport function getProjectUserId(scope: string): string {\n  const projectDir = getProjectDir();\n  const projectName = projectDir.split('/').pop() || 'unknown';\n  const sanitized = projectName.toLowerCase().replace(/[^a-z0-9-]/g, '-');\n  return `${sanitized}-${scope}`;\n}\n\n/**\n * Get user-scoped ID for mem0 storage\n * Format: {user_id}-{scope} (e.g., \"alice@company.com-preferences\")\n */\nexport function getUserScopedId(scope: string): string {\n  const identity = resolveUserIdentity();\n  const sanitizedUserId = identity.user_id.toLowerCase().replace(/[^a-z0-9@.-]/g, '-');\n  return `${sanitizedUserId}-${scope}`;\n}\n\n/**\n * Get global scope ID (for cross-project best practices)\n */\nexport function getGlobalScopeId(scope: string): string {\n  return `orchestkit-global-${scope}`;\n}\n", "/**\n * Tool Categories\n * Issue #245 Phase 4: Tool Usage Tracking\n *\n * Maps Claude Code tools to semantic categories for:\n * - Usage pattern analysis\n * - Tool preference learning\n * - Workflow detection\n *\n * Categories align with user workflow intentions, not implementation details.\n */\n\n/**\n * Tool category types\n */\nexport type ToolCategory =\n  | 'search'        // Finding files/content: Grep, Glob, WebSearch\n  | 'file_read'     // Reading files: Read\n  | 'file_write'    // Creating files: Write\n  | 'file_edit'     // Modifying files: Edit, MultiEdit, NotebookEdit\n  | 'execution'     // Running commands: Bash\n  | 'agent'         // Spawning agents: Task\n  | 'skill'         // Invoking skills: Skill\n  | 'web'           // Web access: WebFetch, WebSearch\n  | 'interaction'   // User interaction: AskUserQuestion\n  | 'task_mgmt'     // Task management: TaskCreate, TaskUpdate, TaskList, TaskGet\n  | 'other';        // Unknown/uncategorized\n\n/**\n * Static tool \u2192 category mapping\n *\n * This mapping covers all known Claude Code tools as of CC 2.1.22.\n * Unknown tools default to 'other'.\n */\nexport const TOOL_CATEGORIES: Record<string, ToolCategory> = {\n  // Search tools - finding files and content\n  Grep: 'search',\n  Glob: 'search',\n  WebSearch: 'web',\n\n  // File reading\n  Read: 'file_read',\n\n  // File writing (creation)\n  Write: 'file_write',\n\n  // File editing (modification)\n  Edit: 'file_edit',\n  MultiEdit: 'file_edit',\n  NotebookEdit: 'file_edit',\n\n  // Execution\n  Bash: 'execution',\n\n  // Agent/skill invocation\n  Task: 'agent',\n  Skill: 'skill',\n\n  // Web access\n  WebFetch: 'web',\n\n  // User interaction\n  AskUserQuestion: 'interaction',\n\n  // Task management (CC 2.1.16)\n  TaskCreate: 'task_mgmt',\n  TaskUpdate: 'task_mgmt',\n  TaskList: 'task_mgmt',\n  TaskGet: 'task_mgmt',\n  TaskOutput: 'task_mgmt',\n  TaskStop: 'task_mgmt',\n\n  // Planning\n  EnterPlanMode: 'interaction',\n  ExitPlanMode: 'interaction',\n};\n\n/**\n * Get the category for a tool\n *\n * @param toolName - The name of the tool (e.g., 'Grep', 'Read')\n * @returns The tool's category, or 'other' if unknown\n *\n * @example\n * getToolCategory('Grep')  // 'search'\n * getToolCategory('Read')  // 'file_read'\n * getToolCategory('CustomTool')  // 'other'\n */\nexport function getToolCategory(toolName: string): ToolCategory {\n  return TOOL_CATEGORIES[toolName] || 'other';\n}\n\n/**\n * Get all tools in a category\n *\n * @param category - The category to look up\n * @returns Array of tool names in that category\n *\n * @example\n * getToolsInCategory('search')  // ['Grep', 'Glob']\n */\nexport function getToolsInCategory(category: ToolCategory): string[] {\n  return Object.entries(TOOL_CATEGORIES)\n    .filter(([, cat]) => cat === category)\n    .map(([tool]) => tool);\n}\n\n/**\n * Check if two tools are in the same category\n *\n * @param tool1 - First tool name\n * @param tool2 - Second tool name\n * @returns true if both tools are in the same category\n *\n * @example\n * areSameCategory('Grep', 'Glob')  // true (both 'search')\n * areSameCategory('Read', 'Write') // false\n */\nexport function areSameCategory(tool1: string, tool2: string): boolean {\n  return getToolCategory(tool1) === getToolCategory(tool2);\n}\n\n/**\n * Get a human-readable description of a category\n *\n * @param category - The category\n * @returns Description of what tools in this category do\n */\nexport function getCategoryDescription(category: ToolCategory): string {\n  const descriptions: Record<ToolCategory, string> = {\n    search: 'Finding files and content',\n    file_read: 'Reading file contents',\n    file_write: 'Creating new files',\n    file_edit: 'Modifying existing files',\n    execution: 'Running shell commands',\n    agent: 'Spawning specialized agents',\n    skill: 'Invoking skills',\n    web: 'Accessing web resources',\n    interaction: 'User interaction',\n    task_mgmt: 'Managing tasks',\n    other: 'Other operations',\n  };\n  return descriptions[category];\n}\n", "/**\n * Task Completion Check - Verifies tasks are properly completed before stop\n * Hook: Stop\n * CC 2.1.20: Orphan detection and deletion support\n */\n\nimport { existsSync, readFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, getSessionId, outputSilentSuccess, outputWithContext } from '../lib/common.js';\nimport { getOrphanedTasks, formatTaskDeleteForClaude } from '../lib/task-integration.js';\n\ninterface TodoItem {\n  status: string;\n  description?: string;\n}\n\n/**\n * Task completion check hook\n */\nexport function taskCompletionCheck(input: HookInput): HookResult {\n  logHook('task-completion-check', 'Stop hook - checking task completion');\n\n  const warnings: string[] = [];\n\n  // CC 2.1.20: Check orchestration registry for in_progress tasks\n  const projectDir = input.project_dir || getProjectDir();\n  const sessionId = input.session_id || getSessionId();\n  const registryFile = `${projectDir}/.claude/orchestration/task-registry-${sessionId}.json`;\n\n  if (existsSync(registryFile)) {\n    try {\n      const registry = JSON.parse(readFileSync(registryFile, 'utf-8'));\n      const inProgress = (registry.tasks || []).filter(\n        (t: { status: string }) => t.status === 'in_progress'\n      );\n      if (inProgress.length > 0) {\n        logHook('task-completion-check', `WARNING: ${inProgress.length} orchestration tasks still in progress`);\n        warnings.push(`${inProgress.length} orchestration task(s) still in progress at session stop`);\n      }\n    } catch (error) {\n      logHook('task-completion-check', `Error reading registry: ${error}`);\n    }\n  }\n\n  // CC 2.1.20: Check for orphaned tasks and generate deletion instructions\n  const orphans = getOrphanedTasks();\n  let orphanInstructions = '';\n  if (orphans.length > 0) {\n    logHook('task-completion-check', `Found ${orphans.length} orphaned tasks`);\n    orphanInstructions = '\\n\\n## Orphaned Tasks\\n\\nThe following tasks are orphaned (all blockers failed) and should be deleted:\\n';\n    for (const orphan of orphans) {\n      orphanInstructions += `\\n${formatTaskDeleteForClaude(orphan.taskId, 'All blocking tasks have failed')}`;\n    }\n  }\n\n  // Legacy fallback: check /tmp/claude-active-todos.json\n  const todosFile = '/tmp/claude-active-todos.json';\n  if (existsSync(todosFile)) {\n    try {\n      const todos: TodoItem[] = JSON.parse(readFileSync(todosFile, 'utf-8'));\n      const inProgress = todos.filter((t) => t.status === 'in_progress');\n      if (inProgress.length > 0) {\n        logHook('task-completion-check', `WARNING: ${inProgress.length} legacy tasks in progress at stop`);\n        warnings.push(`${inProgress.length} legacy task(s) still in progress`);\n      }\n    } catch (error) {\n      logHook('task-completion-check', `Error reading legacy todos: ${error}`);\n    }\n  }\n\n  if (warnings.length > 0 || orphanInstructions) {\n    let context = `## Task Completion Warning\\n\\n${warnings.map(w => `- ${w}`).join('\\n')}`;\n    if (orphanInstructions) {\n      context += orphanInstructions;\n    }\n    return outputWithContext(context);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Task Integration - Bridge to CC 2.1.16 Task Management System\n * Issue #197: Agent Orchestration Layer\n *\n * Provides utilities for:\n * - Generating task creation instructions\n * - Tracking task-to-agent relationships\n * - Managing task state for orchestration\n *\n * Note: This module generates INSTRUCTIONS for Claude to execute\n * task operations, as hooks cannot directly call CC tools.\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport type {\n  TaskCreateInstruction,\n  TaskUpdateInstruction,\n  TaskMetadata,\n  PipelineExecution,\n} from './orchestration-types.js';\n\n// -----------------------------------------------------------------------------\n// Types\n// -----------------------------------------------------------------------------\n\n/** Task tracking entry stored locally */\ninterface TaskEntry {\n  taskId: string;\n  agent: string;\n  confidence: number;\n  createdAt: string;\n  status: 'pending' | 'in_progress' | 'completed' | 'failed';\n  pipelineId?: string;\n  pipelineStep?: number;\n  blockedBy?: string[];\n  blocks?: string[];\n}\n\n/** Task registry for session */\ninterface TaskRegistry {\n  schemaVersion: string;\n  sessionId: string;\n  tasks: TaskEntry[];\n  pipelines: PipelineExecution[];\n  updatedAt: string;\n}\n\n// -----------------------------------------------------------------------------\n// Registry File Management\n// -----------------------------------------------------------------------------\n\nfunction getRegistryFile(): string {\n  const sessionId = getSessionId();\n  return `${getProjectDir()}/.claude/orchestration/task-registry-${sessionId}.json`;\n}\n\nfunction ensureDir(): void {\n  const dir = `${getProjectDir()}/.claude/orchestration`;\n  if (!existsSync(dir)) {\n    try {\n      mkdirSync(dir, { recursive: true });\n    } catch {\n      // Ignore\n    }\n  }\n}\n\nfunction loadRegistry(): TaskRegistry {\n  const file = getRegistryFile();\n\n  if (existsSync(file)) {\n    try {\n      return JSON.parse(readFileSync(file, 'utf8'));\n    } catch {\n      // Return default on error\n    }\n  }\n\n  return {\n    schemaVersion: '1.0.0',\n    sessionId: getSessionId(),\n    tasks: [],\n    pipelines: [],\n    updatedAt: new Date().toISOString(),\n  };\n}\n\nfunction saveRegistry(registry: TaskRegistry): void {\n  ensureDir();\n  const file = getRegistryFile();\n  registry.updatedAt = new Date().toISOString();\n\n  try {\n    writeFileSync(file, JSON.stringify(registry, null, 2));\n  } catch (err) {\n    logHook('task-integration', `Failed to save registry: ${err}`);\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Task Instructions Generators\n// -----------------------------------------------------------------------------\n\n/**\n * Get action-specific activeForm based on agent type\n */\nfunction getActiveFormForAgent(agent: string, description: string): string {\n  const actionMap: Record<string, string> = {\n    'backend-system-architect': 'Designing',\n    'frontend-ui-developer': 'Building',\n    'test-generator': 'Writing tests for',\n    'security-auditor': 'Auditing',\n    'workflow-architect': 'Architecting',\n    'database-engineer': 'Implementing database for',\n    'llm-integrator': 'Integrating LLM for',\n    'code-quality-reviewer': 'Reviewing',\n    'ux-researcher': 'Researching UX for',\n    'product-strategist': 'Strategizing',\n    'debug-investigator': 'Investigating',\n    'performance-engineer': 'Optimizing',\n    'accessibility-specialist': 'Auditing accessibility for',\n    'infrastructure-architect': 'Designing infrastructure for',\n    'data-pipeline-engineer': 'Building pipeline for',\n  };\n\n  const action = actionMap[agent] || 'Working on';\n  const shortDesc = description.slice(0, 40).toLowerCase();\n  return `${action} ${shortDesc}`;\n}\n\n/**\n * Generate TaskCreate instruction for an agent dispatch\n */\nexport function generateTaskCreateInstruction(\n  agent: string,\n  description: string,\n  confidence: number,\n  metadata?: Partial<TaskMetadata>\n): TaskCreateInstruction {\n  const agentTitle = agent\n    .split('-')\n    .map(w => w.charAt(0).toUpperCase() + w.slice(1))\n    .join(' ');\n\n  const fullMetadata: TaskMetadata = {\n    source: 'orchestration',\n    dispatchedAgent: agent,\n    dispatchConfidence: confidence,\n    ...metadata,\n  };\n\n  return {\n    subject: `${agentTitle}: ${description.slice(0, 50)}`,\n    description: `Agent dispatched automatically at ${confidence}% confidence.\\n\\n${description}`,\n    activeForm: getActiveFormForAgent(agent, description),\n    metadata: fullMetadata,\n  };\n}\n\n/**\n * Generate TaskUpdate instruction for status change\n */\nexport function generateTaskUpdateInstruction(\n  taskId: string,\n  status: 'pending' | 'in_progress' | 'completed' | 'deleted',\n  blockedBy?: string[],\n  blocks?: string[]\n): TaskUpdateInstruction {\n  const instruction: TaskUpdateInstruction = {\n    taskId,\n    status,\n  };\n\n  if (blockedBy && blockedBy.length > 0) {\n    instruction.addBlockedBy = blockedBy;\n  }\n\n  if (blocks && blocks.length > 0) {\n    instruction.addBlocks = blocks;\n  }\n\n  return instruction;\n}\n\n/**\n * Format TaskCreate instruction as markdown for Claude\n */\nexport function formatTaskCreateForClaude(instruction: TaskCreateInstruction): string {\n  return `### Create Task for Tracking\n\n\\`\\`\\`\nTaskCreate:\n  subject: \"${instruction.subject}\"\n  description: \"${instruction.description}\"\n  activeForm: \"${instruction.activeForm}\"\n  metadata:\n    source: \"${instruction.metadata.source}\"\n    dispatchedAgent: \"${instruction.metadata.dispatchedAgent || ''}\"\n    dispatchConfidence: ${instruction.metadata.dispatchConfidence || 0}\n\\`\\`\\``;\n}\n\n/**\n * Generate TaskUpdate instruction for task deletion (CC 2.1.20)\n */\nexport function generateTaskDeleteInstruction(\n  taskId: string,\n  _reason: string\n): TaskUpdateInstruction {\n  return {\n    taskId,\n    status: 'deleted',\n  };\n}\n\n/**\n * Format TaskDelete instruction as markdown for Claude (CC 2.1.20)\n */\nexport function formatTaskDeleteForClaude(taskId: string, reason: string): string {\n  return `### Delete Orphaned Task\n\n\\`\\`\\`\nTaskUpdate:\n  taskId: \"${taskId}\"\n  status: \"deleted\"\n\\`\\`\\`\n\n**Reason**: ${reason}`;\n}\n\n/**\n * Format TaskUpdate instruction as markdown for Claude\n */\nexport function formatTaskUpdateForClaude(instruction: TaskUpdateInstruction): string {\n  let md = `### Update Task\n\n\\`\\`\\`\nTaskUpdate:\n  taskId: \"${instruction.taskId}\"`;\n\n  if (instruction.status) {\n    md += `\\n  status: \"${instruction.status}\"`;\n  }\n\n  if (instruction.addBlockedBy && instruction.addBlockedBy.length > 0) {\n    md += `\\n  addBlockedBy: ${JSON.stringify(instruction.addBlockedBy)}`;\n  }\n\n  if (instruction.addBlocks && instruction.addBlocks.length > 0) {\n    md += `\\n  addBlocks: ${JSON.stringify(instruction.addBlocks)}`;\n  }\n\n  md += '\\n```';\n  return md;\n}\n\n// -----------------------------------------------------------------------------\n// Task Tracking Operations\n// -----------------------------------------------------------------------------\n\n/**\n * Register a new task for an agent\n */\nexport function registerTask(\n  taskId: string,\n  agent: string,\n  confidence: number,\n  pipelineId?: string,\n  pipelineStep?: number,\n  blockedBy?: string[],\n  blocks?: string[]\n): void {\n  const registry = loadRegistry();\n\n  // Check for duplicate\n  const existing = registry.tasks.find(t => t.taskId === taskId);\n  if (existing) {\n    logHook('task-integration', `Task ${taskId} already registered`);\n    return;\n  }\n\n  registry.tasks.push({\n    taskId,\n    agent,\n    confidence,\n    createdAt: new Date().toISOString(),\n    status: 'pending',\n    pipelineId,\n    pipelineStep,\n    blockedBy,\n    blocks,\n  });\n\n  saveRegistry(registry);\n  logHook('task-integration', `Registered task ${taskId} for agent ${agent}`);\n}\n\n/**\n * Update task status in registry\n */\nexport function updateTaskStatus(\n  taskId: string,\n  status: TaskEntry['status']\n): void {\n  const registry = loadRegistry();\n\n  const task = registry.tasks.find(t => t.taskId === taskId);\n  if (task) {\n    task.status = status;\n    saveRegistry(registry);\n    logHook('task-integration', `Updated task ${taskId} status to ${status}`);\n  }\n}\n\n/**\n * Get task by agent name\n */\nexport function getTaskByAgent(agent: string): TaskEntry | undefined {\n  const registry = loadRegistry();\n  return registry.tasks.find(\n    t => t.agent === agent && (t.status === 'pending' || t.status === 'in_progress')\n  );\n}\n\n/**\n * Get task by ID\n */\nexport function getTaskById(taskId: string): TaskEntry | undefined {\n  const registry = loadRegistry();\n  return registry.tasks.find(t => t.taskId === taskId);\n}\n\n/**\n * Get pending tasks blocked by a specific failed task (CC 2.1.20)\n */\nexport function getTasksBlockedBy(failedTaskId: string): TaskEntry[] {\n  const registry = loadRegistry();\n  return registry.tasks.filter(\n    t =>\n      t.status === 'pending' &&\n      t.blockedBy &&\n      t.blockedBy.includes(failedTaskId)\n  );\n}\n\n/**\n * Get orphaned tasks - pending tasks where all blockers have failed (CC 2.1.20)\n */\nexport function getOrphanedTasks(): TaskEntry[] {\n  const registry = loadRegistry();\n  const failedIds = new Set(\n    registry.tasks.filter(t => t.status === 'failed').map(t => t.taskId)\n  );\n\n  if (failedIds.size === 0) return [];\n\n  return registry.tasks.filter(t => {\n    if (t.status !== 'pending' || !t.blockedBy || t.blockedBy.length === 0) {\n      return false;\n    }\n    // Orphaned if ALL blockers are failed\n    return t.blockedBy.every(id => failedIds.has(id));\n  });\n}\n\n/**\n * Get all tasks for a pipeline\n */\nexport function getPipelineTasks(pipelineId: string): TaskEntry[] {\n  const registry = loadRegistry();\n  return registry.tasks\n    .filter(t => t.pipelineId === pipelineId)\n    .sort((a, b) => (a.pipelineStep || 0) - (b.pipelineStep || 0));\n}\n\n// -----------------------------------------------------------------------------\n// Pipeline Operations\n// -----------------------------------------------------------------------------\n\n/**\n * Register a pipeline execution\n */\nexport function registerPipeline(pipeline: PipelineExecution): void {\n  const registry = loadRegistry();\n\n  // Check for duplicate\n  const existing = registry.pipelines.find(p => p.pipelineId === pipeline.pipelineId);\n  if (existing) {\n    logHook('task-integration', `Pipeline ${pipeline.pipelineId} already registered`);\n    return;\n  }\n\n  registry.pipelines.push(pipeline);\n  saveRegistry(registry);\n  logHook('task-integration', `Registered pipeline ${pipeline.pipelineId} (${pipeline.type})`);\n}\n\n/**\n * Update pipeline state\n */\nexport function updatePipeline(\n  pipelineId: string,\n  updates: Partial<PipelineExecution>\n): void {\n  const registry = loadRegistry();\n\n  const pipeline = registry.pipelines.find(p => p.pipelineId === pipelineId);\n  if (pipeline) {\n    Object.assign(pipeline, updates);\n    saveRegistry(registry);\n    logHook('task-integration', `Updated pipeline ${pipelineId}`);\n  }\n}\n\n/**\n * Get active pipeline (if any)\n */\nexport function getActivePipeline(): PipelineExecution | undefined {\n  const registry = loadRegistry();\n  return registry.pipelines.find(p => p.status === 'running');\n}\n\n/**\n * Mark pipeline step complete and check for next\n */\nexport function completePipelineStep(pipelineId: string, step: number): number | null {\n  const registry = loadRegistry();\n\n  const pipeline = registry.pipelines.find(p => p.pipelineId === pipelineId);\n  if (!pipeline) return null;\n\n  if (!pipeline.completedSteps.includes(step)) {\n    pipeline.completedSteps.push(step);\n    pipeline.completedSteps.sort((a, b) => a - b);\n  }\n\n  // Find next unblocked step\n  const tasks = getPipelineTasks(pipelineId);\n  for (const task of tasks) {\n    const taskStep = task.pipelineStep;\n    if (taskStep === undefined) continue;\n    if (pipeline.completedSteps.includes(taskStep)) continue;\n    if (task.status !== 'pending') continue;\n\n    // Check if dependencies are met\n    // For now, assume sequential - previous steps must be complete\n    const prevStepsComplete = taskStep === 0 ||\n      pipeline.completedSteps.includes(taskStep - 1);\n\n    if (prevStepsComplete) {\n      pipeline.currentStep = taskStep;\n      saveRegistry(registry);\n      return taskStep;\n    }\n  }\n\n  // No more steps - pipeline complete\n  pipeline.status = 'completed';\n  saveRegistry(registry);\n  return null;\n}\n\n// -----------------------------------------------------------------------------\n// Cleanup\n// -----------------------------------------------------------------------------\n\n/**\n * Clean up completed tasks older than threshold\n */\nexport function cleanupOldTasks(maxAgeMs: number = 24 * 60 * 60 * 1000): void {\n  const registry = loadRegistry();\n  const cutoff = Date.now() - maxAgeMs;\n\n  registry.tasks = registry.tasks.filter(t => {\n    if (t.status === 'pending' || t.status === 'in_progress') return true;\n    const taskTime = new Date(t.createdAt).getTime();\n    return taskTime > cutoff;\n  });\n\n  registry.pipelines = registry.pipelines.filter(p => {\n    if (p.status === 'running') return true;\n    const pipelineTime = new Date(p.startedAt).getTime();\n    return pipelineTime > cutoff;\n  });\n\n  saveRegistry(registry);\n}\n", "/**\n * Orchestration State - Session state management for agent orchestration\n * Issue #197: Agent Orchestration Layer\n *\n * Manages:\n * - Active dispatched agents\n * - Injected skills tracking\n * - Prompt history for context continuity\n * - State persistence across hook invocations\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport type {\n  OrchestrationState,\n  DispatchedAgent,\n  OrchestrationConfig,\n  ClassificationResult,\n} from './orchestration-types.js';\n\n// -----------------------------------------------------------------------------\n// State File Management\n// -----------------------------------------------------------------------------\n\nfunction getStateDir(): string {\n  return `${getProjectDir()}/.claude/orchestration`;\n}\n\nfunction getStateFile(): string {\n  const sessionId = getSessionId();\n  return `${getStateDir()}/session-${sessionId}.json`;\n}\n\nfunction getConfigFile(): string {\n  return `${getProjectDir()}/.claude/orchestration/config.json`;\n}\n\n/**\n * Ensure state directory exists\n */\nfunction ensureStateDir(): void {\n  const dir = getStateDir();\n  if (!existsSync(dir)) {\n    try {\n      mkdirSync(dir, { recursive: true });\n    } catch {\n      logHook('orchestration-state', `Failed to create state dir: ${dir}`);\n    }\n  }\n}\n\n// -----------------------------------------------------------------------------\n// State Operations\n// -----------------------------------------------------------------------------\n\n/**\n * Load orchestration state for current session\n */\nexport function loadState(): OrchestrationState {\n  const stateFile = getStateFile();\n\n  if (existsSync(stateFile)) {\n    try {\n      const data = readFileSync(stateFile, 'utf8');\n      return JSON.parse(data) as OrchestrationState;\n    } catch (err) {\n      logHook('orchestration-state', `Failed to load state: ${err}`);\n    }\n  }\n\n  // Return default state\n  return {\n    sessionId: getSessionId(),\n    activeAgents: [],\n    injectedSkills: [],\n    promptHistory: [],\n    maxHistorySize: 10,\n    updatedAt: new Date().toISOString(),\n  };\n}\n\n/**\n * Save orchestration state\n */\nexport function saveState(state: OrchestrationState): void {\n  ensureStateDir();\n  const stateFile = getStateFile();\n\n  state.updatedAt = new Date().toISOString();\n\n  try {\n    writeFileSync(stateFile, JSON.stringify(state, null, 2));\n  } catch (err) {\n    logHook('orchestration-state', `Failed to save state: ${err}`);\n  }\n}\n\n/**\n * Update state with a mutation function\n */\nexport function updateState(\n  mutate: (state: OrchestrationState) => void\n): OrchestrationState {\n  const state = loadState();\n  mutate(state);\n  saveState(state);\n  return state;\n}\n\n// -----------------------------------------------------------------------------\n// Agent Tracking\n// -----------------------------------------------------------------------------\n\n/**\n * Add a dispatched agent to state\n */\nexport function trackDispatchedAgent(\n  agent: string,\n  confidence: number,\n  taskId?: string\n): DispatchedAgent {\n  const dispatched: DispatchedAgent = {\n    agent,\n    taskId,\n    confidence,\n    dispatchedAt: new Date().toISOString(),\n    status: 'pending',\n    retryCount: 0,\n    maxRetries: 3,\n  };\n\n  updateState(state => {\n    // Remove any existing entry for same agent\n    state.activeAgents = state.activeAgents.filter(a => a.agent !== agent);\n    state.activeAgents.push(dispatched);\n  });\n\n  logHook('orchestration-state', `Tracked dispatched agent: ${agent} (conf: ${confidence})`);\n  return dispatched;\n}\n\n/**\n * Update agent status\n */\nexport function updateAgentStatus(\n  agent: string,\n  status: DispatchedAgent['status'],\n  taskId?: string\n): void {\n  updateState(state => {\n    const entry = state.activeAgents.find(a => a.agent === agent);\n    if (entry) {\n      entry.status = status;\n      if (taskId) entry.taskId = taskId;\n      if (status === 'retrying') entry.retryCount++;\n    }\n  });\n\n  logHook('orchestration-state', `Updated agent status: ${agent} -> ${status}`);\n}\n\n/**\n * Remove completed/failed agent from tracking\n */\nexport function removeAgent(agent: string): void {\n  updateState(state => {\n    state.activeAgents = state.activeAgents.filter(a => a.agent !== agent);\n  });\n}\n\n/**\n * Get currently active agent (if any)\n */\nexport function getActiveAgent(): DispatchedAgent | undefined {\n  const state = loadState();\n  return state.activeAgents.find(a => a.status === 'in_progress');\n}\n\n/**\n * Check if an agent is currently dispatched\n */\nexport function isAgentDispatched(agent: string): boolean {\n  const state = loadState();\n  return state.activeAgents.some(\n    a => a.agent === agent && (a.status === 'pending' || a.status === 'in_progress')\n  );\n}\n\n// -----------------------------------------------------------------------------\n// Skill Tracking\n// -----------------------------------------------------------------------------\n\n/**\n * Track injected skill\n */\nexport function trackInjectedSkill(skill: string): void {\n  updateState(state => {\n    if (!state.injectedSkills.includes(skill)) {\n      state.injectedSkills.push(skill);\n    }\n  });\n}\n\n/**\n * Check if skill was already injected\n */\nexport function isSkillInjected(skill: string): boolean {\n  const state = loadState();\n  return state.injectedSkills.includes(skill);\n}\n\n/**\n * Get all injected skills\n */\nexport function getInjectedSkills(): string[] {\n  return loadState().injectedSkills;\n}\n\n// -----------------------------------------------------------------------------\n// Prompt History\n// -----------------------------------------------------------------------------\n\n/**\n * Add prompt to history (for context continuity)\n */\nexport function addToPromptHistory(prompt: string): void {\n  updateState(state => {\n    state.promptHistory.push(prompt);\n    // Trim to max size\n    if (state.promptHistory.length > state.maxHistorySize) {\n      state.promptHistory = state.promptHistory.slice(-state.maxHistorySize);\n    }\n  });\n}\n\n/**\n * Get recent prompt history\n */\nexport function getPromptHistory(): string[] {\n  return loadState().promptHistory;\n}\n\n// -----------------------------------------------------------------------------\n// Classification Caching\n// -----------------------------------------------------------------------------\n\n/**\n * Store last classification result\n */\nexport function cacheClassification(result: ClassificationResult): void {\n  updateState(state => {\n    state.lastClassification = result;\n  });\n}\n\n/**\n * Get last classification result\n */\nexport function getLastClassification(): ClassificationResult | undefined {\n  return loadState().lastClassification;\n}\n\n// -----------------------------------------------------------------------------\n// Configuration\n// -----------------------------------------------------------------------------\n\nconst DEFAULT_CONFIG_VALUES: OrchestrationConfig = {\n  enableAutoDispatch: true,\n  enableSkillInjection: true,\n  maxSkillInjectionTokens: 800,\n  enableCalibration: true,\n  enablePipelines: true,\n  maxRetries: 3,\n  retryDelayBaseMs: 1000,\n};\n\n/**\n * Load orchestration configuration\n */\nexport function loadConfig(): OrchestrationConfig {\n  const configFile = getConfigFile();\n\n  if (existsSync(configFile)) {\n    try {\n      const data = readFileSync(configFile, 'utf8');\n      return { ...DEFAULT_CONFIG_VALUES, ...JSON.parse(data) };\n    } catch {\n      // Return defaults on error\n    }\n  }\n\n  return DEFAULT_CONFIG_VALUES;\n}\n\n/**\n * Save orchestration configuration\n */\nexport function saveConfig(config: Partial<OrchestrationConfig>): void {\n  ensureStateDir();\n  const configFile = getConfigFile();\n  const current = loadConfig();\n  const merged = { ...current, ...config };\n\n  try {\n    writeFileSync(configFile, JSON.stringify(merged, null, 2));\n  } catch (err) {\n    logHook('orchestration-state', `Failed to save config: ${err}`);\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Cleanup\n// -----------------------------------------------------------------------------\n\n/**\n * Clear session state (called on session end)\n */\nexport function clearSessionState(): void {\n  const stateFile = getStateFile();\n\n  try {\n    if (existsSync(stateFile)) {\n      const { unlinkSync } = require('node:fs');\n      unlinkSync(stateFile);\n      logHook('orchestration-state', 'Cleared session state');\n    }\n  } catch {\n    // Ignore cleanup errors\n  }\n}\n\n/**\n * Clean up old state files (keep last 5 sessions)\n */\nexport function cleanupOldStates(): void {\n  const dir = getStateDir();\n\n  if (!existsSync(dir)) return;\n\n  try {\n    const { readdirSync, statSync, unlinkSync } = require('node:fs');\n    const files = readdirSync(dir)\n      .filter((f: string) => f.startsWith('session-') && f.endsWith('.json'))\n      .map((f: string) => ({\n        name: f,\n        path: `${dir}/${f}`,\n        mtime: statSync(`${dir}/${f}`).mtime.getTime(),\n      }))\n      .sort((a: { mtime: number }, b: { mtime: number }) => b.mtime - a.mtime);\n\n    // Keep only last 5\n    for (const file of files.slice(5)) {\n      try {\n        unlinkSync(file.path);\n        logHook('orchestration-state', `Cleaned up old state: ${file.name}`);\n      } catch {\n        // Ignore\n      }\n    }\n  } catch {\n    // Ignore cleanup errors\n  }\n}\n", "/**\n * Calibration Persist - Stop Hook for Persisting Calibration Data\n * Issue #197: Agent Orchestration Layer\n *\n * End-of-session calibration operations:\n * - Applies decay to old adjustments\n * - Cleans up expired records\n * - Saves final calibration state\n *\n * CC 2.1.7 Compliant: Silent hook that persists in background\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { outputSilentSuccess, logHook } from '../lib/common.js';\nimport {\n  loadCalibrationData,\n  saveCalibrationData,\n  applyDecay,\n} from '../lib/calibration-engine.js';\nimport { loadConfig, clearSessionState, cleanupOldStates } from '../lib/orchestration-state.js';\nimport { cleanupOldTasks } from '../lib/task-integration.js';\n\n// -----------------------------------------------------------------------------\n// Constants\n// -----------------------------------------------------------------------------\n\n/** Maximum age for calibration records (30 days) */\nconst MAX_RECORD_AGE_MS = 30 * 24 * 60 * 60 * 1000;\n\n// -----------------------------------------------------------------------------\n// Helper Functions\n// -----------------------------------------------------------------------------\n\n/**\n * Clean up old calibration records\n */\nfunction cleanupOldRecords(data: ReturnType<typeof loadCalibrationData>): void {\n  const cutoff = Date.now() - MAX_RECORD_AGE_MS;\n\n  const before = data.records.length;\n  data.records = data.records.filter(r => {\n    const recordTime = new Date(r.timestamp).getTime();\n    return recordTime > cutoff;\n  });\n  const after = data.records.length;\n\n  if (before !== after) {\n    logHook('calibration-persist', `Cleaned up ${before - after} old records`);\n  }\n}\n\n/**\n * Generate calibration summary for logging\n */\nfunction generateSummary(data: ReturnType<typeof loadCalibrationData>): string {\n  const stats = data.stats;\n  const topAgents = stats.topAgents\n    .slice(0, 3)\n    .map(a => `${a.agent}(${Math.round(a.successRate * 100)}%)`)\n    .join(', ');\n\n  return `Calibration summary: ${stats.totalDispatches} dispatches, ` +\n    `${Math.round(stats.successRate * 100)}% success rate, ` +\n    `${data.adjustments.length} adjustments active. ` +\n    `Top agents: ${topAgents || 'none'}`;\n}\n\n// -----------------------------------------------------------------------------\n// Hook Implementation\n// -----------------------------------------------------------------------------\n\n/**\n * Calibration persist hook\n *\n * Runs at session end to:\n * 1. Apply decay to old adjustments\n * 2. Clean up expired records\n * 3. Save final calibration state\n * 4. Clean up session-specific state\n */\nexport function calibrationPersist(_input: HookInput): HookResult {\n  // Check if calibration is enabled\n  const config = loadConfig();\n  if (!config.enableCalibration) {\n    // Still do cleanup even if calibration disabled\n    clearSessionState();\n    cleanupOldStates();\n    return outputSilentSuccess();\n  }\n\n  logHook('calibration-persist', 'Running end-of-session calibration persistence...');\n\n  try {\n    // Load current calibration data\n    const data = loadCalibrationData();\n\n    // Apply decay to old adjustments\n    applyDecay(data);\n\n    // Clean up old records\n    cleanupOldRecords(data);\n\n    // Save updated calibration data\n    saveCalibrationData(data);\n\n    // Log summary\n    const summary = generateSummary(data);\n    logHook('calibration-persist', summary);\n\n  } catch (err) {\n    logHook('calibration-persist', `Error during calibration persist: ${err}`);\n  }\n\n  // Clean up session state\n  try {\n    clearSessionState();\n    cleanupOldStates();\n    cleanupOldTasks();\n    logHook('calibration-persist', 'Cleaned up session state');\n  } catch (err) {\n    logHook('calibration-persist', `Error during state cleanup: ${err}`);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * User Profile Management\n * Aggregates session data into user profiles for learning patterns across sessions.\n *\n * Profiles track:\n * - Skill usage patterns\n * - Agent preferences\n * - Decision history\n * - Workflow patterns\n * - Tool preferences\n *\n * Storage: ~/.claude/orchestkit/users/{user_id}/profile.json (cross-project)\n *\n * Migration: Profiles are migrated from old project-local path on first access\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { join, dirname } from 'node:path';\nimport { getProjectDir, logHook } from './common.js';\nimport { resolveUserIdentity } from './user-identity.js';\nimport { generateSessionSummary, type SessionSummary } from './session-tracker.js';\nimport { analyzeDecisionFlow, type WorkflowPattern as FlowWorkflowPattern } from './decision-flow-tracker.js';\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * Usage statistics for a skill/agent/tool\n */\nexport interface UsageStats {\n  /** Total times used */\n  count: number;\n  /** Success rate (0-1) */\n  success_rate: number;\n  /** Average duration in ms */\n  avg_duration_ms?: number;\n  /** First used timestamp */\n  first_used: string;\n  /** Last used timestamp */\n  last_used: string;\n}\n\n/**\n * Recorded decision\n */\nexport interface RecordedDecision {\n  /** What was decided */\n  what: string;\n  /** Alternatives considered */\n  alternatives?: string[];\n  /** Rationale provided */\n  rationale?: string;\n  /** Confidence score */\n  confidence: number;\n  /** When decided */\n  timestamp: string;\n  /** Project where decision was made */\n  project?: string;\n}\n\n/**\n * Recorded preference\n */\nexport interface RecordedPreference {\n  /** Category (e.g., \"file_search\", \"testing\", \"language\") */\n  category: string;\n  /** What is preferred */\n  preference: string;\n  /** Confidence score */\n  confidence: number;\n  /** When recorded */\n  timestamp: string;\n  /** How many times this preference was observed */\n  observation_count: number;\n}\n\n/**\n * Detected workflow pattern\n */\nexport interface WorkflowPattern {\n  /** Pattern name */\n  name: string;\n  /** Pattern description */\n  description: string;\n  /** How often this pattern is observed (0-1) */\n  frequency: number;\n  /** Tool sequences that indicate this pattern */\n  tool_sequences: string[][];\n}\n\n/**\n * Descriptions for workflow pattern names\n */\nconst WORKFLOW_PATTERN_DESCRIPTIONS: Record<FlowWorkflowPattern, string> = {\n  'test-first': 'Writes tests before implementation (TDD)',\n  'explore-first': 'Reads existing code before making changes',\n  'iterate-fast': 'Makes quick write \u2192 test iterations',\n  'big-bang': 'Writes multiple files then tests',\n  'agent-delegate': 'Delegates tasks to specialized agents',\n  'mixed': 'Varies approach by task',\n};\n\n/**\n * Convert decision-flow-tracker pattern to user-profile WorkflowPattern\n */\nfunction convertFlowPattern(flowPattern: FlowWorkflowPattern, existingPatterns: WorkflowPattern[]): WorkflowPattern {\n  const existing = existingPatterns.find(p => p.name === flowPattern);\n  const frequency = existing ? Math.min(1, existing.frequency + 0.1) : 0.1;\n\n  return {\n    name: flowPattern,\n    description: WORKFLOW_PATTERN_DESCRIPTIONS[flowPattern],\n    frequency,\n    tool_sequences: [], // Populated by detailed analysis if needed\n  };\n}\n\n/**\n * Complete user profile\n */\nexport interface UserProfile {\n  /** User identifier */\n  user_id: string;\n  /** Anonymous identifier for global sharing */\n  anonymous_id: string;\n  /** Display name */\n  display_name: string;\n  /** Team/org if known */\n  team_id?: string;\n  /** Total sessions analyzed */\n  sessions_count: number;\n  /** First seen timestamp */\n  first_seen: string;\n  /** Last seen timestamp */\n  last_seen: string;\n  /** Profile version for migrations */\n  version: number;\n\n  /** Skill usage statistics */\n  skill_usage: Record<string, UsageStats>;\n  /** Agent usage statistics */\n  agent_usage: Record<string, UsageStats>;\n  /** Tool usage statistics */\n  tool_usage: Record<string, UsageStats>;\n\n  /** Tool preferences by category (Phase 4: Tool Usage Tracking)\n   * Maps category \u2192 preferred tool name based on usage frequency\n   * e.g., { search: 'Grep', file_read: 'Read' }\n   */\n  tool_preferences?: Record<string, string>;\n\n  /** Tool usage by category (Phase 4: Tool Usage Tracking)\n   * Maps category \u2192 { tool \u2192 count }\n   * e.g., { search: { Grep: 10, Glob: 3 } }\n   */\n  tool_usage_by_category?: Record<string, Record<string, number>>;\n\n  /** Recorded decisions */\n  decisions: RecordedDecision[];\n  /** Recorded preferences */\n  preferences: RecordedPreference[];\n\n  /** Detected workflow patterns */\n  workflow_patterns: WorkflowPattern[];\n\n  /** Session IDs that have been aggregated */\n  aggregated_sessions: string[];\n}\n\n// =============================================================================\n// CONSTANTS\n// =============================================================================\n\nconst PROFILE_VERSION = 1;\nconst MAX_DECISIONS = 100;\nconst MAX_PREFERENCES = 50;\n\n// =============================================================================\n// PATHS\n// =============================================================================\n\n/**\n * Get the home directory for cross-project storage\n */\nfunction getHomeDir(): string {\n  return process.env.HOME || process.env.USERPROFILE || '/tmp';\n}\n\n/**\n * Get the cross-project OrchestKit directory\n */\nfunction getOrchestKitDir(): string {\n  return join(getHomeDir(), '.claude', 'orchestkit');\n}\n\n/**\n * Get user profile directory (cross-project, in home directory)\n */\nfunction getUserProfileDir(userId: string): string {\n  const sanitizedUserId = userId.replace(/[^a-zA-Z0-9@._-]/g, '_');\n  return join(getOrchestKitDir(), 'users', sanitizedUserId);\n}\n\n/**\n * Get user profile file path\n */\nfunction getUserProfilePath(userId: string): string {\n  return join(getUserProfileDir(userId), 'profile.json');\n}\n\n/**\n * Get the OLD project-local profile path (for migration)\n */\nfunction getLegacyProfilePath(userId: string): string {\n  const sanitizedUserId = userId.replace(/[^a-zA-Z0-9@._-]/g, '_');\n  return join(getProjectDir(), '.claude', 'memory', 'users', sanitizedUserId, 'profile.json');\n}\n\n/**\n * Migrate profile from old project-local path to new cross-project path\n * Returns true if migration occurred\n */\nfunction migrateProfileIfNeeded(userId: string): boolean {\n  const legacyPath = getLegacyProfilePath(userId);\n  const newPath = getUserProfilePath(userId);\n\n  // If new path exists, no migration needed\n  if (existsSync(newPath)) {\n    return false;\n  }\n\n  // If legacy path exists, migrate it\n  if (existsSync(legacyPath)) {\n    try {\n      const newDir = dirname(newPath);\n      if (!existsSync(newDir)) {\n        mkdirSync(newDir, { recursive: true });\n      }\n\n      // Read legacy profile\n      const content = readFileSync(legacyPath, 'utf8');\n      const profile = JSON.parse(content);\n\n      // Write to new location\n      writeFileSync(newPath, JSON.stringify(profile, null, 2));\n\n      logHook('user-profile', `Migrated profile for ${userId} to cross-project storage`, 'info');\n      return true;\n    } catch (error) {\n      logHook('user-profile', `Failed to migrate profile: ${error}`, 'warn');\n      return false;\n    }\n  }\n\n  return false;\n}\n\n// =============================================================================\n// PROFILE LOADING/SAVING\n// =============================================================================\n\n/**\n * Create empty profile for a user\n */\nfunction createEmptyProfile(userId: string): UserProfile {\n  const identity = resolveUserIdentity();\n  const now = new Date().toISOString();\n\n  return {\n    user_id: userId,\n    anonymous_id: identity.anonymous_id,\n    display_name: identity.display_name,\n    team_id: identity.team_id,\n    sessions_count: 0,\n    first_seen: now,\n    last_seen: now,\n    version: PROFILE_VERSION,\n    skill_usage: {},\n    agent_usage: {},\n    tool_usage: {},\n    decisions: [],\n    preferences: [],\n    workflow_patterns: [],\n    aggregated_sessions: [],\n  };\n}\n\n/**\n * Load user profile from disk\n */\nexport function loadUserProfile(userId?: string): UserProfile {\n  // Attempt migration from legacy project-local path\n  const uid = userId || resolveUserIdentity().user_id;\n  migrateProfileIfNeeded(uid);\n\n  const profilePath = getUserProfilePath(uid);\n\n\n  if (!existsSync(profilePath)) {\n    return createEmptyProfile(uid);\n  }\n\n  try {\n    const content = readFileSync(profilePath, 'utf8');\n    const profile = JSON.parse(content) as UserProfile;\n\n    // Handle version migrations here if needed\n    if (profile.version < PROFILE_VERSION) {\n      // Migrate profile\n      profile.version = PROFILE_VERSION;\n    }\n\n    return profile;\n  } catch (error) {\n    logHook('user-profile', `Failed to load profile: ${error}`, 'warn');\n    return createEmptyProfile(uid);\n  }\n}\n\n/**\n * Save user profile to disk\n */\nexport function saveUserProfile(profile: UserProfile): boolean {\n  const profileDir = getUserProfileDir(profile.user_id);\n  const profilePath = getUserProfilePath(profile.user_id);\n\n  try {\n    if (!existsSync(profileDir)) {\n      mkdirSync(profileDir, { recursive: true });\n    }\n\n    profile.last_seen = new Date().toISOString();\n    writeFileSync(profilePath, JSON.stringify(profile, null, 2));\n\n    logHook('user-profile', `Saved profile for ${profile.user_id}`, 'debug');\n    return true;\n  } catch (error) {\n    logHook('user-profile', `Failed to save profile: ${error}`, 'error');\n    return false;\n  }\n}\n\n// =============================================================================\n// PROFILE AGGREGATION\n// =============================================================================\n\n/**\n * Update usage stats with new data\n */\nfunction updateUsageStats(\n  existing: UsageStats | undefined,\n  success: boolean,\n  durationMs?: number\n): UsageStats {\n  const now = new Date().toISOString();\n\n  if (!existing) {\n    return {\n      count: 1,\n      success_rate: success ? 1 : 0,\n      avg_duration_ms: durationMs,\n      first_used: now,\n      last_used: now,\n    };\n  }\n\n  const newCount = existing.count + 1;\n  const successCount = Math.round(existing.success_rate * existing.count) + (success ? 1 : 0);\n  const newSuccessRate = successCount / newCount;\n\n  let newAvgDuration = existing.avg_duration_ms;\n  if (durationMs !== undefined) {\n    if (existing.avg_duration_ms !== undefined) {\n      newAvgDuration =\n        (existing.avg_duration_ms * existing.count + durationMs) / newCount;\n    } else {\n      newAvgDuration = durationMs;\n    }\n  }\n\n  return {\n    count: newCount,\n    success_rate: newSuccessRate,\n    avg_duration_ms: newAvgDuration,\n    first_used: existing.first_used,\n    last_used: now,\n  };\n}\n\n/**\n * Aggregate a session into the user profile\n */\nexport function aggregateSession(\n  profile: UserProfile,\n  summary: SessionSummary\n): UserProfile {\n  // Skip if already aggregated\n  if (profile.aggregated_sessions.includes(summary.session_id)) {\n    logHook('user-profile', `Session ${summary.session_id} already aggregated`, 'debug');\n    return profile;\n  }\n\n  // Update session count\n  profile.sessions_count++;\n  profile.aggregated_sessions.push(summary.session_id);\n\n  // Aggregate skill usage\n  for (const skill of summary.skills_used) {\n    profile.skill_usage[skill] = updateUsageStats(\n      profile.skill_usage[skill],\n      true // We don't have per-skill success in summary\n    );\n  }\n\n  // Aggregate agent usage\n  for (const agent of summary.agents_spawned) {\n    profile.agent_usage[agent] = updateUsageStats(\n      profile.agent_usage[agent],\n      true\n    );\n  }\n\n  // Aggregate workflow pattern from decision flow (Issue #245 Phase 4)\n  try {\n    const flow = analyzeDecisionFlow(summary.session_id);\n    if (flow?.inferred_pattern && flow.inferred_pattern !== 'mixed') {\n      // Convert to WorkflowPattern interface and add to profile\n      const patternName = flow.inferred_pattern;\n      const existingIndex = profile.workflow_patterns.findIndex(p => p.name === patternName);\n\n      if (existingIndex !== -1) {\n        // Update existing pattern: increase frequency and move to front\n        const existing = profile.workflow_patterns[existingIndex];\n        existing.frequency = Math.min(1, existing.frequency + 0.1);\n        profile.workflow_patterns.splice(existingIndex, 1);\n        profile.workflow_patterns.unshift(existing);\n      } else {\n        // Add new pattern\n        const newPattern = convertFlowPattern(patternName, profile.workflow_patterns);\n        profile.workflow_patterns.unshift(newPattern);\n      }\n\n      // Keep only last 10 workflow patterns\n      if (profile.workflow_patterns.length > 10) {\n        profile.workflow_patterns = profile.workflow_patterns.slice(0, 10);\n      }\n      logHook('user-profile', `Aggregated workflow pattern: ${patternName}`, 'debug');\n    }\n  } catch (error) {\n    // Non-blocking: workflow pattern aggregation failure shouldn't stop profile aggregation\n    logHook('user-profile', `Failed to aggregate workflow pattern: ${error}`, 'debug');\n  }\n\n  // Keep only last N sessions to prevent unbounded growth\n  const MAX_AGGREGATED_SESSIONS = 100;\n  if (profile.aggregated_sessions.length > MAX_AGGREGATED_SESSIONS) {\n    profile.aggregated_sessions = profile.aggregated_sessions.slice(\n      -MAX_AGGREGATED_SESSIONS\n    );\n  }\n\n  return profile;\n}\n\n/**\n * Aggregate current session and save profile\n */\nexport function aggregateCurrentSession(): UserProfile {\n  const identity = resolveUserIdentity();\n  const profile = loadUserProfile(identity.user_id);\n  const summary = generateSessionSummary();\n\n  const updatedProfile = aggregateSession(profile, summary);\n  saveUserProfile(updatedProfile);\n\n  return updatedProfile;\n}\n\n// =============================================================================\n// DECISION/PREFERENCE RECORDING\n// =============================================================================\n\n/**\n * Add a decision to user profile\n */\nexport function addDecision(\n  profile: UserProfile,\n  decision: Omit<RecordedDecision, 'timestamp'>\n): UserProfile {\n  const newDecision: RecordedDecision = {\n    ...decision,\n    timestamp: new Date().toISOString(),\n  };\n\n  profile.decisions.unshift(newDecision);\n\n  // Keep only last N decisions\n  if (profile.decisions.length > MAX_DECISIONS) {\n    profile.decisions = profile.decisions.slice(0, MAX_DECISIONS);\n  }\n\n  return profile;\n}\n\n/**\n * Add or update a preference\n */\nexport function addPreference(\n  profile: UserProfile,\n  category: string,\n  preference: string,\n  confidence: number\n): UserProfile {\n  // Check if preference already exists\n  const existingIdx = profile.preferences.findIndex(\n    p => p.category === category && p.preference === preference\n  );\n\n  if (existingIdx >= 0) {\n    // Update existing\n    const existing = profile.preferences[existingIdx];\n    existing.observation_count++;\n    existing.confidence = Math.max(existing.confidence, confidence);\n    existing.timestamp = new Date().toISOString();\n  } else {\n    // Add new\n    profile.preferences.push({\n      category,\n      preference,\n      confidence,\n      timestamp: new Date().toISOString(),\n      observation_count: 1,\n    });\n\n    // Keep only top N preferences\n    if (profile.preferences.length > MAX_PREFERENCES) {\n      profile.preferences.sort((a, b) => b.observation_count - a.observation_count);\n      profile.preferences = profile.preferences.slice(0, MAX_PREFERENCES);\n    }\n  }\n\n  return profile;\n}\n\n// =============================================================================\n// PROFILE QUERIES\n// =============================================================================\n\n/**\n * Get top N used skills for a user\n */\nexport function getTopSkills(profile: UserProfile, limit: number = 5): Array<{\n  skill: string;\n  stats: UsageStats;\n}> {\n  return Object.entries(profile.skill_usage)\n    .map(([skill, stats]) => ({ skill, stats }))\n    .sort((a, b) => b.stats.count - a.stats.count)\n    .slice(0, limit);\n}\n\n/**\n * Get top N used agents for a user\n */\nexport function getTopAgents(profile: UserProfile, limit: number = 5): Array<{\n  agent: string;\n  stats: UsageStats;\n}> {\n  return Object.entries(profile.agent_usage)\n    .map(([agent, stats]) => ({ agent, stats }))\n    .sort((a, b) => b.stats.count - a.stats.count)\n    .slice(0, limit);\n}\n\n/**\n * Get user's preferred tool for a category\n */\nexport function getPreferredTool(\n  profile: UserProfile,\n  category: string\n): string | undefined {\n  const pref = profile.preferences.find(p => p.category === category);\n  return pref?.preference;\n}\n\n/**\n * Get recent decisions for a user\n */\nexport function getRecentDecisions(\n  profile: UserProfile,\n  limit: number = 10\n): RecordedDecision[] {\n  return profile.decisions.slice(0, limit);\n}\n\n/**\n * Check if user has made a specific type of decision before\n */\nexport function hasDecisionAbout(\n  profile: UserProfile,\n  keyword: string\n): RecordedDecision | undefined {\n  const lower = keyword.toLowerCase();\n  return profile.decisions.find(\n    d =>\n      d.what.toLowerCase().includes(lower) ||\n      d.rationale?.toLowerCase().includes(lower)\n  );\n}\n\n// =============================================================================\n// PROFILE EXPORT (for sharing)\n// =============================================================================\n\n/**\n * Export profile for team sharing (respects privacy settings)\n */\nexport function exportForTeam(profile: UserProfile): Partial<UserProfile> {\n  return {\n    user_id: profile.user_id,\n    display_name: profile.display_name,\n    team_id: profile.team_id,\n    skill_usage: profile.skill_usage,\n    agent_usage: profile.agent_usage,\n    decisions: profile.decisions,\n    preferences: profile.preferences,\n  };\n}\n\n/**\n * Export profile for global sharing (anonymized)\n */\nexport function exportForGlobal(profile: UserProfile): {\n  anonymous_id: string;\n  decisions: Array<Omit<RecordedDecision, 'project'>>;\n  preferences: RecordedPreference[];\n} {\n  // Remove project info from decisions for privacy\n  const anonDecisions = profile.decisions.map(d => {\n    const { project, ...rest } = d;\n    return rest;\n  });\n\n  return {\n    anonymous_id: profile.anonymous_id,\n    decisions: anonDecisions,\n    preferences: profile.preferences,\n  };\n}\n", "/**\n * Decision Flow Tracker - Cross-tool correlation for understanding decision patterns\n *\n * Part of Intelligent Decision Capture System\n *\n * Purpose:\n * - Track sequence of tool actions within a session\n * - Infer workflow patterns (TDD, explore-first, iterate-fast)\n * - Detect when a decision flow completes\n * - Enable understanding of how decisions are made across multiple tools\n *\n * CC 2.1.16 Compliant\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync, appendFileSync } from 'node:fs';\nimport { join, dirname } from 'node:path';\nimport { getProjectDir, logHook } from './common.js';\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * A single tool action in the decision flow\n */\nexport interface ToolAction {\n  /** Tool name (Bash, Read, Write, etc.) */\n  tool: string;\n  /** File involved if applicable */\n  file?: string;\n  /** When the action occurred */\n  timestamp: string;\n  /** Brief summary of what was done */\n  summary: string;\n  /** Result of the action */\n  result: 'success' | 'failure' | 'partial';\n  /** Exit code for Bash */\n  exit_code?: number;\n  /** Action category */\n  category: ActionCategory;\n}\n\n/**\n * Categories for tool actions\n */\nexport type ActionCategory =\n  | 'exploration'  // Read, Glob, Grep\n  | 'modification' // Write, Edit\n  | 'execution'    // Bash\n  | 'testing'      // Bash with test commands\n  | 'building'     // Bash with build commands\n  | 'git'          // Git operations\n  | 'agent'        // Task (subagent spawn)\n  | 'other';\n\n/**\n * Detected workflow pattern\n */\nexport type WorkflowPattern =\n  | 'test-first'      // Tests before implementation (TDD)\n  | 'explore-first'   // Read multiple files before writing\n  | 'iterate-fast'    // Write \u2192 Execute \u2192 Write cycles\n  | 'big-bang'        // Multiple writes then one test\n  | 'agent-delegate'  // Heavy use of Task tool\n  | 'mixed';          // No clear pattern\n\n/**\n * Complete decision flow for a session\n */\nexport interface DecisionFlow {\n  /** Session ID */\n  session_id: string;\n  /** Sequence of actions */\n  actions: ToolAction[];\n  /** Detected workflow pattern */\n  inferred_pattern?: WorkflowPattern;\n  /** When the flow started */\n  started_at: string;\n  /** Last action timestamp */\n  last_action_at: string;\n  /** Summary statistics */\n  stats: FlowStats;\n}\n\n/**\n * Statistics about the decision flow\n */\nexport interface FlowStats {\n  total_actions: number;\n  reads: number;\n  writes: number;\n  tests: number;\n  builds: number;\n  agent_spawns: number;\n  success_rate: number;\n}\n\n// =============================================================================\n// PATTERN DETECTION\n// =============================================================================\n\n/**\n * Patterns for categorizing actions\n */\nconst TEST_COMMAND_PATTERNS = [\n  /\\b(pytest|jest|vitest|npm\\s+test|yarn\\s+test|bun\\s+test|go\\s+test)\\b/i,\n  /\\b(test|tests|spec)\\b.*\\b(run|execute)\\b/i,\n];\n\nconst BUILD_COMMAND_PATTERNS = [\n  /\\b(npm\\s+run\\s+build|yarn\\s+build|make|cargo\\s+build|docker\\s+build|tsc)\\b/i,\n  /\\b(build|compile)\\b/i,\n];\n\nconst GIT_COMMAND_PATTERNS = [\n  /\\bgit\\s+(commit|push|pull|merge|rebase|checkout|branch|status|diff|log)\\b/i,\n  /\\bgh\\s+(pr|issue)\\b/i,\n];\n\n// =============================================================================\n// FILE OPERATIONS\n// =============================================================================\n\n/**\n * Get path to session flow file\n */\nfunction getFlowFilePath(sessionId: string): string {\n  return join(getProjectDir(), '.claude', 'memory', 'flows', `${sessionId}.json`);\n}\n\n/**\n * Get path to completed flows archive\n */\nfunction getCompletedFlowsPath(): string {\n  return join(getProjectDir(), '.claude', 'memory', 'completed-flows.jsonl');\n}\n\n/**\n * Load decision flow for a session\n */\nexport function loadDecisionFlow(sessionId: string): DecisionFlow | null {\n  const filePath = getFlowFilePath(sessionId);\n\n  if (!existsSync(filePath)) {\n    return null;\n  }\n\n  try {\n    const content = readFileSync(filePath, 'utf-8');\n    return JSON.parse(content) as DecisionFlow;\n  } catch (err) {\n    logHook('decision-flow-tracker', `Failed to load flow for ${sessionId}: ${err}`, 'warn');\n    return null;\n  }\n}\n\n/**\n * Save decision flow for a session\n */\nfunction saveDecisionFlow(flow: DecisionFlow): boolean {\n  const filePath = getFlowFilePath(flow.session_id);\n\n  try {\n    const dir = dirname(filePath);\n    if (!existsSync(dir)) {\n      mkdirSync(dir, { recursive: true });\n    }\n\n    writeFileSync(filePath, JSON.stringify(flow, null, 2));\n    return true;\n  } catch (err) {\n    logHook('decision-flow-tracker', `Failed to save flow: ${err}`, 'warn');\n    return false;\n  }\n}\n\n/**\n * Archive a completed flow\n */\nfunction archiveFlow(flow: DecisionFlow): boolean {\n  const archivePath = getCompletedFlowsPath();\n\n  try {\n    const dir = dirname(archivePath);\n    if (!existsSync(dir)) {\n      mkdirSync(dir, { recursive: true });\n    }\n\n    const line = JSON.stringify(flow) + '\\n';\n    appendFileSync(archivePath, line);\n    return true;\n  } catch (err) {\n    logHook('decision-flow-tracker', `Failed to archive flow: ${err}`, 'warn');\n    return false;\n  }\n}\n\n// =============================================================================\n// ACTION CATEGORIZATION\n// =============================================================================\n\n/**\n * Categorize a tool action\n */\nexport function categorizeAction(\n  tool: string,\n  command?: string,\n  _file?: string\n): ActionCategory {\n  // Check for specific tool types\n  if (tool === 'Read' || tool === 'Glob' || tool === 'Grep') {\n    return 'exploration';\n  }\n\n  if (tool === 'Write' || tool === 'Edit' || tool === 'MultiEdit' || tool === 'NotebookEdit') {\n    return 'modification';\n  }\n\n  if (tool === 'Task') {\n    return 'agent';\n  }\n\n  // For Bash, check command patterns\n  if (tool === 'Bash' && command) {\n    if (TEST_COMMAND_PATTERNS.some(p => p.test(command))) {\n      return 'testing';\n    }\n    if (BUILD_COMMAND_PATTERNS.some(p => p.test(command))) {\n      return 'building';\n    }\n    if (GIT_COMMAND_PATTERNS.some(p => p.test(command))) {\n      return 'git';\n    }\n    return 'execution';\n  }\n\n  return 'other';\n}\n\n/**\n * Summarize a tool action\n */\nexport function summarizeAction(\n  tool: string,\n  command?: string,\n  file?: string,\n  result?: 'success' | 'failure' | 'partial'\n): string {\n  const resultStr = result === 'success' ? '\u2713' : result === 'failure' ? '\u2717' : '~';\n\n  if (tool === 'Read') {\n    return `${resultStr} Read ${file?.split('/').pop() || 'file'}`;\n  }\n  if (tool === 'Write') {\n    return `${resultStr} Write ${file?.split('/').pop() || 'file'}`;\n  }\n  if (tool === 'Edit') {\n    return `${resultStr} Edit ${file?.split('/').pop() || 'file'}`;\n  }\n  if (tool === 'Glob') {\n    return `${resultStr} Search files`;\n  }\n  if (tool === 'Grep') {\n    return `${resultStr} Search content`;\n  }\n  if (tool === 'Task') {\n    return `${resultStr} Spawn agent`;\n  }\n\n  if (tool === 'Bash' && command) {\n    // Extract meaningful part of command\n    const cmd = command.split('\\n')[0].slice(0, 50);\n    return `${resultStr} ${cmd}${command.length > 50 ? '...' : ''}`;\n  }\n\n  return `${resultStr} ${tool}`;\n}\n\n// =============================================================================\n// PATTERN INFERENCE\n// =============================================================================\n\n/**\n * Infer workflow pattern from action sequence\n */\nexport function inferWorkflowPattern(actions: ToolAction[]): WorkflowPattern {\n  if (actions.length < 3) {\n    return 'mixed';\n  }\n\n  // Count categories\n  const counts = {\n    exploration: 0,\n    modification: 0,\n    testing: 0,\n    building: 0,\n    agent: 0,\n    execution: 0,\n    git: 0,\n    other: 0,\n  };\n\n  for (const action of actions) {\n    counts[action.category]++;\n  }\n\n  // Check for test-first pattern\n  // Pattern: test \u2192 write \u2192 test\n  if (counts.testing >= 2) {\n    const testIndices = actions\n      .map((a, i) => (a.category === 'testing' ? i : -1))\n      .filter(i => i >= 0);\n    const writeIndices = actions\n      .map((a, i) => (a.category === 'modification' ? i : -1))\n      .filter(i => i >= 0);\n\n    if (testIndices.length >= 2 && writeIndices.length > 0) {\n      // Check if first test comes before first write\n      if (testIndices[0] < writeIndices[0]) {\n        return 'test-first';\n      }\n    }\n  }\n\n  // Check for explore-first pattern\n  // Pattern: read \u2192 read \u2192 read \u2192 write\n  if (counts.exploration >= 3 && counts.modification > 0) {\n    const exploreRun = findConsecutiveRun(actions, 'exploration');\n    if (exploreRun >= 3) {\n      return 'explore-first';\n    }\n  }\n\n  // Check for iterate-fast pattern\n  // Pattern: write \u2192 execute \u2192 write \u2192 execute\n  if (counts.modification >= 2 && (counts.execution + counts.testing) >= 2) {\n    const alternating = countAlternations(actions, 'modification', ['execution', 'testing']);\n    if (alternating >= 2) {\n      return 'iterate-fast';\n    }\n  }\n\n  // Check for agent-delegate pattern\n  if (counts.agent >= 3 || counts.agent / actions.length > 0.3) {\n    return 'agent-delegate';\n  }\n\n  // Check for big-bang pattern\n  // Pattern: write \u2192 write \u2192 write \u2192 test\n  if (counts.modification >= 3 && counts.testing === 1) {\n    const lastTest = actions.map((a, i) => (a.category === 'testing' ? i : -1)).filter(i => i >= 0).pop();\n    if (lastTest && lastTest > actions.length - 3) {\n      return 'big-bang';\n    }\n  }\n\n  return 'mixed';\n}\n\n/**\n * Find longest consecutive run of a category\n */\nfunction findConsecutiveRun(actions: ToolAction[], category: ActionCategory): number {\n  let maxRun = 0;\n  let currentRun = 0;\n\n  for (const action of actions) {\n    if (action.category === category) {\n      currentRun++;\n      maxRun = Math.max(maxRun, currentRun);\n    } else {\n      currentRun = 0;\n    }\n  }\n\n  return maxRun;\n}\n\n/**\n * Count alternations between category A and categories B\n */\nfunction countAlternations(\n  actions: ToolAction[],\n  categoryA: ActionCategory,\n  categoriesB: ActionCategory[]\n): number {\n  let alternations = 0;\n  let lastWasA = false;\n\n  for (const action of actions) {\n    const isA = action.category === categoryA;\n    const isB = categoriesB.includes(action.category);\n\n    if (isA && !lastWasA) {\n      lastWasA = true;\n    } else if (isB && lastWasA) {\n      alternations++;\n      lastWasA = false;\n    }\n  }\n\n  return alternations;\n}\n\n// =============================================================================\n// FLOW MANAGEMENT\n// =============================================================================\n\n/**\n * Calculate flow statistics\n */\nfunction calculateStats(actions: ToolAction[]): FlowStats {\n  const successes = actions.filter(a => a.result === 'success').length;\n\n  return {\n    total_actions: actions.length,\n    reads: actions.filter(a => a.category === 'exploration').length,\n    writes: actions.filter(a => a.category === 'modification').length,\n    tests: actions.filter(a => a.category === 'testing').length,\n    builds: actions.filter(a => a.category === 'building').length,\n    agent_spawns: actions.filter(a => a.category === 'agent').length,\n    success_rate: actions.length > 0 ? successes / actions.length : 0,\n  };\n}\n\n/**\n * Track a tool action in the decision flow\n */\nexport function trackToolAction(\n  sessionId: string,\n  tool: string,\n  command: string | undefined,\n  file: string | undefined,\n  exitCode: number | undefined\n): DecisionFlow {\n  const timestamp = new Date().toISOString();\n\n  // Determine result from exit code\n  let result: 'success' | 'failure' | 'partial' = 'success';\n  if (exitCode !== undefined) {\n    result = exitCode === 0 ? 'success' : 'failure';\n  }\n\n  // Categorize and summarize the action\n  const category = categorizeAction(tool, command, file);\n  const summary = summarizeAction(tool, command, file, result);\n\n  const action: ToolAction = {\n    tool,\n    file,\n    timestamp,\n    summary,\n    result,\n    exit_code: exitCode,\n    category,\n  };\n\n  // Load or create flow\n  let flow = loadDecisionFlow(sessionId);\n\n  if (!flow) {\n    flow = {\n      session_id: sessionId,\n      actions: [],\n      started_at: timestamp,\n      last_action_at: timestamp,\n      stats: calculateStats([]),\n    };\n  }\n\n  // Add action (limit to last 100 actions to prevent unbounded growth)\n  flow.actions.push(action);\n  if (flow.actions.length > 100) {\n    flow.actions = flow.actions.slice(-100);\n  }\n\n  // Update metadata\n  flow.last_action_at = timestamp;\n  flow.inferred_pattern = inferWorkflowPattern(flow.actions);\n  flow.stats = calculateStats(flow.actions);\n\n  // Save\n  saveDecisionFlow(flow);\n\n  return flow;\n}\n\n/**\n * Analyze the decision flow for a session\n */\nexport function analyzeDecisionFlow(sessionId: string): DecisionFlow | null {\n  const flow = loadDecisionFlow(sessionId);\n\n  if (!flow) {\n    return null;\n  }\n\n  // Ensure pattern is up to date\n  flow.inferred_pattern = inferWorkflowPattern(flow.actions);\n  flow.stats = calculateStats(flow.actions);\n\n  return flow;\n}\n\n/**\n * Complete and archive a decision flow (called on session end)\n */\nexport function completeDecisionFlow(sessionId: string): boolean {\n  const flow = loadDecisionFlow(sessionId);\n\n  if (!flow) {\n    return false;\n  }\n\n  // Update final analysis\n  flow.inferred_pattern = inferWorkflowPattern(flow.actions);\n  flow.stats = calculateStats(flow.actions);\n\n  // Archive\n  const archived = archiveFlow(flow);\n\n  if (archived) {\n    logHook(\n      'decision-flow-tracker',\n      `Completed flow for ${sessionId}: ${flow.actions.length} actions, pattern: ${flow.inferred_pattern}`,\n      'info'\n    );\n  }\n\n  return archived;\n}\n\n// =============================================================================\n// GAP-010 FIX: Removed getRecentFlows()\n// Function was exported but never called by production code.\n// Cross-session flow analysis should be added to workflow-preference-learner if needed.\n// =============================================================================\n", "/**\n * Session Profile Aggregator - Aggregate session data into user profile at session end\n *\n * Part of Intelligent Decision Capture System\n *\n * This hook runs at session end to:\n * 1. Generate session summary from events\n * 2. Aggregate into user profile (skills, agents, decisions)\n * 3. Save updated profile to disk\n * 4. Export generalizable decisions for global sharing (if enabled)\n *\n * CC 2.1.7 Compliant: Uses outputSilentSuccess for silent operation\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, outputSilentSuccess } from '../lib/common.js';\nimport { resolveUserIdentity, canShare, getPrivacySettings } from '../lib/user-identity.js';\n// GAP-012: Removed trackSessionEnd import - handled by session-end-tracking.ts\nimport { generateSessionSummary } from '../lib/session-tracker.js';\nimport {\n  loadUserProfile,\n  saveUserProfile,\n  aggregateSession,\n  exportForGlobal,\n} from '../lib/user-profile.js';\n\n/**\n * Aggregate session data into user profile\n */\nexport function sessionProfileAggregator(input: HookInput): HookResult {\n  try {\n    // GAP-012: trackSessionEnd() removed - handled by session-end-tracking.ts hook\n    // Both hooks run in Stop dispatcher, avoiding duplicate session_end events\n\n    // Get user identity\n    const identity = resolveUserIdentity();\n    logHook('session-profile-aggregator', `Aggregating session for ${identity.user_id}`, 'debug');\n\n    // Generate session summary\n    const summary = generateSessionSummary();\n\n    // Skip if no meaningful activity\n    if (\n      summary.skills_used.length === 0 &&\n      summary.agents_spawned.length === 0 &&\n      summary.decisions_made === 0\n    ) {\n      logHook('session-profile-aggregator', 'No meaningful activity to aggregate', 'debug');\n      return outputSilentSuccess();\n    }\n\n    // Load and update user profile\n    const profile = loadUserProfile(identity.user_id);\n    const updatedProfile = aggregateSession(profile, summary);\n\n    // Save updated profile\n    const saved = saveUserProfile(updatedProfile);\n    if (!saved) {\n      logHook('session-profile-aggregator', 'Failed to save profile', 'warn');\n      return outputSilentSuccess();\n    }\n\n    logHook(\n      'session-profile-aggregator',\n      `Aggregated session: ${summary.skills_used.length} skills, ${summary.agents_spawned.length} agents, ${summary.decisions_made} decisions`,\n      'info'\n    );\n\n    // Export for global sharing if privacy allows\n    const privacy = getPrivacySettings();\n    if (privacy.share_globally && canShare('decisions', 'global')) {\n      const globalExport = exportForGlobal(updatedProfile);\n\n      // Only export if there are decisions worth sharing\n      const generalizableDecisions = globalExport.decisions.filter(\n        d => d.confidence >= 0.8 && d.rationale\n      );\n\n      if (generalizableDecisions.length > 0) {\n        logHook(\n          'session-profile-aggregator',\n          `${generalizableDecisions.length} decisions eligible for global sharing`,\n          'info'\n        );\n        // Note: Actual export to mem0 happens via batch-sync.py or mem0-pre-compaction-sync\n      }\n    }\n\n    return outputSilentSuccess();\n  } catch (error) {\n    logHook('session-profile-aggregator', `Error aggregating session: ${error}`, 'error');\n    return outputSilentSuccess();\n  }\n}\n", "/**\n * Session End Tracking Hook\n * Issue #245: Multi-User Intelligent Decision Capture System\n *\n * Tracks session end event to finalize session in user profile.\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { outputSilentSuccess, logHook } from '../lib/common.js';\nimport { trackSessionEnd } from '../lib/session-tracker.js';\n\n/**\n * Track session end event\n */\nexport function sessionEndTracking(_input: HookInput): HookResult {\n  try {\n    trackSessionEnd();\n    logHook('session-end-tracking', 'Tracked session end', 'debug');\n    return outputSilentSuccess();\n  } catch (error) {\n    logHook('session-end-tracking', `Error: ${error}`, 'warn');\n    return outputSilentSuccess();\n  }\n}\n", "/**\n * Graph Queue Sync - Process queued graph operations at session end\n *\n * Part of Issue #245: Multi-User Intelligent Decision Capture System\n *\n * This hook reads the graph-queue.jsonl file and outputs a systemMessage\n * prompting Claude to execute the queued MCP graph operations.\n *\n * The queue contains:\n * - create_entities: New entities to create in the knowledge graph\n * - create_relations: Relations between entities\n * - add_observations: New observations to add to existing entities\n *\n * CC 2.1.19 Compliant: Outputs systemMessage for Claude to act on\n */\n\nimport { existsSync, readFileSync, unlinkSync } from 'node:fs';\nimport { join } from 'node:path';\nimport type { HookInput, HookResult } from '../types.js';\nimport { getProjectDir, logHook, outputSilentSuccess } from '../lib/common.js';\nimport type { QueuedGraphOperation, GraphEntity, GraphRelation } from '../lib/memory-writer.js';\n\n// =============================================================================\n// PATHS\n// =============================================================================\n\n/**\n * Get path to graph operations queue\n */\nfunction getGraphQueuePath(): string {\n  return join(getProjectDir(), '.claude', 'memory', 'graph-queue.jsonl');\n}\n\n/**\n * Get path to processed queue archive (for debugging)\n */\n\n// =============================================================================\n// QUEUE READING\n// =============================================================================\n\n/**\n * Read all queued operations from the graph queue\n */\nfunction readQueuedOperations(): QueuedGraphOperation[] {\n  const queuePath = getGraphQueuePath();\n\n  if (!existsSync(queuePath)) {\n    return [];\n  }\n\n  try {\n    const content = readFileSync(queuePath, 'utf8');\n    const lines = content.trim().split('\\n').filter(line => line.trim());\n\n    const operations: QueuedGraphOperation[] = [];\n    for (const line of lines) {\n      try {\n        const op = JSON.parse(line) as QueuedGraphOperation;\n        operations.push(op);\n      } catch {\n        logHook('graph-queue-sync', `Failed to parse queue line: ${line.slice(0, 100)}`, 'warn');\n      }\n    }\n\n    return operations;\n  } catch (error) {\n    logHook('graph-queue-sync', `Failed to read queue: ${error}`, 'warn');\n    return [];\n  }\n}\n\n/**\n * Clear the queue after processing\n */\nfunction clearQueue(): void {\n  const queuePath = getGraphQueuePath();\n\n  if (existsSync(queuePath)) {\n    try {\n      unlinkSync(queuePath);\n      logHook('graph-queue-sync', 'Cleared graph queue', 'debug');\n    } catch (error) {\n      logHook('graph-queue-sync', `Failed to clear queue: ${error}`, 'warn');\n    }\n  }\n}\n\n// =============================================================================\n// OPERATION AGGREGATION\n// =============================================================================\n\n/**\n * Aggregate multiple operations into batched calls\n * Combines all create_entities into one call, all create_relations into one call, etc.\n */\nfunction aggregateOperations(operations: QueuedGraphOperation[]): {\n  entities: GraphEntity[];\n  relations: GraphRelation[];\n  observations: Array<{ entityName: string; contents: string[] }>;\n} {\n  const entities: GraphEntity[] = [];\n  const relations: GraphRelation[] = [];\n  const observations: Array<{ entityName: string; contents: string[] }> = [];\n\n  // Track seen entity names to avoid duplicates\n  const seenEntities = new Set<string>();\n  const seenRelations = new Set<string>();\n\n  for (const op of operations) {\n    if (op.type === 'create_entities' && op.payload.entities) {\n      for (const entity of op.payload.entities) {\n        if (!seenEntities.has(entity.name)) {\n          entities.push(entity);\n          seenEntities.add(entity.name);\n        }\n      }\n    }\n\n    if (op.type === 'create_relations' && op.payload.relations) {\n      for (const rel of op.payload.relations) {\n        const key = `${rel.from}|${rel.relationType}|${rel.to}`;\n        if (!seenRelations.has(key)) {\n          relations.push(rel);\n          seenRelations.add(key);\n        }\n      }\n    }\n\n    if (op.type === 'add_observations' && op.payload.observations) {\n      // Merge observations for same entity\n      for (const obs of op.payload.observations) {\n        const existing = observations.find(o => o.entityName === obs.entityName);\n        if (existing) {\n          existing.contents.push(...obs.contents);\n        } else {\n          observations.push({ ...obs });\n        }\n      }\n    }\n  }\n\n  return { entities, relations, observations };\n}\n\n// =============================================================================\n// MESSAGE GENERATION\n// =============================================================================\n\n/**\n * Generate a systemMessage for Claude to execute the graph operations\n */\nfunction generateSystemMessage(aggregated: {\n  entities: GraphEntity[];\n  relations: GraphRelation[];\n  observations: Array<{ entityName: string; contents: string[] }>;\n}): string {\n  const { entities, relations, observations } = aggregated;\n\n  if (entities.length === 0 && relations.length === 0 && observations.length === 0) {\n    return '';\n  }\n\n  const parts: string[] = [\n    '## Graph Memory Sync',\n    '',\n    'The following decisions and patterns were captured this session.',\n    'To persist them to the knowledge graph, execute these MCP calls:',\n    '',\n  ];\n\n  if (entities.length > 0) {\n    parts.push('### Create Entities');\n    parts.push('```json');\n    parts.push(`mcp__memory__create_entities({`);\n    parts.push(`  \"entities\": ${JSON.stringify(entities, null, 2).split('\\n').map((l, i) => i === 0 ? l : '  ' + l).join('\\n')}`);\n    parts.push(`})`);\n    parts.push('```');\n    parts.push('');\n  }\n\n  if (relations.length > 0) {\n    parts.push('### Create Relations');\n    parts.push('```json');\n    parts.push(`mcp__memory__create_relations({`);\n    parts.push(`  \"relations\": ${JSON.stringify(relations, null, 2).split('\\n').map((l, i) => i === 0 ? l : '  ' + l).join('\\n')}`);\n    parts.push(`})`);\n    parts.push('```');\n    parts.push('');\n  }\n\n  if (observations.length > 0) {\n    parts.push('### Add Observations');\n    parts.push('```json');\n    parts.push(`mcp__memory__add_observations({`);\n    parts.push(`  \"observations\": ${JSON.stringify(observations, null, 2).split('\\n').map((l, i) => i === 0 ? l : '  ' + l).join('\\n')}`);\n    parts.push(`})`);\n    parts.push('```');\n    parts.push('');\n  }\n\n  parts.push(`**Summary:** ${entities.length} entities, ${relations.length} relations, ${observations.length} observations to sync.`);\n\n  return parts.join('\\n');\n}\n\n// =============================================================================\n// HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Process the graph queue at session end\n *\n * This hook:\n * 1. Reads all queued operations from graph-queue.jsonl\n * 2. Aggregates them to remove duplicates\n * 3. Outputs a systemMessage with MCP calls for Claude to execute\n * 4. Clears the queue\n */\nexport function graphQueueSync(_input: HookInput): HookResult {\n  // Read queued operations\n  const operations = readQueuedOperations();\n\n  if (operations.length === 0) {\n    logHook('graph-queue-sync', 'No queued graph operations', 'debug');\n    return outputSilentSuccess();\n  }\n\n  logHook('graph-queue-sync', `Processing ${operations.length} queued operations`, 'info');\n\n  // Aggregate operations\n  const aggregated = aggregateOperations(operations);\n\n  // Generate system message\n  const systemMessage = generateSystemMessage(aggregated);\n\n  // Clear the queue\n  clearQueue();\n\n  if (!systemMessage) {\n    return outputSilentSuccess();\n  }\n\n  // Return with systemMessage for Claude to see\n  return {\n    continue: true,\n    systemMessage,\n  };\n}\n\n// Default export for hook system\nexport default graphQueueSync;\n", "/**\n * Workflow Preference Learner Hook - Learn user's development workflow patterns\n *\n * Part of Intelligent Decision Capture System\n * Hook: Stop\n *\n * Purpose:\n * - Analyze the session's decision flow on completion\n * - Detect workflow patterns (TDD, explore-first, iterate-fast)\n * - Track patterns across sessions for learning\n * - Store workflow preferences\n *\n * Patterns Detected:\n * - test-first: TDD workflow (tests before implementation)\n * - explore-first: Read files before writing\n * - iterate-fast: Quick write \u2192 test cycles\n * - big-bang: Multiple writes then test\n * - agent-delegate: Heavy use of subagents\n *\n * CC 2.1.16 Compliant\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport {\n  outputSilentSuccess,\n  getProjectDir,\n  getSessionId,\n  logHook,\n} from '../lib/common.js';\nimport {\n  analyzeDecisionFlow,\n  completeDecisionFlow,\n  type WorkflowPattern,\n  type DecisionFlow,\n} from '../lib/decision-flow-tracker.js';\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { join, dirname } from 'node:path';\n\n// =============================================================================\n// CONSTANTS\n// =============================================================================\n\nconst HOOK_NAME = 'workflow-preference-learner';\nconst MIN_ACTIONS_FOR_PATTERN = 5; // Need at least 5 actions to detect pattern\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * Workflow preference with statistics\n */\nexport interface WorkflowPreference {\n  /** The workflow pattern */\n  pattern: WorkflowPattern;\n  /** How often this pattern is used (0-1) */\n  frequency: number;\n  /** Number of sessions with this pattern */\n  count: number;\n  /** Total sessions analyzed */\n  total_sessions: number;\n  /** Average success rate for this pattern */\n  avg_success_rate: number;\n  /** Last updated timestamp */\n  updated_at: string;\n}\n\n/**\n * All workflow preferences data\n */\ninterface WorkflowPreferencesData {\n  /** Count of each pattern */\n  pattern_counts: Record<WorkflowPattern, number>;\n  /** Success rates for each pattern */\n  pattern_success_rates: Record<WorkflowPattern, number[]>;\n  /** Total sessions analyzed */\n  total_sessions: number;\n  /** Derived preferences */\n  preferences: WorkflowPreference[];\n  /** Last update timestamp */\n  updated_at: string;\n}\n\n// =============================================================================\n// FILE OPERATIONS\n// =============================================================================\n\n/**\n * Get path to workflow preferences file\n */\nfunction getWorkflowPreferencesPath(): string {\n  return join(getProjectDir(), '.claude', 'memory', 'workflow-preferences.json');\n}\n\n/**\n * Load workflow preferences data\n */\nfunction loadWorkflowPreferences(): WorkflowPreferencesData {\n  const filePath = getWorkflowPreferencesPath();\n\n  if (!existsSync(filePath)) {\n    return createEmptyWorkflowPreferences();\n  }\n\n  try {\n    const content = readFileSync(filePath, 'utf-8');\n    return JSON.parse(content) as WorkflowPreferencesData;\n  } catch {\n    return createEmptyWorkflowPreferences();\n  }\n}\n\n/**\n * Save workflow preferences data\n */\nfunction saveWorkflowPreferences(data: WorkflowPreferencesData): boolean {\n  const filePath = getWorkflowPreferencesPath();\n\n  try {\n    const dir = dirname(filePath);\n    if (!existsSync(dir)) {\n      mkdirSync(dir, { recursive: true });\n    }\n\n    writeFileSync(filePath, JSON.stringify(data, null, 2));\n    return true;\n  } catch (err) {\n    logHook(HOOK_NAME, `Failed to save workflow preferences: ${err}`, 'warn');\n    return false;\n  }\n}\n\n/**\n * Create empty workflow preferences structure\n */\nfunction createEmptyWorkflowPreferences(): WorkflowPreferencesData {\n  const patterns: WorkflowPattern[] = [\n    'test-first', 'explore-first', 'iterate-fast', 'big-bang', 'agent-delegate', 'mixed',\n  ];\n\n  const pattern_counts: Record<WorkflowPattern, number> = {} as Record<WorkflowPattern, number>;\n  const pattern_success_rates: Record<WorkflowPattern, number[]> = {} as Record<WorkflowPattern, number[]>;\n\n  for (const pattern of patterns) {\n    pattern_counts[pattern] = 0;\n    pattern_success_rates[pattern] = [];\n  }\n\n  return {\n    pattern_counts,\n    pattern_success_rates,\n    total_sessions: 0,\n    preferences: [],\n    updated_at: new Date().toISOString(),\n  };\n}\n\n// =============================================================================\n// PREFERENCE CALCULATION\n// =============================================================================\n\n/**\n * Calculate preferences from pattern data\n */\nfunction calculateWorkflowPreferences(data: WorkflowPreferencesData): WorkflowPreference[] {\n  const preferences: WorkflowPreference[] = [];\n  const timestamp = new Date().toISOString();\n\n  for (const [pattern, count] of Object.entries(data.pattern_counts)) {\n    if (count === 0) continue;\n\n    const successRates = data.pattern_success_rates[pattern as WorkflowPattern] || [];\n    const avgSuccessRate = successRates.length > 0\n      ? successRates.reduce((a, b) => a + b, 0) / successRates.length\n      : 0;\n\n    preferences.push({\n      pattern: pattern as WorkflowPattern,\n      frequency: data.total_sessions > 0 ? count / data.total_sessions : 0,\n      count,\n      total_sessions: data.total_sessions,\n      avg_success_rate: avgSuccessRate,\n      updated_at: timestamp,\n    });\n  }\n\n  // Sort by frequency descending\n  preferences.sort((a, b) => b.frequency - a.frequency);\n\n  return preferences;\n}\n\n/**\n * Update workflow preferences with a new session's pattern\n */\nfunction updateWorkflowPreferences(\n  data: WorkflowPreferencesData,\n  flow: DecisionFlow\n): void {\n  if (!flow.inferred_pattern) return;\n\n  const pattern = flow.inferred_pattern;\n  const successRate = flow.stats.success_rate;\n\n  // Update counts\n  data.pattern_counts[pattern] = (data.pattern_counts[pattern] || 0) + 1;\n  data.total_sessions++;\n\n  // Update success rates (keep last 20 per pattern)\n  if (!data.pattern_success_rates[pattern]) {\n    data.pattern_success_rates[pattern] = [];\n  }\n  data.pattern_success_rates[pattern].push(successRate);\n  if (data.pattern_success_rates[pattern].length > 20) {\n    data.pattern_success_rates[pattern] = data.pattern_success_rates[pattern].slice(-20);\n  }\n\n  // Recalculate preferences\n  data.preferences = calculateWorkflowPreferences(data);\n  data.updated_at = new Date().toISOString();\n}\n\n// =============================================================================\n// MAIN HOOK\n// =============================================================================\n\n/**\n * Learn workflow preferences from completed session\n */\nexport function workflowPreferenceLearner(input: HookInput): HookResult {\n  const sessionId = input.session_id || getSessionId();\n\n  // Analyze the decision flow\n  const flow = analyzeDecisionFlow(sessionId);\n\n  if (!flow) {\n    logHook(HOOK_NAME, `No decision flow found for session ${sessionId}`, 'debug');\n    return outputSilentSuccess();\n  }\n\n  // Need minimum actions to detect meaningful pattern\n  if (flow.actions.length < MIN_ACTIONS_FOR_PATTERN) {\n    logHook(HOOK_NAME, `Too few actions (${flow.actions.length}) for pattern detection`, 'debug');\n    return outputSilentSuccess();\n  }\n\n  // Complete and archive the flow\n  completeDecisionFlow(sessionId);\n\n  // Skip 'mixed' patterns as they don't provide learning value\n  if (flow.inferred_pattern === 'mixed') {\n    return outputSilentSuccess();\n  }\n\n  // Load and update preferences\n  const data = loadWorkflowPreferences();\n  updateWorkflowPreferences(data, flow);\n  saveWorkflowPreferences(data);\n\n  // Log the detected pattern\n  logHook(\n    HOOK_NAME,\n    `Session pattern: ${flow.inferred_pattern} (${flow.actions.length} actions, ${(flow.stats.success_rate * 100).toFixed(0)}% success)`,\n    'info'\n  );\n\n  // Check for strong preference emergence\n  const topPref = data.preferences[0];\n  if (topPref && topPref.frequency > 0.6 && topPref.count >= 5) {\n    logHook(\n      HOOK_NAME,\n      `Strong workflow preference: ${topPref.pattern} (${(topPref.frequency * 100).toFixed(0)}% of sessions)`,\n      'info'\n    );\n  }\n\n  return outputSilentSuccess();\n}\n\n// =============================================================================\n// EXPORTS FOR OTHER HOOKS\n// =============================================================================\n\n/**\n * Get the user's primary workflow preference\n */\nexport function getPrimaryWorkflowPreference(): WorkflowPreference | null {\n  const data = loadWorkflowPreferences();\n  return data.preferences[0] || null;\n}\n\n/**\n * Get all workflow preferences\n */\nexport function getAllWorkflowPreferences(): WorkflowPreference[] {\n  const data = loadWorkflowPreferences();\n  return data.preferences;\n}\n\n/**\n * Get workflow pattern summary for context injection\n */\nexport function getWorkflowSummary(): string | null {\n  const data = loadWorkflowPreferences();\n\n  if (data.total_sessions < 3) {\n    return null; // Not enough data\n  }\n\n  const primary = data.preferences[0];\n  if (!primary || primary.frequency < 0.4) {\n    return null; // No clear preference\n  }\n\n  const patternDescriptions: Record<WorkflowPattern, string> = {\n    'test-first': 'writes tests before implementation (TDD)',\n    'explore-first': 'reads existing code before making changes',\n    'iterate-fast': 'makes quick write \u2192 test iterations',\n    'big-bang': 'writes multiple files then tests',\n    'agent-delegate': 'delegates tasks to specialized agents',\n    'mixed': 'varies approach by task',\n  };\n\n  return `User typically ${patternDescriptions[primary.pattern]} (${(primary.frequency * 100).toFixed(0)}% of sessions, ${(primary.avg_success_rate * 100).toFixed(0)}% success rate)`;\n}\n", "/**\n * Mem0 Queue Sync - Process queued mem0 operations at session end\n *\n * Part of Issue #245: Multi-User Intelligent Decision Capture System\n * GAP-006: mem0-queue.jsonl processor\n *\n * This hook reads the mem0-queue.jsonl file and outputs a systemMessage\n * prompting Claude to execute the queued mcp__mem0__add_memory operations.\n *\n * The queue contains memories queued by memory-writer.ts:queueForMem0()\n * with structure:\n * - text: The memory content\n * - user_id: Scoped user identifier (project/global)\n * - metadata: Category, confidence, source, etc.\n * - queued_at: ISO timestamp\n *\n * CC 2.1.19 Compliant: Outputs systemMessage for Claude to act on\n */\n\nimport { existsSync, readFileSync, unlinkSync } from 'node:fs';\nimport { join } from 'node:path';\nimport type { HookInput, HookResult } from '../types.js';\nimport { getProjectDir, logHook, outputSilentSuccess } from '../lib/common.js';\nimport { isMem0Configured } from '../lib/memory-writer.js';\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * Queued mem0 memory payload (written by memory-writer.ts:queueForMem0)\n */\nexport interface QueuedMem0Memory {\n  /** Memory text content */\n  text: string;\n  /** User ID scope (project or global) */\n  user_id: string;\n  /** Memory metadata */\n  metadata: {\n    type?: string;\n    category?: string;\n    confidence?: number;\n    source?: string;\n    project?: string;\n    timestamp?: string;\n    entities?: string[];\n    has_rationale?: boolean;\n    has_alternatives?: boolean;\n    importance?: 'high' | 'medium' | 'low';\n    is_generalizable?: boolean;\n    contributor_id?: string;\n  };\n  /** When this was queued */\n  queued_at: string;\n}\n\n// =============================================================================\n// PATHS\n// =============================================================================\n\n/**\n * Get path to mem0 operations queue\n */\nfunction getMem0QueuePath(): string {\n  return join(getProjectDir(), '.claude', 'memory', 'mem0-queue.jsonl');\n}\n\n// =============================================================================\n// QUEUE READING\n// =============================================================================\n\n/**\n * Read all queued memories from the mem0 queue\n */\nfunction readQueuedMemories(): QueuedMem0Memory[] {\n  const queuePath = getMem0QueuePath();\n\n  if (!existsSync(queuePath)) {\n    return [];\n  }\n\n  try {\n    const content = readFileSync(queuePath, 'utf8');\n    const lines = content.trim().split('\\n').filter(line => line.trim());\n\n    const memories: QueuedMem0Memory[] = [];\n    for (const line of lines) {\n      try {\n        const memory = JSON.parse(line) as QueuedMem0Memory;\n        // Validate required fields\n        if (memory.text && memory.user_id) {\n          memories.push(memory);\n        } else {\n          logHook('mem0-queue-sync', `Skipping invalid memory (missing text or user_id)`, 'warn');\n        }\n      } catch {\n        logHook('mem0-queue-sync', `Failed to parse queue line: ${line.slice(0, 100)}`, 'warn');\n      }\n    }\n\n    return memories;\n  } catch (error) {\n    logHook('mem0-queue-sync', `Failed to read queue: ${error}`, 'warn');\n    return [];\n  }\n}\n\n/**\n * Clear the queue after processing\n */\nfunction clearQueue(): void {\n  const queuePath = getMem0QueuePath();\n\n  if (existsSync(queuePath)) {\n    try {\n      unlinkSync(queuePath);\n      logHook('mem0-queue-sync', 'Cleared mem0 queue', 'debug');\n    } catch (error) {\n      logHook('mem0-queue-sync', `Failed to clear queue: ${error}`, 'warn');\n    }\n  }\n}\n\n// =============================================================================\n// AGGREGATION\n// =============================================================================\n\n/**\n * Group memories by user_id for batched operations\n */\nfunction groupByUserId(memories: QueuedMem0Memory[]): Map<string, QueuedMem0Memory[]> {\n  const groups = new Map<string, QueuedMem0Memory[]>();\n\n  for (const memory of memories) {\n    const existing = groups.get(memory.user_id) || [];\n    existing.push(memory);\n    groups.set(memory.user_id, existing);\n  }\n\n  return groups;\n}\n\n/**\n * Deduplicate memories by text (keep most recent)\n */\nfunction deduplicateMemories(memories: QueuedMem0Memory[]): QueuedMem0Memory[] {\n  const seen = new Map<string, QueuedMem0Memory>();\n\n  for (const memory of memories) {\n    // Use text as dedup key (normalized)\n    const key = memory.text.trim().toLowerCase();\n    const existing = seen.get(key);\n\n    // Keep the most recent one\n    if (!existing || memory.queued_at > existing.queued_at) {\n      seen.set(key, memory);\n    }\n  }\n\n  return Array.from(seen.values());\n}\n\n// =============================================================================\n// MESSAGE GENERATION\n// =============================================================================\n\n/**\n * Generate a systemMessage for Claude to execute the mem0 operations\n */\nfunction generateSystemMessage(memories: QueuedMem0Memory[]): string {\n  if (memories.length === 0) {\n    return '';\n  }\n\n  // Group by user_id for organized output\n  const grouped = groupByUserId(memories);\n\n  const parts: string[] = [\n    '## Mem0 Cloud Memory Sync',\n    '',\n    'The following decisions and patterns were captured this session.',\n    'To persist them to mem0 cloud memory, execute these MCP calls:',\n    '',\n  ];\n\n  // Generate add_memory calls for each memory\n  let callIndex = 1;\n  for (const [userId, userMemories] of grouped) {\n    parts.push(`### Scope: ${userId}`);\n    parts.push('');\n\n    for (const memory of userMemories) {\n      parts.push(`**Memory ${callIndex}:**`);\n      parts.push('```json');\n      parts.push(`mcp__mem0__add_memory({`);\n      parts.push(`  \"text\": ${JSON.stringify(memory.text)},`);\n      parts.push(`  \"user_id\": ${JSON.stringify(memory.user_id)},`);\n      parts.push(`  \"metadata\": ${JSON.stringify(memory.metadata, null, 4).split('\\n').map((l, i) => i === 0 ? l : '  ' + l).join('\\n')}`);\n      parts.push(`})`);\n      parts.push('```');\n      parts.push('');\n      callIndex++;\n    }\n  }\n\n  // Summary\n  const categories = new Set(memories.map(m => m.metadata.category).filter(Boolean));\n  parts.push(`**Summary:** ${memories.length} memories to sync across ${grouped.size} scope(s).`);\n  if (categories.size > 0) {\n    parts.push(`Categories: ${Array.from(categories).join(', ')}`);\n  }\n\n  return parts.join('\\n');\n}\n\n// =============================================================================\n// HOOK IMPLEMENTATION\n// =============================================================================\n\n/**\n * Process the mem0 queue at session end\n *\n * This hook:\n * 1. Checks if MEM0_API_KEY is configured (early return if not)\n * 2. Reads all queued memories from mem0-queue.jsonl\n * 3. Deduplicates them (same text, keep most recent)\n * 4. Outputs a systemMessage with MCP calls for Claude to execute\n * 5. Clears the queue\n */\nexport function mem0QueueSync(_input: HookInput): HookResult {\n  // Gate: Only process if mem0 is configured\n  if (!isMem0Configured()) {\n    logHook('mem0-queue-sync', 'MEM0_API_KEY not configured, skipping', 'debug');\n    return outputSilentSuccess();\n  }\n\n  // Read queued memories\n  const rawMemories = readQueuedMemories();\n\n  if (rawMemories.length === 0) {\n    logHook('mem0-queue-sync', 'No queued mem0 memories', 'debug');\n    return outputSilentSuccess();\n  }\n\n  logHook('mem0-queue-sync', `Processing ${rawMemories.length} queued memories`, 'info');\n\n  // Deduplicate\n  const memories = deduplicateMemories(rawMemories);\n  if (memories.length < rawMemories.length) {\n    logHook(\n      'mem0-queue-sync',\n      `Deduplicated ${rawMemories.length} \u2192 ${memories.length} memories`,\n      'debug'\n    );\n  }\n\n  // Generate system message\n  const systemMessage = generateSystemMessage(memories);\n\n  // Clear the queue\n  clearQueue();\n\n  if (!systemMessage) {\n    return outputSilentSuccess();\n  }\n\n  // Return with systemMessage for Claude to see\n  return {\n    continue: true,\n    systemMessage,\n  };\n}\n\n// Default export for hook system\nexport default mem0QueueSync;\n", "/**\n * Shared Technology Registry - Single source of truth for all technologies, patterns, and tools\n *\n * Eliminates duplication across:\n * 1. TECHNOLOGY_ALIASES in user-intent-detector.ts\n * 2. inferEntityType() in memory-writer.ts\n * 3. KNOWN_PATTERNS array in user-intent-detector.ts\n * 4. inferCategory() in capture-user-intent.ts\n *\n * CC 2.1.16 Compliant\n */\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * Categories for grouping technologies and patterns\n */\nexport type TechnologyCategory =\n  | 'database'\n  | 'frontend'\n  | 'backend'\n  | 'language'\n  | 'auth'\n  | 'ai-ml'\n  | 'infrastructure'\n  | 'testing'\n  | 'build-tool'\n  | 'package-manager'\n  | 'architecture-pattern'\n  | 'caching-pattern'\n  | 'api-pattern'\n  | 'deployment-pattern'\n  | 'workflow-pattern';\n\n/**\n * Entity types for graph memory storage\n */\nexport type EntityType = 'Technology' | 'Pattern' | 'Tool';\n\n/**\n * A registered technology/tool with metadata\n */\nexport interface TechnologyEntry {\n  /** Canonical name (primary identifier) */\n  canonical: string;\n  /** Aliases that map to this canonical name */\n  aliases: string[];\n  /** Category for grouping and inference */\n  category: TechnologyCategory;\n  /** Entity type for graph storage */\n  entityType: EntityType;\n  /** Optional: short description */\n  description?: string;\n}\n\n/**\n * A registered pattern with metadata\n */\nexport interface PatternEntry {\n  /** Canonical name with hyphens */\n  canonical: string;\n  /** Alternative forms (e.g., with spaces or underscores) */\n  variants: string[];\n  /** Category for pattern classification */\n  category:\n    | 'architecture-pattern'\n    | 'caching-pattern'\n    | 'api-pattern'\n    | 'deployment-pattern'\n    | 'workflow-pattern'\n    | 'pagination-pattern';\n  /** Entity type (always 'Pattern') */\n  entityType: 'Pattern';\n  /** Description */\n  description: string;\n}\n\n/**\n * A registered tool with metadata\n */\nexport interface ToolEntry {\n  /** Canonical name */\n  canonical: string;\n  /** Aliases */\n  aliases: string[];\n  /** Category */\n  category: 'build-tool' | 'package-manager' | 'cli-tool';\n  /** Entity type (always 'Tool') */\n  entityType: 'Tool';\n  /** Description */\n  description: string;\n}\n\n// =============================================================================\n// TECHNOLOGY REGISTRY\n// =============================================================================\n\nconst TECHNOLOGIES: Record<string, TechnologyEntry> = {\n  // =========================================================================\n  // DATABASES\n  // =========================================================================\n  postgresql: {\n    canonical: 'postgresql',\n    aliases: ['postgres', 'pg', 'psql'],\n    category: 'database',\n    entityType: 'Technology',\n    description: 'PostgreSQL relational database',\n  },\n  pgvector: {\n    canonical: 'pgvector',\n    aliases: ['pg-vector'],\n    category: 'database',\n    entityType: 'Technology',\n    description: 'PostgreSQL vector extension',\n  },\n  redis: {\n    canonical: 'redis',\n    aliases: ['redis-cache'],\n    category: 'database',\n    entityType: 'Technology',\n    description: 'Redis in-memory data store',\n  },\n  mongodb: {\n    canonical: 'mongodb',\n    aliases: ['mongo'],\n    category: 'database',\n    entityType: 'Technology',\n    description: 'MongoDB document database',\n  },\n  sqlite: {\n    canonical: 'sqlite',\n    aliases: ['sqlite3'],\n    category: 'database',\n    entityType: 'Technology',\n    description: 'SQLite embedded database',\n  },\n  mysql: {\n    canonical: 'mysql',\n    aliases: ['mariadb'],\n    category: 'database',\n    entityType: 'Technology',\n    description: 'MySQL relational database',\n  },\n  dynamodb: {\n    canonical: 'dynamodb',\n    aliases: ['dynamo'],\n    category: 'database',\n    entityType: 'Technology',\n    description: 'AWS DynamoDB NoSQL database',\n  },\n\n  // =========================================================================\n  // BACKEND FRAMEWORKS\n  // =========================================================================\n  fastapi: {\n    canonical: 'fastapi',\n    aliases: ['fast-api'],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'FastAPI Python web framework',\n  },\n  django: {\n    canonical: 'django',\n    aliases: ['django-rest'],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'Django Python web framework',\n  },\n  flask: {\n    canonical: 'flask',\n    aliases: [],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'Flask Python microframework',\n  },\n  express: {\n    canonical: 'express',\n    aliases: ['expressjs', 'express.js'],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'Express.js Node.js framework',\n  },\n  nextjs: {\n    canonical: 'nextjs',\n    aliases: ['next.js', 'next'],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'Next.js React framework',\n  },\n  nest: {\n    canonical: 'nest',\n    aliases: ['nestjs', 'nest.js'],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'NestJS Node.js framework',\n  },\n  spring: {\n    canonical: 'spring',\n    aliases: ['spring-boot', 'springboot'],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'Spring Java framework',\n  },\n  rails: {\n    canonical: 'rails',\n    aliases: ['ruby-on-rails', 'ror'],\n    category: 'backend',\n    entityType: 'Technology',\n    description: 'Ruby on Rails framework',\n  },\n\n  // =========================================================================\n  // FRONTEND FRAMEWORKS\n  // =========================================================================\n  react: {\n    canonical: 'react',\n    aliases: ['reactjs', 'react.js'],\n    category: 'frontend',\n    entityType: 'Technology',\n    description: 'React UI library',\n  },\n  vue: {\n    canonical: 'vue',\n    aliases: ['vuejs', 'vue.js'],\n    category: 'frontend',\n    entityType: 'Technology',\n    description: 'Vue.js framework',\n  },\n  angular: {\n    canonical: 'angular',\n    aliases: ['angularjs'],\n    category: 'frontend',\n    entityType: 'Technology',\n    description: 'Angular framework',\n  },\n  svelte: {\n    canonical: 'svelte',\n    aliases: ['sveltekit'],\n    category: 'frontend',\n    entityType: 'Technology',\n    description: 'Svelte framework',\n  },\n  solid: {\n    canonical: 'solid',\n    aliases: ['solidjs', 'solid.js'],\n    category: 'frontend',\n    entityType: 'Technology',\n    description: 'SolidJS framework',\n  },\n  qwik: {\n    canonical: 'qwik',\n    aliases: [],\n    category: 'frontend',\n    entityType: 'Technology',\n    description: 'Qwik framework',\n  },\n  astro: {\n    canonical: 'astro',\n    aliases: [],\n    category: 'frontend',\n    entityType: 'Technology',\n    description: 'Astro static site builder',\n  },\n\n  // =========================================================================\n  // LANGUAGES\n  // =========================================================================\n  typescript: {\n    canonical: 'typescript',\n    aliases: ['ts'],\n    category: 'language',\n    entityType: 'Technology',\n    description: 'TypeScript language',\n  },\n  python: {\n    canonical: 'python',\n    aliases: ['py', 'python3'],\n    category: 'language',\n    entityType: 'Technology',\n    description: 'Python language',\n  },\n  javascript: {\n    canonical: 'javascript',\n    aliases: ['js', 'ecmascript'],\n    category: 'language',\n    entityType: 'Technology',\n    description: 'JavaScript language',\n  },\n  rust: {\n    canonical: 'rust',\n    aliases: ['rustlang'],\n    category: 'language',\n    entityType: 'Technology',\n    description: 'Rust language',\n  },\n  go: {\n    canonical: 'go',\n    aliases: ['golang'],\n    category: 'language',\n    entityType: 'Technology',\n    description: 'Go language',\n  },\n  java: {\n    canonical: 'java',\n    aliases: ['jdk'],\n    category: 'language',\n    entityType: 'Technology',\n    description: 'Java language',\n  },\n  kotlin: {\n    canonical: 'kotlin',\n    aliases: ['kt'],\n    category: 'language',\n    entityType: 'Technology',\n    description: 'Kotlin language',\n  },\n\n  // =========================================================================\n  // AUTH\n  // =========================================================================\n  jwt: {\n    canonical: 'jwt',\n    aliases: ['json-web-token'],\n    category: 'auth',\n    entityType: 'Technology',\n    description: 'JSON Web Tokens',\n  },\n  oauth2: {\n    canonical: 'oauth2',\n    aliases: ['oauth', 'oidc'],\n    category: 'auth',\n    entityType: 'Technology',\n    description: 'OAuth 2.0 protocol',\n  },\n  passkeys: {\n    canonical: 'passkeys',\n    aliases: ['webauthn', 'fido2'],\n    category: 'auth',\n    entityType: 'Technology',\n    description: 'Passkeys authentication',\n  },\n  saml: {\n    canonical: 'saml',\n    aliases: ['saml2'],\n    category: 'auth',\n    entityType: 'Technology',\n    description: 'SAML authentication',\n  },\n\n  // =========================================================================\n  // AI/ML\n  // =========================================================================\n  langchain: {\n    canonical: 'langchain',\n    aliases: ['lang-chain'],\n    category: 'ai-ml',\n    entityType: 'Technology',\n    description: 'LangChain LLM framework',\n  },\n  langgraph: {\n    canonical: 'langgraph',\n    aliases: ['lang-graph'],\n    category: 'ai-ml',\n    entityType: 'Technology',\n    description: 'LangGraph agent framework',\n  },\n  langfuse: {\n    canonical: 'langfuse',\n    aliases: ['lang-fuse'],\n    category: 'ai-ml',\n    entityType: 'Technology',\n    description: 'Langfuse LLM observability',\n  },\n  openai: {\n    canonical: 'openai',\n    aliases: ['gpt', 'chatgpt'],\n    category: 'ai-ml',\n    entityType: 'Technology',\n    description: 'OpenAI GPT models',\n  },\n  anthropic: {\n    canonical: 'anthropic',\n    aliases: ['claude'],\n    category: 'ai-ml',\n    entityType: 'Technology',\n    description: 'Anthropic Claude models',\n  },\n  llama: {\n    canonical: 'llama',\n    aliases: ['llama2', 'llama3'],\n    category: 'ai-ml',\n    entityType: 'Technology',\n    description: 'Meta Llama models',\n  },\n\n  // =========================================================================\n  // INFRASTRUCTURE\n  // =========================================================================\n  docker: {\n    canonical: 'docker',\n    aliases: ['container'],\n    category: 'infrastructure',\n    entityType: 'Technology',\n    description: 'Docker containerization',\n  },\n  kubernetes: {\n    canonical: 'kubernetes',\n    aliases: ['k8s', 'kube'],\n    category: 'infrastructure',\n    entityType: 'Technology',\n    description: 'Kubernetes orchestration',\n  },\n  terraform: {\n    canonical: 'terraform',\n    aliases: ['tf'],\n    category: 'infrastructure',\n    entityType: 'Technology',\n    description: 'Terraform IaC',\n  },\n  aws: {\n    canonical: 'aws',\n    aliases: ['amazon-web-services'],\n    category: 'infrastructure',\n    entityType: 'Technology',\n    description: 'Amazon Web Services',\n  },\n  gcp: {\n    canonical: 'gcp',\n    aliases: ['google-cloud', 'google-cloud-platform'],\n    category: 'infrastructure',\n    entityType: 'Technology',\n    description: 'Google Cloud Platform',\n  },\n  azure: {\n    canonical: 'azure',\n    aliases: ['microsoft-azure'],\n    category: 'infrastructure',\n    entityType: 'Technology',\n    description: 'Microsoft Azure',\n  },\n\n  // =========================================================================\n  // TESTING FRAMEWORKS\n  // =========================================================================\n  pytest: {\n    canonical: 'pytest',\n    aliases: ['py-test'],\n    category: 'testing',\n    entityType: 'Technology',\n    description: 'Python testing framework',\n  },\n  jest: {\n    canonical: 'jest',\n    aliases: [],\n    category: 'testing',\n    entityType: 'Technology',\n    description: 'JavaScript testing framework',\n  },\n  vitest: {\n    canonical: 'vitest',\n    aliases: ['vite-test'],\n    category: 'testing',\n    entityType: 'Technology',\n    description: 'Vite-native test framework',\n  },\n  playwright: {\n    canonical: 'playwright',\n    aliases: [],\n    category: 'testing',\n    entityType: 'Technology',\n    description: 'Playwright E2E testing',\n  },\n  cypress: {\n    canonical: 'cypress',\n    aliases: [],\n    category: 'testing',\n    entityType: 'Technology',\n    description: 'Cypress E2E testing',\n  },\n  msw: {\n    canonical: 'msw',\n    aliases: ['mock-service-worker'],\n    category: 'testing',\n    entityType: 'Technology',\n    description: 'Mock Service Worker',\n  },\n\n  // =========================================================================\n  // BUILD TOOLS\n  // =========================================================================\n  webpack: {\n    canonical: 'webpack',\n    aliases: [],\n    category: 'build-tool',\n    entityType: 'Technology',\n    description: 'Webpack bundler',\n  },\n  vite: {\n    canonical: 'vite',\n    aliases: ['vitejs'],\n    category: 'build-tool',\n    entityType: 'Technology',\n    description: 'Vite build tool',\n  },\n  esbuild: {\n    canonical: 'esbuild',\n    aliases: [],\n    category: 'build-tool',\n    entityType: 'Technology',\n    description: 'esbuild bundler',\n  },\n  turbopack: {\n    canonical: 'turbopack',\n    aliases: [],\n    category: 'build-tool',\n    entityType: 'Technology',\n    description: 'Turbopack bundler',\n  },\n  bun: {\n    canonical: 'bun',\n    aliases: ['bunjs'],\n    category: 'build-tool',\n    entityType: 'Technology',\n    description: 'Bun runtime',\n  },\n};\n\n// =============================================================================\n// PATTERN REGISTRY\n// =============================================================================\n\nconst PATTERNS: Record<string, PatternEntry> = {\n  'cursor-pagination': {\n    canonical: 'cursor-pagination',\n    variants: ['cursor pagination', 'cursor_pagination'],\n    category: 'pagination-pattern',\n    entityType: 'Pattern',\n    description: 'Cursor-based pagination pattern',\n  },\n  'offset-pagination': {\n    canonical: 'offset-pagination',\n    variants: ['offset pagination', 'offset_pagination'],\n    category: 'pagination-pattern',\n    entityType: 'Pattern',\n    description: 'Offset-based pagination pattern',\n  },\n  'keyset-pagination': {\n    canonical: 'keyset-pagination',\n    variants: ['keyset pagination', 'keyset_pagination'],\n    category: 'pagination-pattern',\n    entityType: 'Pattern',\n    description: 'Keyset-based pagination pattern',\n  },\n  'repository-pattern': {\n    canonical: 'repository-pattern',\n    variants: ['repository pattern', 'repository_pattern'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Repository design pattern',\n  },\n  'service-layer': {\n    canonical: 'service-layer',\n    variants: ['service layer', 'service_layer'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Service layer pattern',\n  },\n  'clean-architecture': {\n    canonical: 'clean-architecture',\n    variants: ['clean architecture', 'clean_architecture'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Clean architecture pattern',\n  },\n  'dependency-injection': {\n    canonical: 'dependency-injection',\n    variants: ['dependency injection', 'di', 'dependency_injection'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Dependency injection pattern',\n  },\n  'event-sourcing': {\n    canonical: 'event-sourcing',\n    variants: ['event sourcing', 'event_sourcing'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Event sourcing pattern',\n  },\n  'cqrs': {\n    canonical: 'cqrs',\n    variants: ['command-query-responsibility-segregation'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'CQRS pattern',\n  },\n  'saga-pattern': {\n    canonical: 'saga-pattern',\n    variants: ['saga pattern', 'saga_pattern', 'saga'],\n    category: 'workflow-pattern',\n    entityType: 'Pattern',\n    description: 'Saga pattern for distributed transactions',\n  },\n  'circuit-breaker': {\n    canonical: 'circuit-breaker',\n    variants: ['circuit breaker', 'circuit_breaker'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Circuit breaker pattern',\n  },\n  'rate-limiting': {\n    canonical: 'rate-limiting',\n    variants: ['rate limiting', 'rate_limiting', 'throttling'],\n    category: 'api-pattern',\n    entityType: 'Pattern',\n    description: 'Rate limiting pattern',\n  },\n  'retry-pattern': {\n    canonical: 'retry-pattern',\n    variants: ['retry pattern', 'retry_pattern', 'retry'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Retry pattern',\n  },\n  'cache-aside': {\n    canonical: 'cache-aside',\n    variants: ['cache aside', 'cache_aside', 'lazy-loading'],\n    category: 'caching-pattern',\n    entityType: 'Pattern',\n    description: 'Cache-aside pattern',\n  },\n  'write-through': {\n    canonical: 'write-through',\n    variants: ['write through', 'write_through'],\n    category: 'caching-pattern',\n    entityType: 'Pattern',\n    description: 'Write-through cache pattern',\n  },\n  'read-through': {\n    canonical: 'read-through',\n    variants: ['read through', 'read_through'],\n    category: 'caching-pattern',\n    entityType: 'Pattern',\n    description: 'Read-through cache pattern',\n  },\n  'rag': {\n    canonical: 'rag',\n    variants: ['retrieval-augmented-generation'],\n    category: 'workflow-pattern',\n    entityType: 'Pattern',\n    description: 'Retrieval-Augmented Generation',\n  },\n  'semantic-search': {\n    canonical: 'semantic-search',\n    variants: ['semantic search', 'semantic_search'],\n    category: 'workflow-pattern',\n    entityType: 'Pattern',\n    description: 'Semantic search pattern',\n  },\n  'vector-search': {\n    canonical: 'vector-search',\n    variants: ['vector search', 'vector_search'],\n    category: 'workflow-pattern',\n    entityType: 'Pattern',\n    description: 'Vector search pattern',\n  },\n  'tdd': {\n    canonical: 'tdd',\n    variants: ['test-driven-development'],\n    category: 'workflow-pattern',\n    entityType: 'Pattern',\n    description: 'Test-Driven Development',\n  },\n  'bdd': {\n    canonical: 'bdd',\n    variants: ['behavior-driven-development'],\n    category: 'workflow-pattern',\n    entityType: 'Pattern',\n    description: 'Behavior-Driven Development',\n  },\n  'ddd': {\n    canonical: 'ddd',\n    variants: ['domain-driven-design'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Domain-Driven Design',\n  },\n  'microservices': {\n    canonical: 'microservices',\n    variants: ['micro-services', 'micro_services'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Microservices architecture',\n  },\n  'monolith': {\n    canonical: 'monolith',\n    variants: ['monolithic'],\n    category: 'architecture-pattern',\n    entityType: 'Pattern',\n    description: 'Monolithic architecture',\n  },\n  'serverless': {\n    canonical: 'serverless',\n    variants: ['faas', 'function-as-a-service'],\n    category: 'deployment-pattern',\n    entityType: 'Pattern',\n    description: 'Serverless architecture',\n  },\n  'rest': {\n    canonical: 'rest',\n    variants: ['restful', 'rest-api'],\n    category: 'api-pattern',\n    entityType: 'Pattern',\n    description: 'REST API pattern',\n  },\n  'graphql': {\n    canonical: 'graphql',\n    variants: ['graph-ql'],\n    category: 'api-pattern',\n    entityType: 'Pattern',\n    description: 'GraphQL API pattern',\n  },\n  'grpc': {\n    canonical: 'grpc',\n    variants: ['g-rpc'],\n    category: 'api-pattern',\n    entityType: 'Pattern',\n    description: 'gRPC protocol',\n  },\n  'websocket': {\n    canonical: 'websocket',\n    variants: ['websockets', 'web-socket'],\n    category: 'api-pattern',\n    entityType: 'Pattern',\n    description: 'WebSocket protocol',\n  },\n  'sse': {\n    canonical: 'sse',\n    variants: ['server-sent-events'],\n    category: 'api-pattern',\n    entityType: 'Pattern',\n    description: 'Server-Sent Events',\n  },\n};\n\n// =============================================================================\n// TOOLS REGISTRY\n// =============================================================================\n\nconst TOOLS: Record<string, ToolEntry> = {\n  grep: {\n    canonical: 'grep',\n    aliases: ['ripgrep', 'rg'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Text search utility',\n  },\n  read: {\n    canonical: 'read',\n    aliases: [],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Claude Code file reader',\n  },\n  write: {\n    canonical: 'write',\n    aliases: [],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Claude Code file writer',\n  },\n  edit: {\n    canonical: 'edit',\n    aliases: [],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Claude Code file editor',\n  },\n  glob: {\n    canonical: 'glob',\n    aliases: [],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Claude Code file finder',\n  },\n  bash: {\n    canonical: 'bash',\n    aliases: ['shell', 'sh'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Bash shell',\n  },\n  task: {\n    canonical: 'task',\n    aliases: [],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Claude Code task management',\n  },\n  git: {\n    canonical: 'git',\n    aliases: ['git-cli'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Version control system',\n  },\n  gh: {\n    canonical: 'gh',\n    aliases: ['github-cli'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'GitHub command line tool',\n  },\n  npm: {\n    canonical: 'npm',\n    aliases: ['node-package-manager'],\n    category: 'package-manager',\n    entityType: 'Tool',\n    description: 'Node.js package manager',\n  },\n  yarn: {\n    canonical: 'yarn',\n    aliases: [],\n    category: 'package-manager',\n    entityType: 'Tool',\n    description: 'Yarn package manager',\n  },\n  pnpm: {\n    canonical: 'pnpm',\n    aliases: [],\n    category: 'package-manager',\n    entityType: 'Tool',\n    description: 'pnpm package manager',\n  },\n  claude: {\n    canonical: 'claude',\n    aliases: ['claude-code', 'claude-cli'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Claude Code CLI',\n  },\n  cursor: {\n    canonical: 'cursor',\n    aliases: [],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Cursor code editor',\n  },\n  vscode: {\n    canonical: 'vscode',\n    aliases: ['vs-code', 'visual-studio-code'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Visual Studio Code editor',\n  },\n  vim: {\n    canonical: 'vim',\n    aliases: ['vi'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Terminal text editor',\n  },\n  neovim: {\n    canonical: 'neovim',\n    aliases: ['nvim', 'neo-vim'],\n    category: 'cli-tool',\n    entityType: 'Tool',\n    description: 'Modern vim fork',\n  },\n};\n\n// =============================================================================\n// REVERSE LOOKUP MAPS\n// =============================================================================\n\n/**\n * Build reverse alias \u2192 canonical map for efficient lookup\n */\nfunction buildAliasMap(\n  registry: Record<string, { canonical: string; aliases: string[] }>\n): Map<string, string> {\n  const map = new Map<string, string>();\n\n  for (const entry of Object.values(registry)) {\n    // Map canonical to itself\n    map.set(entry.canonical.toLowerCase(), entry.canonical);\n\n    // Map all aliases to canonical\n    for (const alias of entry.aliases) {\n      map.set(alias.toLowerCase(), entry.canonical);\n    }\n  }\n\n  return map;\n}\n\n/**\n * Build variant maps for patterns\n */\nfunction buildPatternVariantMap(\n  registry: Record<string, PatternEntry>\n): Map<string, string> {\n  const map = new Map<string, string>();\n\n  for (const entry of Object.values(registry)) {\n    // Map canonical\n    map.set(entry.canonical.toLowerCase(), entry.canonical);\n\n    // Map all variants\n    for (const variant of entry.variants) {\n      map.set(variant.toLowerCase(), entry.canonical);\n    }\n  }\n\n  return map;\n}\n\n// Pre-compute reverse maps for O(1) lookup\nconst TECH_ALIAS_MAP = buildAliasMap(TECHNOLOGIES);\nconst TOOL_ALIAS_MAP = buildAliasMap(TOOLS);\nconst PATTERN_VARIANT_MAP = buildPatternVariantMap(PATTERNS);\n\n// =============================================================================\n// PUBLIC API\n// =============================================================================\n\n/**\n * Get canonical name for a technology\n */\nexport function getTechnologyCanonical(nameOrAlias: string): string | null {\n  const lower = nameOrAlias.toLowerCase();\n  return TECH_ALIAS_MAP.get(lower) || null;\n}\n\n/**\n * Get canonical name for a pattern\n */\nexport function getPatternCanonical(nameOrVariant: string): string | null {\n  const lower = nameOrVariant.toLowerCase();\n  return PATTERN_VARIANT_MAP.get(lower) || null;\n}\n\n/**\n * Get canonical name for a tool\n */\nexport function getToolCanonical(nameOrAlias: string): string | null {\n  const lower = nameOrAlias.toLowerCase();\n  return TOOL_ALIAS_MAP.get(lower) || null;\n}\n\n/**\n * Get category for a technology\n */\nexport function getTechnologyCategory(\n  nameOrAlias: string\n): TechnologyCategory | null {\n  const canonical = getTechnologyCanonical(nameOrAlias);\n  if (!canonical) return null;\n  return TECHNOLOGIES[canonical]?.category || null;\n}\n\n/**\n * Get category for a pattern\n */\nexport function getPatternCategory(\n  nameOrVariant: string\n): PatternEntry['category'] | null {\n  const canonical = getPatternCanonical(nameOrVariant);\n  if (!canonical) return null;\n  return PATTERNS[canonical]?.category || null;\n}\n\n/**\n * Infer entity type (Technology, Pattern, or Tool)\n * Checks in order: Technology \u2192 Pattern \u2192 Tool \u2192 null\n */\nexport function inferEntityType(name: string): EntityType | null {\n  const lower = name.toLowerCase();\n\n  // Check if it's a technology\n  if (TECH_ALIAS_MAP.has(lower)) {\n    return 'Technology';\n  }\n\n  // Check if it's a pattern\n  if (PATTERN_VARIANT_MAP.has(lower)) {\n    return 'Pattern';\n  }\n\n  // Check if it's a tool\n  if (TOOL_ALIAS_MAP.has(lower)) {\n    return 'Tool';\n  }\n\n  return null;\n}\n\n/**\n * Infer category from any name (technology, pattern, or tool)\n */\nexport function inferCategory(name: string): TechnologyCategory | PatternEntry['category'] | string {\n  // Try technology first\n  const techCategory = getTechnologyCategory(name);\n  if (techCategory) return techCategory;\n\n  // Try pattern\n  const patternCategory = getPatternCategory(name);\n  if (patternCategory) return patternCategory;\n\n  // Try tool category mapping\n  const toolCanonical = getToolCanonical(name);\n  if (toolCanonical) {\n    const tool = TOOLS[toolCanonical];\n    if (tool) {\n      // Map tool categories to broader categories\n      if (tool.category === 'cli-tool') return 'backend';\n      return tool.category;\n    }\n  }\n\n  // Default to 'general'\n  return 'general';\n}\n\n/**\n * Check if a name is a known technology\n */\nexport function isTechnology(nameOrAlias: string): boolean {\n  return getTechnologyCanonical(nameOrAlias) !== null;\n}\n\n/**\n * Check if a name is a known pattern\n */\nexport function isPattern(nameOrVariant: string): boolean {\n  return getPatternCanonical(nameOrVariant) !== null;\n}\n\n/**\n * Check if a name is a known tool\n */\nexport function isTool(nameOrAlias: string): boolean {\n  return getToolCanonical(nameOrAlias) !== null;\n}\n\n/**\n * Get technology aliases for extraction (used in user-intent-detector.ts)\n * Returns { alias: canonical } mapping\n */\nexport function getTechnologyAliasMap(): Record<string, string> {\n  const result: Record<string, string> = {};\n\n  for (const entry of Object.values(TECHNOLOGIES)) {\n    // Add canonical \u2192 canonical\n    result[entry.canonical] = entry.canonical;\n\n    // Add all aliases \u2192 canonical\n    for (const alias of entry.aliases) {\n      result[alias] = entry.canonical;\n    }\n  }\n\n  return result;\n}\n\n/**\n * Get pattern names for extraction (used in user-intent-detector.ts)\n */\nexport function getPatternsList(): string[] {\n  return Object.values(PATTERNS).map((entry) => entry.canonical);\n}\n\n/**\n * Get tool names for extraction (used in user-intent-detector.ts)\n */\nexport function getToolsList(): string[] {\n  return Object.values(TOOLS).map((entry) => entry.canonical);\n}\n\n/**\n * Get all canonical names for word boundary matching\n */\nexport function getAllKnownNames(): string[] {\n  const names: string[] = [];\n\n  // Add technology names and aliases\n  for (const entry of Object.values(TECHNOLOGIES)) {\n    names.push(entry.canonical);\n    names.push(...entry.aliases);\n  }\n\n  // Add pattern names and variants\n  for (const entry of Object.values(PATTERNS)) {\n    names.push(entry.canonical);\n    names.push(...entry.variants);\n  }\n\n  // Add tool names and aliases\n  for (const entry of Object.values(TOOLS)) {\n    names.push(entry.canonical);\n    names.push(...entry.aliases);\n  }\n\n  return names;\n}\n", "/**\n * Unified Memory Writer - Store decisions to local graph and mem0 cloud\n *\n * Part of Intelligent Decision Capture System\n *\n * Purpose:\n * - Unify storage to local graph memory (PRIMARY)\n * - Store backup to local JSON files\n * - Optionally sync to mem0 cloud (when MEM0_API_KEY is set)\n * - Build rich graph relationships (CHOSE, CHOSE_OVER, CONSTRAINT)\n * - Support cross-project best practices sharing via user identity\n *\n * Storage Tiers:\n * 1. Local JSON (always) - .claude/memory/*.jsonl\n * 2. Local Graph (if available) - mcp__memory__* operations queued\n * 3. Mem0 Cloud (optional) - when MEM0_API_KEY env var is set\n *\n * Sharing Scopes:\n * - local: Current session only\n * - user: User's personal profile\n * - team: Shared within project/team\n * - global: Cross-project best practices (anonymized)\n *\n * CC 2.1.16 Compliant\n */\n\nimport { existsSync, appendFileSync, mkdirSync } from 'node:fs';\nimport { join, dirname } from 'node:path';\nimport { getProjectDir, logHook } from './common.js';\nimport {\n  getIdentityContext,\n  canShare,\n  getUserIdForScope,\n  getProjectUserId,\n  getGlobalScopeId,\n} from './user-identity.js';\nimport {\n  trackDecisionMade,\n  trackPreferenceStated,\n} from './session-tracker.js';\nimport { buildRelatesWithStrategy } from './relates-to-scaling.js';\nimport { inferEntityType as inferEntityTypeFromRegistry } from './technology-registry.js';\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\n/**\n * Sharing scope for decisions\n */\nexport type SharingScope = 'local' | 'user' | 'team' | 'global';\n\n/**\n * Decision record for storage\n */\nexport interface DecisionRecord {\n  /** Unique ID */\n  id: string;\n  /** Record type */\n  type: 'decision' | 'preference' | 'problem-solution' | 'pattern' | 'workflow';\n  /** Main content */\n  content: {\n    /** What was decided */\n    what: string;\n    /** Why it was decided (rationale) */\n    why?: string;\n    /** Alternatives considered */\n    alternatives?: string[];\n    /** Constraints that influenced the decision */\n    constraints?: string[];\n    /** Tradeoffs accepted */\n    tradeoffs?: string[];\n  };\n  /** Mentioned entities (technologies, patterns, tools) */\n  entities: string[];\n  /** Graph relations to create */\n  relations: Array<{\n    from: string;\n    to: string;\n    type: RelationType;\n  }>;\n  /** User identity context */\n  identity: {\n    /** User ID (email or anonymous) */\n    user_id: string;\n    /** Anonymous ID for global sharing */\n    anonymous_id: string;\n    /** Team/org ID if known */\n    team_id?: string;\n    /** Machine ID */\n    machine_id: string;\n  };\n  /** Metadata */\n  metadata: {\n    session_id: string;\n    timestamp: string;\n    confidence: number;\n    source: DecisionSource;\n    project: string;\n    category: string;\n    importance?: 'high' | 'medium' | 'low';\n    /** Is this pattern generalizable across projects? */\n    is_generalizable?: boolean;\n    /** Maximum scope this can be shared to */\n    sharing_scope?: SharingScope;\n  };\n}\n\n/**\n * Source of the decision\n */\nexport type DecisionSource =\n  | 'user_prompt'\n  | 'tool_output'\n  | 'flow_inference'\n  | 'skill_output'\n  | 'git_commit';\n\n/**\n * Relation types for graph\n */\nexport type RelationType =\n  | 'CHOSE'\n  | 'CHOSE_OVER'\n  | 'MENTIONS'\n  | 'CONSTRAINT'\n  | 'TRADEOFF'\n  | 'RELATES_TO'\n  | 'SOLVED_BY'\n  | 'PREFERS';\n\n/**\n * Graph entity for memory storage\n */\nexport interface GraphEntity {\n  name: string;\n  entityType: EntityType;\n  observations: string[];\n}\n\n/**\n * Entity types for graph\n */\nexport type EntityType =\n  | 'Decision'\n  | 'Preference'\n  | 'Problem'\n  | 'Solution'\n  | 'Technology'\n  | 'Pattern'\n  | 'Tool'\n  | 'Workflow';\n\n/**\n * Graph relation for memory storage\n */\nexport interface GraphRelation {\n  from: string;\n  to: string;\n  relationType: RelationType;\n}\n\n/**\n * Queued operation for graph memory\n */\nexport interface QueuedGraphOperation {\n  type: 'create_entities' | 'create_relations' | 'add_observations';\n  payload: {\n    entities?: GraphEntity[];\n    relations?: GraphRelation[];\n    observations?: Array<{ entityName: string; contents: string[] }>;\n  };\n  timestamp: string;\n}\n\n// =============================================================================\n// FILE PATHS\n// =============================================================================\n\n/**\n * Get path to decisions storage file\n */\nfunction getDecisionsPath(): string {\n  return join(getProjectDir(), '.claude', 'memory', 'decisions.jsonl');\n}\n\n/**\n * Get path to graph operations queue\n */\nfunction getGraphQueuePath(): string {\n  return join(getProjectDir(), '.claude', 'memory', 'graph-queue.jsonl');\n}\n\n/**\n * Get path to mem0 queue (for async sync)\n */\nfunction getMem0QueuePath(): string {\n  return join(getProjectDir(), '.claude', 'memory', 'mem0-queue.jsonl');\n}\n\n// =============================================================================\n// LOCAL STORAGE\n// =============================================================================\n\n/**\n * Append record to JSONL file\n */\nfunction appendToJsonl(filePath: string, record: unknown): boolean {\n  try {\n    const dir = dirname(filePath);\n    if (!existsSync(dir)) {\n      mkdirSync(dir, { recursive: true });\n    }\n\n    const line = JSON.stringify(record) + '\\n';\n    appendFileSync(filePath, line);\n    return true;\n  } catch (err) {\n    logHook('memory-writer', `Failed to write to ${filePath}: ${err}`, 'warn');\n    return false;\n  }\n}\n\n/**\n * Store decision to local JSON backup\n */\nfunction storeToLocalJson(decision: DecisionRecord): boolean {\n  return appendToJsonl(getDecisionsPath(), decision);\n}\n\n// =============================================================================\n// GRAPH OPERATIONS\n// =============================================================================\n\n/**\n * Build graph operations from a decision record\n */\nexport function buildGraphOperations(decision: DecisionRecord): QueuedGraphOperation[] {\n  const operations: QueuedGraphOperation[] = [];\n  const timestamp = new Date().toISOString();\n\n  // 1. Create main decision/preference entity\n  const mainEntity: GraphEntity = {\n    name: decision.id,\n    entityType: capitalizeEntityType(decision.type),\n    observations: buildObservations(decision),\n  };\n\n  // 2. Create entities for mentioned technologies/patterns\n  const entityEntities: GraphEntity[] = decision.entities.map(e => ({\n    name: e,\n    entityType: inferEntityType(e),\n    observations: [`Mentioned in ${decision.type}: ${decision.content.what.slice(0, 100)}`],\n  }));\n\n  operations.push({\n    type: 'create_entities',\n    payload: {\n      entities: [mainEntity, ...entityEntities],\n    },\n    timestamp,\n  });\n\n  // 3. Create relations\n  const relations: GraphRelation[] = [];\n\n  // Link decision to entities with CHOSE, or preferences with PREFERS\n  for (const entity of decision.entities) {\n    const relationType: RelationType =\n      decision.type === 'decision' ? 'CHOSE'\n      : decision.type === 'preference' ? 'PREFERS'\n      : 'MENTIONS';\n    relations.push({\n      from: decision.id,\n      to: entity,\n      relationType,\n    });\n  }\n\n  // Create CHOSE_OVER relations for alternatives\n  if (decision.content.alternatives?.length) {\n    for (const alt of decision.content.alternatives) {\n      relations.push({\n        from: decision.content.what,\n        to: alt,\n        relationType: 'CHOSE_OVER',\n      });\n    }\n  }\n\n  // Create CONSTRAINT relations\n  if (decision.content.constraints?.length) {\n    for (const constraint of decision.content.constraints) {\n      relations.push({\n        from: decision.id,\n        to: constraint,\n        relationType: 'CONSTRAINT',\n      });\n    }\n  }\n\n  // Create TRADEOFF relations\n  if (decision.content.tradeoffs?.length) {\n    for (const tradeoff of decision.content.tradeoffs) {\n      relations.push({\n        from: decision.id,\n        to: tradeoff,\n        relationType: 'TRADEOFF',\n      });\n    }\n  }\n\n  // Create RELATES_TO between co-occurring entities (cross-links)\n  // Uses scaling strategy to avoid O(n\u00B2) explosion for large entity sets\n  // - \u226410 entities: all pairs (max 45 relations)\n  // - >10 entities: weighted importance strategy with topk fallback\n  if (decision.entities.length >= 2) {\n    const relatesToRelations = buildRelatesWithStrategy(decision.entities);\n    relations.push(...relatesToRelations);\n  }\n\n  // Add any explicit relations from the record\n  for (const rel of decision.relations) {\n    relations.push({\n      from: rel.from,\n      to: rel.to,\n      relationType: rel.type,\n    });\n  }\n\n  if (relations.length > 0) {\n    operations.push({\n      type: 'create_relations',\n      payload: { relations },\n      timestamp,\n    });\n  }\n\n  return operations;\n}\n\n/**\n * Build observations list from decision\n */\nfunction buildObservations(decision: DecisionRecord): string[] {\n  const obs: string[] = [];\n\n  obs.push(`What: ${decision.content.what}`);\n\n  if (decision.content.why) {\n    obs.push(`Rationale: ${decision.content.why}`);\n  }\n\n  if (decision.content.alternatives?.length) {\n    obs.push(`Alternatives considered: ${decision.content.alternatives.join(', ')}`);\n  }\n\n  if (decision.content.constraints?.length) {\n    obs.push(`Constraints: ${decision.content.constraints.join('; ')}`);\n  }\n\n  if (decision.content.tradeoffs?.length) {\n    obs.push(`Tradeoffs: ${decision.content.tradeoffs.join('; ')}`);\n  }\n\n  obs.push(`Category: ${decision.metadata.category}`);\n  obs.push(`Confidence: ${(decision.metadata.confidence * 100).toFixed(0)}%`);\n  obs.push(`Source: ${decision.metadata.source}`);\n  obs.push(`Project: ${decision.metadata.project}`);\n  obs.push(`Timestamp: ${decision.metadata.timestamp}`);\n\n  return obs;\n}\n\n/**\n * Capitalize entity type for graph\n */\nfunction capitalizeEntityType(type: string): EntityType {\n  const typeMap: Record<string, EntityType> = {\n    'decision': 'Decision',\n    'preference': 'Preference',\n    'problem-solution': 'Solution',\n    'pattern': 'Pattern',\n    'workflow': 'Workflow',\n  };\n  return typeMap[type] || 'Decision';\n}\n\n/**\n * Infer entity type from name\n * Uses technology-registry.ts as single source of truth\n */\nfunction inferEntityType(name: string): EntityType {\n  // Use centralized registry for accurate type inference\n  const registryType = inferEntityTypeFromRegistry(name);\n  if (registryType) {\n    return registryType;\n  }\n\n  // Fallback: Default to Technology for unknown entities\n  return 'Technology';\n}\n\n/**\n * Queue graph operation for later processing\n */\nexport function queueGraphOperation(operation: QueuedGraphOperation): boolean {\n  return appendToJsonl(getGraphQueuePath(), operation);\n}\n\n// =============================================================================\n// MEM0 OPERATIONS\n// =============================================================================\n\n/**\n * Check if mem0 is configured\n */\nexport function isMem0Configured(): boolean {\n  return !!process.env.MEM0_API_KEY;\n}\n\n/**\n * Build mem0 memory payload from decision\n * Uses appropriate user_id scope based on sharing settings\n */\nfunction buildMem0Payload(decision: DecisionRecord): Record<string, unknown> {\n  const scope = decision.metadata.sharing_scope || 'team';\n  const isGeneralizable = decision.metadata.is_generalizable || false;\n\n  // Determine the appropriate user_id based on scope and privacy\n  let userId: string;\n  if (scope === 'global' && isGeneralizable && canShare('decisions', 'global')) {\n    // Use global best practices scope (anonymized)\n    userId = getGlobalScopeId('best-practices');\n  } else if (canShare('decisions', 'team')) {\n    // Use project-scoped ID\n    userId = getProjectUserId('decisions');\n  } else {\n    // Fallback to user-scoped\n    userId = `${getUserIdForScope('local')}-decisions`;\n  }\n\n  return {\n    text: `${decision.type}: ${decision.content.what}${decision.content.why ? ` because ${decision.content.why}` : ''}`,\n    user_id: userId,\n    metadata: {\n      type: decision.type,\n      category: decision.metadata.category,\n      confidence: decision.metadata.confidence,\n      source: decision.metadata.source,\n      project: decision.metadata.project,\n      timestamp: decision.metadata.timestamp,\n      entities: decision.entities,\n      has_rationale: !!decision.content.why,\n      has_alternatives: !!decision.content.alternatives?.length,\n      importance: decision.metadata.importance,\n      is_generalizable: isGeneralizable,\n      // Include identity for attribution (anonymized if global)\n      contributor_id: scope === 'global' ? decision.identity.anonymous_id : decision.identity.user_id,\n    },\n  };\n}\n\n/**\n * Queue for mem0 async sync\n */\nfunction queueForMem0(decision: DecisionRecord): boolean {\n  if (!isMem0Configured()) {\n    return false;\n  }\n\n  const payload = buildMem0Payload(decision);\n  return appendToJsonl(getMem0QueuePath(), {\n    ...payload,\n    queued_at: new Date().toISOString(),\n  });\n}\n\n// =============================================================================\n// MAIN STORAGE FUNCTION\n// =============================================================================\n\n/**\n * Store a decision to all configured storage backends\n *\n * @param decision - The decision record to store\n * @returns Object indicating which backends succeeded\n */\nexport async function storeDecision(decision: DecisionRecord): Promise<{\n  local: boolean;\n  graph_queued: boolean;\n  mem0_queued: boolean;\n}> {\n  const result = {\n    local: false,\n    graph_queued: false,\n    mem0_queued: false,\n  };\n\n  // 1. Store to local JSON (always, primary backup)\n  result.local = storeToLocalJson(decision);\n\n  // 2. Queue graph operations\n  const graphOps = buildGraphOperations(decision);\n  let graphQueued = true;\n  for (const op of graphOps) {\n    if (!queueGraphOperation(op)) {\n      graphQueued = false;\n    }\n  }\n  result.graph_queued = graphQueued;\n\n  // 3. Queue for mem0 (if configured)\n  if (isMem0Configured()) {\n    result.mem0_queued = queueForMem0(decision);\n  }\n\n  // Log result\n  const backends = [\n    result.local ? 'local' : null,\n    result.graph_queued ? 'graph' : null,\n    result.mem0_queued ? 'mem0' : null,\n  ].filter(Boolean);\n\n  if (backends.length > 0) {\n    logHook(\n      'memory-writer',\n      `Stored ${decision.type} ${decision.id} to: ${backends.join(', ')}`,\n      'info'\n    );\n  }\n\n  return result;\n}\n\n/**\n * Determine if a decision is generalizable (can be shared globally)\n */\nfunction isGeneralizable(\n  content: DecisionRecord['content'],\n  confidence: number,\n  entities: string[]\n): boolean {\n  // High confidence decisions with rationale are more generalizable\n  if (confidence < 0.8) return false;\n  if (!content.why) return false;\n\n  // Must mention at least one well-known technology/pattern\n  const generalPatterns = [\n    'pagination', 'caching', 'authentication', 'authorization', 'testing',\n    'deployment', 'security', 'performance', 'database', 'api', 'architecture',\n  ];\n  const hasGeneralPattern = entities.some(e =>\n    generalPatterns.some(p => e.toLowerCase().includes(p))\n  );\n\n  return hasGeneralPattern;\n}\n\n/**\n * Create a decision record from basic inputs\n */\nexport function createDecisionRecord(\n  type: DecisionRecord['type'],\n  content: DecisionRecord['content'],\n  entities: string[],\n  metadata: Partial<DecisionRecord['metadata']> & {\n    session_id: string;\n    source: DecisionSource;\n  }\n): DecisionRecord {\n  const timestamp = new Date().toISOString();\n  const id = generateId(type);\n  const project = getProjectDir().split('/').pop() || 'unknown';\n  const identityCtx = getIdentityContext();\n  const confidence = metadata.confidence ?? 0.5;\n\n  // Determine if this can be shared globally\n  const generalizable = isGeneralizable(content, confidence, entities);\n\n  // Track in session (for profile aggregation)\n  if (type === 'decision') {\n    trackDecisionMade(content.what, content.why, confidence);\n  } else if (type === 'preference') {\n    trackPreferenceStated(content.what, confidence);\n  }\n\n  return {\n    id,\n    type,\n    content,\n    entities,\n    relations: [], // Will be built automatically from content\n    identity: {\n      user_id: identityCtx.user_id,\n      anonymous_id: identityCtx.anonymous_id,\n      team_id: identityCtx.team_id,\n      machine_id: identityCtx.machine_id,\n    },\n    metadata: {\n      session_id: metadata.session_id,\n      timestamp,\n      confidence,\n      source: metadata.source,\n      project,\n      category: metadata.category ?? 'general',\n      importance: metadata.importance,\n      is_generalizable: generalizable,\n      sharing_scope: generalizable ? 'global' : 'team',\n    },\n  };\n}\n\n/**\n * Generate unique ID\n */\nfunction generateId(prefix: string): string {\n  const timestamp = Date.now().toString(36);\n  const random = Math.random().toString(36).slice(2, 8);\n  return `${prefix}-${timestamp}-${random}`;\n}\n", "/**\n * Unified Stop Dispatcher\n * Issue #235: Hook Architecture Refactor\n *\n * Consolidates 4 async Stop hooks into a single dispatcher.\n * Reduces \"Async hook Stop completed\" messages from 4 to 1.\n *\n * CC 2.1.19 Compliant: Single async hook with internal routing\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { outputSilentSuccess, logHook } from '../lib/common.js';\n\n// Import individual hook implementations\nimport { autoSaveContext } from './auto-save-context.js';\nimport { sessionPatterns } from './session-patterns.js';\nimport { issueWorkSummary } from './issue-work-summary.js';\nimport { calibrationPersist } from './calibration-persist.js';\nimport { sessionProfileAggregator } from './session-profile-aggregator.js';\nimport { sessionEndTracking } from './session-end-tracking.js';\n// Issue #245: GAP-001 & GAP-002 - Wire missing tracking hooks\nimport { graphQueueSync } from './graph-queue-sync.js';\nimport { workflowPreferenceLearner } from './workflow-preference-learner.js';\n// Issue #245: GAP-006 - mem0 cloud memory sync\nimport { mem0QueueSync } from './mem0-queue-sync.js';\n\n// -----------------------------------------------------------------------------\n// Types\n// -----------------------------------------------------------------------------\n\ntype HookFn = (input: HookInput) => HookResult | Promise<HookResult>;\n\ninterface HookConfig {\n  name: string;\n  fn: HookFn;\n}\n\n// -----------------------------------------------------------------------------\n// Hook Registry\n// -----------------------------------------------------------------------------\n\n/**\n * Registry of all async Stop hooks consolidated into dispatcher\n * Issue #245: Added graph-queue-sync (GAP-001) and workflow-preference-learner (GAP-002)\n */\nconst HOOKS: HookConfig[] = [\n  { name: 'auto-save-context', fn: autoSaveContext },\n  { name: 'session-patterns', fn: sessionPatterns },\n  { name: 'issue-work-summary', fn: issueWorkSummary },\n  { name: 'calibration-persist', fn: calibrationPersist },\n  { name: 'session-profile-aggregator', fn: sessionProfileAggregator },\n  { name: 'session-end-tracking', fn: sessionEndTracking },\n  // Issue #245 GAP-001: Graph memory sync - processes queued entity/relation operations\n  { name: 'graph-queue-sync', fn: graphQueueSync },\n  // Issue #245 GAP-002: Workflow preference learning - tracks user's development patterns\n  { name: 'workflow-preference-learner', fn: workflowPreferenceLearner },\n  // Issue #245 GAP-006: mem0 cloud sync - processes queued memories to mem0 (gated by MEM0_API_KEY)\n  { name: 'mem0-queue-sync', fn: mem0QueueSync },\n];\n\n/** Exposed for registry wiring tests */\nexport const registeredHookNames = () => HOOKS.map(h => h.name);\n\n// -----------------------------------------------------------------------------\n// Dispatcher Implementation\n// -----------------------------------------------------------------------------\n\n/**\n * Unified dispatcher that runs all Stop hooks in parallel\n */\nexport async function unifiedStopDispatcher(input: HookInput): Promise<HookResult> {\n  // Run all hooks in parallel\n  const results = await Promise.allSettled(\n    HOOKS.map(async hook => {\n      try {\n        const result = hook.fn(input);\n        if (result instanceof Promise) {\n          await result;\n        }\n        return { hook: hook.name, status: 'success' };\n      } catch (error) {\n        const message = error instanceof Error ? error.message : String(error);\n        logHook('stop-dispatcher', `${hook.name} failed: ${message}`);\n        return { hook: hook.name, status: 'error', message };\n      }\n    })\n  );\n\n  // Log summary for debugging (only errors)\n  const errors = results.filter(\n    r => r.status === 'rejected' || (r.status === 'fulfilled' && r.value.status === 'error')\n  );\n\n  if (errors.length > 0) {\n    logHook('stop-dispatcher', `${errors.length}/${HOOKS.length} hooks had errors`);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Stop Hooks Entry Point\n *\n * Hooks that run when conversation stops (Stop event)\n * Bundle: stop.mjs (~25 KB estimated)\n */\n\n// Re-export types and utilities\nexport * from '../types.js';\nexport * from '../lib/common.js';\n\n// Re-export calibration engine for stop hooks\nexport * from '../lib/calibration-engine.js';\n\n// Stop hooks (12)\nimport { autoRememberContinuity } from '../stop/auto-remember-continuity.js';\nimport { autoSaveContext } from '../stop/auto-save-context.js';\nimport { cleanupInstance } from '../stop/cleanup-instance.js';\nimport { contextCompressor } from '../stop/context-compressor.js';\nimport { fullTestSuite } from '../stop/full-test-suite.js';\nimport { issueWorkSummary } from '../stop/issue-work-summary.js';\nimport { mem0PreCompactionSync } from '../stop/mem0-pre-compaction-sync.js';\nimport { multiInstanceCleanup } from '../stop/multi-instance-cleanup.js';\nimport { securityScanAggregator } from '../stop/security-scan-aggregator.js';\nimport { sessionPatterns } from '../stop/session-patterns.js';\nimport { taskCompletionCheck } from '../stop/task-completion-check.js';\nimport { calibrationPersist } from '../stop/calibration-persist.js';\nimport { unifiedStopDispatcher } from '../stop/unified-dispatcher.js';\n\n// Intelligent Decision Capture System\nimport { workflowPreferenceLearner } from '../stop/workflow-preference-learner.js';\nimport { graphQueueSync } from '../stop/graph-queue-sync.js';\nimport { sessionEndTracking } from '../stop/session-end-tracking.js';\n\nimport type { HookFn } from '../types.js';\n\n/**\n * Stop hooks registry\n */\nexport const hooks: Record<string, HookFn> = {\n  'stop/auto-remember-continuity': autoRememberContinuity,\n  'stop/auto-save-context': autoSaveContext,\n  'stop/cleanup-instance': cleanupInstance,\n  'stop/context-compressor': contextCompressor,\n  'stop/full-test-suite': fullTestSuite,\n  'stop/issue-work-summary': issueWorkSummary,\n  'stop/mem0-pre-compaction-sync': mem0PreCompactionSync,\n  'stop/multi-instance-cleanup': multiInstanceCleanup,\n  'stop/security-scan-aggregator': securityScanAggregator,\n  'stop/session-patterns': sessionPatterns,\n  'stop/task-completion-check': taskCompletionCheck,\n  'stop/calibration-persist': calibrationPersist,\n  'stop/unified-dispatcher': unifiedStopDispatcher,\n  // Intelligent Decision Capture System\n  'stop/workflow-preference-learner': workflowPreferenceLearner,\n  'stop/graph-queue-sync': graphQueueSync,\n  'stop/session-end-tracking': sessionEndTracking,\n};\n\nexport function getHook(name: string): HookFn | undefined {\n  return hooks[name];\n}\n\nexport function listHooks(): string[] {\n  return Object.keys(hooks);\n}\n"],
  "mappings": ";;;0PAoNO,SAASA,GAAYC,EAA0C,CACpE,OAAO,OAAOA,EAAM,SAAY,QAClC,CAEO,SAASC,GAAaD,EAA2C,CACtE,OAAO,OAAOA,EAAM,WAAc,UAAY,OAAOA,EAAM,SAAY,QACzE,CAEO,SAASE,GAAYF,EAA0C,CACpE,OACE,OAAOA,EAAM,WAAc,UAC3B,OAAOA,EAAM,YAAe,UAC5B,OAAOA,EAAM,YAAe,QAEhC,CAEO,SAASG,GAAYH,EAA0C,CACpE,OAAO,OAAOA,EAAM,WAAc,UAAYA,EAAM,UAAY,MAClE,CCjOA,OAAS,kBAAAI,GAAgB,cAAAC,GAAY,YAAAC,GAAU,cAAAC,GAAY,aAAAC,GAAW,YAAAC,OAAgB,UACtF,OAAS,YAAAC,OAAgB,qBAWlB,SAASC,IAAoB,CAClC,OAAI,QAAQ,IAAI,mBACP,GAAG,QAAQ,IAAI,MAAQ,QAAQ,IAAI,aAAe,MAAM,oBAE1D,GAAGC,EAAc,CAAC,eAC3B,CAMO,SAASA,GAAwB,CACtC,OAAO,QAAQ,IAAI,oBAAsB,GAC3C,CAMO,SAASC,IAAwB,CACtC,OAAO,QAAQ,IAAI,oBAAsB,QAAQ,IAAI,oBAAsB,GAC7E,CAQO,SAASC,GAAuB,CACrC,OAAO,QAAQ,IAAI,mBAAqB,YAAY,QAAQ,GAAG,IAAI,KAAK,IAAI,CAAC,EAC/E,CAMO,SAASC,GAAgBC,EAA6B,CAC3D,GAAI,QAAQ,IAAI,kBACd,OAAO,QAAQ,IAAI,kBAGrB,GAAI,CACF,IAAMC,EAASP,GAAS,4BAA6B,CACnD,IAAKM,GAAcJ,EAAc,EACjC,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAAE,KAAK,EACR,eAAQ,IAAI,kBAAoBK,EACzBA,CACT,MAAQ,CACN,MAAO,SACT,CACF,CAKO,SAASC,IAAsB,CACpC,OAAO,QAAQ,IAAI,sBAAwB,MAC7C,CAKO,SAASC,GAAUC,EAAqD,CAC7E,IAAMC,EAAS,CAAC,QAAS,OAAQ,OAAQ,OAAO,EAChD,OAAOA,EAAO,QAAQD,CAAK,GAAKC,EAAO,QAAQH,GAAY,CAAC,CAC9D,CASO,SAASI,GAAkC,CAChD,MAAO,CAAE,SAAU,GAAM,eAAgB,EAAK,CAChD,CAKO,SAASC,IAAgC,CAC9C,MAAO,CACL,SAAU,GACV,eAAgB,GAChB,mBAAoB,CAAE,mBAAoB,OAAQ,CACpD,CACF,CAKO,SAASC,GAAYC,EAA4B,CACtD,MAAO,CACL,SAAU,GACV,WAAYA,EACZ,mBAAoB,CAClB,mBAAoB,OACpB,yBAA0BA,CAC5B,CACF,CACF,CAMO,SAASC,GAAkBC,EAAyB,CACzD,MAAO,CACL,SAAU,GACV,eAAgB,GAChB,mBAAoB,CAClB,cAAe,cACf,kBAAmBA,CACrB,CACF,CACF,CAMO,SAASC,GAAoBD,EAAyB,CAC3D,MAAO,CACL,SAAU,GACV,eAAgB,GAChB,mBAAoB,CAClB,cAAe,mBACf,kBAAmBA,CACrB,CACF,CACF,CAKO,SAASE,GAAuBF,EAAaG,EAAoC,CACtF,IAAMC,EAAqB,CACzB,SAAU,GACV,mBAAoB,CAClB,cAAe,aACf,kBAAmBJ,EACnB,mBAAoB,OACtB,CACF,EAEA,OAAIG,EACFC,EAAO,cAAgBD,EAEvBC,EAAO,eAAiB,GAGnBA,CACT,CAKO,SAASC,GAAYC,EAA6B,CACvD,MAAO,CAAE,SAAU,GAAM,cAAeA,CAAQ,CAClD,CAKO,SAASC,GAAcD,EAA6B,CACzD,MAAO,CAAE,SAAU,GAAM,cAAe,UAAUA,CAAO,EAAG,CAC9D,CAKO,SAASE,GAAWV,EAA4B,CACrD,MAAO,CACL,SAAU,GACV,WAAYA,EACZ,mBAAoB,CAClB,cAAe,aACf,mBAAoB,OACpB,yBAA0BA,CAC5B,CACF,CACF,CAMA,IAAMW,GAAwB,IAAM,KAC9BC,GAA0B,IAAM,KAKtC,SAASC,GAAcC,EAAiBC,EAAuB,CAC7D,GAAKnC,GAAWkC,CAAO,EAEvB,GAAI,CAEF,GADcjC,GAASiC,CAAO,EACpB,KAAOC,EAAS,CACxB,IAAMC,EAAU,GAAGF,CAAO,QAAQ,KAAK,IAAI,CAAC,GAC5ChC,GAAWgC,EAASE,CAAO,CAC7B,CACF,MAAQ,CAER,CACF,CAKA,SAASC,GAAUC,EAAmB,CAC/BtC,GAAWsC,CAAG,GACjBnC,GAAUmC,EAAK,CAAE,UAAW,EAAK,CAAC,CAEtC,CAMO,SAASC,EAAQC,EAAkBZ,EAAiBb,EAA6C,QAAe,CAErH,GAAI,CAACD,GAAUC,CAAK,EAClB,OAGF,IAAM0B,EAASnC,GAAU,EACnB4B,EAAU,GAAGO,CAAM,aAEzB,GAAI,CACFJ,GAAUI,CAAM,EAChBR,GAAcC,EAASH,EAAqB,EAE5C,IAAMW,EAAY,IAAI,KAAK,EAAE,YAAY,EAAE,QAAQ,IAAK,GAAG,EAAE,MAAM,EAAG,EAAE,EACxE3C,GAAemC,EAAS,IAAIQ,CAAS,MAAM3B,EAAM,YAAY,CAAC,MAAMyB,CAAQ,KAAKZ,CAAO;AAAA,CAAI,CAC9F,MAAQ,CAER,CACF,CAMO,SAASe,GACdC,EACAxB,EACAyB,EACM,CACN,IAAMJ,EAASnC,GAAU,EACnB4B,EAAU,GAAGO,CAAM,2BAEzB,GAAI,CACFJ,GAAUI,CAAM,EAChBR,GAAcC,EAASF,EAAuB,EAE9C,IAAMU,EAAY,IAAI,KAAK,EAAE,YAAY,EACnCI,EAAYD,GAAqB,WAAa,QAAQ,IAAI,gBAAkB,UAC5EE,EAAaF,GAAqB,YAAcpC,EAAa,EAEnEV,GACEmC,EACA,GAAGQ,CAAS,MAAME,CAAQ,MAAMxB,CAAM,WAAW0B,CAAQ,cAAcC,CAAS;AAAA,CAClF,CACF,MAAQ,CAER,CACF,CAUO,SAASC,GAAmBC,EAAyB,CAC1D,GAAI,CAACA,EAAS,MAAO,GAGrB,IAAMC,GAFkBD,EAAQ,MAAM,aAAa,GAAK,CAAC,GAAG,OACzBA,EAAQ,OACT,IAAO,IAAM,IAC/C,OAAO,KAAK,KAAKA,EAAQ,OAASC,CAAa,CACjD,CAcO,SAASC,GACd7B,EACAkB,EACAY,EACAC,EACAC,EACY,CACZ,IAAMC,EAASP,GAAmB1B,CAAG,EAErC,OAAI+B,GAAiBA,EAAc,aAAaD,CAAQ,GACtDb,EAAQC,EAAU,wBAAwBY,CAAQ,iBAAiBG,CAAM,GAAG,EACrEtC,EAAoB,IAGzBqC,GACFA,EAAa,gBAAgBd,EAAUY,EAAUG,CAAM,EAGlDhC,GAAoBD,CAAG,EAChC,CAUO,SAASkC,IAA2B,CACzC,GAAI,CAEF,IAAMC,EAAmB,CAAC,EAEpBC,EAAM,OAAO,YAAY,GAAO,EAElCC,EACEC,EAAK,EAEX,OACE,GAAI,CAEF,GADAD,EAAYvD,GAASwD,EAAIF,EAAK,EAAG,IAAS,IAAI,EAC1CC,IAAc,EAAG,MACrBF,EAAO,KAAK,OAAO,KAAKC,EAAI,SAAS,EAAGC,CAAS,CAAC,CAAC,CACrD,MAAQ,CACN,KACF,CAGF,IAAMd,EAAQ,OAAO,OAAOY,CAAM,EAAE,SAAS,MAAM,EAAE,KAAK,EAC1D,OAAKZ,EAIE,KAAK,MAAMA,CAAK,EAHd,CAAE,UAAW,GAAI,WAAYpC,EAAa,EAAG,WAAY,CAAC,CAAE,CAIvE,MAAQ,CACN,MAAO,CAAE,UAAW,GAAI,WAAYA,EAAa,EAAG,WAAY,CAAC,CAAE,CACrE,CACF,CAKO,SAASoD,GAAYhB,EAAkBiB,EAA6B,CACzE,IAAMC,EAAQD,EAAK,QAAQ,MAAO,EAAE,EAAE,MAAM,GAAG,EAC3CE,EAAiBnB,EAErB,QAAWoB,KAAQF,EAAO,CACxB,GAAIC,GAAU,KAA6B,OAC3CA,EAASA,EAAkCC,CAAI,CACjD,CAEA,OAAOD,CACT,CAUO,SAASE,GAAiBC,EAAyB,CACxD,OAAOA,EACJ,QAAQ,gBAAiB,GAAG,EAC5B,QAAQ,MAAO,GAAG,EAClB,QAAQ,OAAQ,GAAG,EACnB,KAAK,CACV,CAKO,SAASC,GAAYC,EAAqB,CAC/C,OAAOA,EAAI,QAAQ,sBAAuB,MAAM,CAClD,CCrZA,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UACnE,OAAS,cAAAC,OAAkB,cAc3B,IAAMC,GAAc,IAGdC,GAA6B,EAG7BC,GAAiB,GAGjBC,GAAkB,EAGlBC,GAAe,GAMrB,SAASC,IAA6B,CACpC,MAAO,GAAGC,EAAc,CAAC,yCAC3B,CAEA,SAASC,IAAkB,CACzB,IAAMC,EAAM,GAAGF,EAAc,CAAC,oBAC9B,GAAI,CAACG,GAAWD,CAAG,EACjB,GAAI,CACFE,GAAUF,EAAK,CAAE,UAAW,EAAK,CAAC,CACpC,MAAQ,CAER,CAEJ,CAKO,SAASG,GAAuC,CACrD,IAAMC,EAAOP,GAAmB,EAEhC,GAAII,GAAWG,CAAI,EACjB,GAAI,CACF,OAAO,KAAK,MAAMC,GAAaD,EAAM,MAAM,CAAC,CAC9C,MAAQ,CACNE,EAAQ,qBAAsB,iDAAiD,CACjF,CAGF,MAAO,CACL,cAAe,QACf,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,QAAS,CAAC,EACV,YAAa,CAAC,EACd,MAAO,CACL,gBAAiB,EACjB,YAAa,EACb,cAAe,EACf,UAAW,CAAC,CACd,CACF,CACF,CAKO,SAASC,GAAoBC,EAA6B,CAC/DT,GAAU,EACV,IAAMK,EAAOP,GAAmB,EAEhCW,EAAK,UAAY,IAAI,KAAK,EAAE,YAAY,EAExC,GAAI,CACFC,GAAcL,EAAM,KAAK,UAAUI,EAAM,KAAM,CAAC,CAAC,EACjDF,EAAQ,qBAAsB,wBAAwB,CACxD,OAASI,EAAK,CACZJ,EAAQ,qBAAsB,oCAAoCI,CAAG,EAAE,CACzE,CACF,CASO,SAASC,GAAWC,EAAwB,CACjD,OAAOC,GAAW,QAAQ,EAAE,OAAOD,EAAO,YAAY,EAAE,KAAK,CAAC,EAAE,OAAO,KAAK,EAAE,MAAM,EAAG,EAAE,CAC3F,CAKO,SAASE,GACdF,EACAG,EACAC,EACAC,EACAC,EACAC,EACAC,EACM,CACN,IAAMZ,EAAOL,EAAoB,EAE3BkB,EAA4B,CAChC,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,UAAWC,EAAa,EACxB,MAAAP,EACA,WAAYJ,GAAWC,CAAM,EAC7B,gBAAAI,EACA,mBAAoBC,EACpB,QAAAC,EACA,WAAAC,EACA,SAAAC,CACF,EAEAZ,EAAK,QAAQ,KAAKa,CAAM,EAGpBb,EAAK,QAAQ,OAAShB,KACxBgB,EAAK,QAAUA,EAAK,QAAQ,MAAM,CAAChB,EAAW,GAIhD+B,GAAkBf,EAAMa,CAAM,EAG9BG,GAAYhB,CAAI,EAEhBD,GAAoBC,CAAI,EAExBF,EACE,qBACA,qBAAqBS,CAAK,OAAOG,CAAO,WAAWD,CAAU,GAC/D,CACF,CASA,SAASM,GAAkBf,EAAuBa,EAAiC,CACjF,IAAMI,EAAaJ,EAAO,UAAY,UAChCK,EAAaL,EAAO,UAAY,WAAaA,EAAO,UAAY,WAEtE,GAAI,CAACI,GAAc,CAACC,EAElB,OAGF,IAAMC,EAAkBF,EAAa9B,GAAkB,CAACA,GAExD,QAAWiC,KAAWP,EAAO,gBAAiB,CAC5C,IAAMQ,EAAWrB,EAAK,YAAY,KAChCsB,GAAKA,EAAE,UAAYF,GAAWE,EAAE,QAAUT,EAAO,KACnD,EAEIQ,GAEFA,EAAS,WAAa,KAAK,IACzB,CAACnC,GACD,KAAK,IAAIA,GAAgBmC,EAAS,WAAaF,CAAe,CAChE,EACAE,EAAS,cACTA,EAAS,YAAc,IAAI,KAAK,EAAE,YAAY,GAG9CrB,EAAK,YAAY,KAAK,CACpB,QAAAoB,EACA,MAAOP,EAAO,MACd,WAAYM,EACZ,YAAa,EACb,YAAa,IAAI,KAAK,EAAE,YAAY,CACtC,CAAC,CAEL,CACF,CAKO,SAASI,GAAWvB,EAA6B,CACtD,IAAMwB,EAAM,KAAK,IAAI,EACfC,EAAQ,KAAU,GAAK,IAE7B,QAAWC,KAAO1B,EAAK,YAAa,CAClC,IAAM2B,EAAMH,EAAM,IAAI,KAAKE,EAAI,WAAW,EAAE,QAAQ,EACpC,KAAK,MAAMC,EAAMF,CAAK,EAExB,IAEZC,EAAI,WAAa,KAAK,MAAMA,EAAI,WAAatC,EAAY,EAGrD,KAAK,IAAIsC,EAAI,UAAU,EAAI,IAC7BA,EAAI,WAAa,GAGvB,CAGA1B,EAAK,YAAcA,EAAK,YAAY,OAAOsB,GAAKA,EAAE,aAAe,CAAC,CACpE,CASA,SAASN,GAAYhB,EAA6B,CAChD,IAAM4B,EAAU5B,EAAK,QACrB,GAAI4B,EAAQ,SAAW,EAAG,OAG1B5B,EAAK,MAAM,gBAAkB4B,EAAQ,OAGrC,IAAMC,EAAaD,EAAQ,OAAOE,GAAKA,EAAE,UAAY,SAAS,EAAE,OAChE9B,EAAK,MAAM,YAAc6B,EAAaD,EAAQ,OAG9C,IAAMG,EAAUH,EAAQ,OAAO,CAACI,EAAKF,IAAME,EAAMF,EAAE,mBAAoB,CAAC,EAAIF,EAAQ,OACpF5B,EAAK,MAAM,cAAgB,KAAK,MAAM+B,CAAO,EAG7C,IAAME,EAAa,IAAI,IACvB,QAAWpB,KAAUe,EAAS,CAC5B,IAAMM,EAAOD,EAAW,IAAIpB,EAAO,KAAK,GAAK,CAAE,MAAO,EAAG,QAAS,CAAE,EACpEqB,EAAK,QACDrB,EAAO,UAAY,WAAWqB,EAAK,UACvCD,EAAW,IAAIpB,EAAO,MAAOqB,CAAI,CACnC,CAEAlC,EAAK,MAAM,UAAY,MAAM,KAAKiC,EAAW,QAAQ,CAAC,EACnD,IAAI,CAAC,CAAC1B,EAAO2B,CAAI,KAAO,CACvB,MAAA3B,EACA,MAAO2B,EAAK,MACZ,YAAaA,EAAK,QAAUA,EAAK,KACnC,EAAE,EACD,KAAK,CAACZ,EAAGa,IAAMA,EAAE,MAAQb,EAAE,KAAK,EAChC,MAAM,EAAG,EAAE,CAChB,CASO,SAASc,IAA0C,CAIxD,OAHazC,EAAoB,EAGrB,YAAY,OAAO2B,GAAKA,EAAE,aAAerC,EAA0B,CACjF,CAKO,SAASoD,GAAoB9B,EAA8B,CAEhE,IAAM+B,EADO3C,EAAoB,EACP,QAAQ,OAAOmC,GAAKA,EAAE,QAAUvB,CAAK,EAE/D,OAAI+B,EAAa,OAASrD,GACjB,KAGUqD,EAAa,OAAOR,GAAKA,EAAE,UAAY,SAAS,EAAE,OACjDQ,EAAa,MACnC,CAKO,SAASC,IAAgD,CAC9D,OAAO5C,EAAoB,EAAE,KAC/B,CAKO,SAAS6C,IAAqC,CAEnD,OADa7C,EAAoB,EACrB,QAAQ,QAAUV,EAChC,CC3SO,SAASwD,GAAuBC,EAA8B,CACnEC,EAAQ,2BAA4B,gBAAgB,EAGpD,IAAMC,GADaF,EAAM,aAAeG,EAAc,GACzB,MAAM,GAAG,EAAE,IAAI,GAAK,UAI3CC,EADgB,CAAC,CAAC,QAAQ,IAAI,aAEhC,iFACA,GAEEC,EAAY;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAMIH,CAAS;AAAA;AAAA;AAAA;AAAA,WAItBE,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wDAkBjB,OAAAH,EAAQ,2BAA4B,0CAA0C,EAEvE,CACL,SAAU,GACV,eAAgB,EAElB,CACF,CCrDA,OAAS,cAAAK,GAAY,aAAAC,GAAW,gBAAAC,GAAc,iBAAAC,OAAqB,UA2B5D,SAASC,EAAgBC,EAA8B,CAC5DC,EAAQ,oBAAqB,gDAAgD,EAG7E,IAAMC,EAAa,GADAF,EAAM,aAAeG,EAAc,CACtB,2BAC1BC,EAAe,GAAGF,CAAU,cAGlC,GAAI,CACGG,GAAWH,CAAU,GACxBI,GAAUJ,EAAY,CAAE,UAAW,EAAK,CAAC,CAE7C,MAAQ,CAER,CAEA,IAAMK,EAAY,IAAI,KAAK,EAAE,YAAY,EAEzC,GAAI,CACF,GAAIF,GAAWD,CAAY,EAAG,CAE5B,IAAMI,EAAUC,GAAaL,EAAc,OAAO,EAC5CM,EAA+B,KAAK,MAAMF,CAAO,EAGjDG,EAAwB,CAC5B,QAASD,EAAM,SAAW,uBAC1B,MAAOA,EAAM,OAAS,CACpB,SAAU,MACV,aAAc,IACd,UAAW,SACX,SAAU,eACV,YAAa,8DACf,EACA,WAAYA,EAAM,YAAc,KAChC,QAASA,EAAM,SAAW,KAC1B,cAAeH,EACf,aAAcG,EAAM,cAAgB,CAAE,YAAa,iBAAkB,OAAQ,SAAU,EACvF,WAAYA,EAAM,YAAc,CAAC,EACjC,SAAUA,EAAM,UAAY,CAAC,CAC/B,EAEAE,GAAcR,EAAc,KAAK,UAAUO,EAAS,KAAM,CAAC,CAAC,EAC5DV,EAAQ,oBAAqB,iCAAiC,CAChE,MAsBEW,GAAcR,EAAc,KAAK,UApBF,CAC7B,QAAS,uBACT,MAAO,CACL,SAAU,MACV,aAAc,IACd,UAAW,SACX,SAAU,eACV,YAAa,8DACf,EACA,WAAY,KACZ,QAASG,EACT,cAAeA,EACf,aAAc,CACZ,YAAa,iBACb,OAAQ,SACV,EACA,WAAY,CAAC,EACb,SAAU,CAAC,CACb,EAEqD,KAAM,CAAC,CAAC,EAC7DN,EAAQ,oBAAqB,oDAAoD,CAErF,OAASY,EAAO,CACdZ,EAAQ,oBAAqB,yBAAyBY,CAAK,EAAE,CAC/D,CAEA,OAAOC,EAAoB,CAC7B,CCvGA,OAAS,cAAAC,GAAY,gBAAAC,OAAoB,UACzC,OAAS,YAAAC,OAAgB,qBAOzB,SAASC,GAAcC,EAAmC,CACxD,IAAMC,EAAS,GAAGD,CAAU,qBAC5B,GAAI,CACF,OAAKE,GAAWD,CAAM,GAGN,KAAK,MAAME,GAAaF,EAAQ,OAAO,CAAC,EACzC,aAAe,IAChC,MAAQ,CACN,OAAO,IACT,CACF,CAKA,SAASG,GAAUC,EAAgBC,EAAmB,CACpD,GAAI,CACFC,GAAS,YAAYF,CAAM,MAAMC,CAAG,IAAK,CACvC,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CAER,CACF,CAKO,SAASE,GAAgBC,EAA8B,CAC5D,IAAMT,EAAaS,EAAM,aAAeC,EAAc,EAChDL,EAAS,GAAGL,CAAU,mCAG5B,GAAI,CAACE,GAAWG,CAAM,EACpB,OAAAM,EAAQ,mBAAoB,4CAA4C,EACjEC,EAAoB,EAI7B,IAAMC,EAAad,GAAcC,CAAU,EAC3C,GAAI,CAACa,EACH,OAAAF,EAAQ,mBAAoB,4BAA4B,EACjDC,EAAoB,EAG7BD,EAAQ,mBAAoB,yBAAyBE,CAAU,EAAE,EAGjEF,EAAQ,mBAAoB,wBAAwB,EACpDP,GAAUC,EAAQ,+CAA+CQ,CAAU,IAAI,EAC/EF,EAAQ,mBAAoB,oBAAoB,EAGhD,GAAI,CACeJ,GACf,YAAYF,CAAM,oFAClB,CAAE,SAAU,OAAQ,QAAS,GAAK,CACpC,EAAE,KAAK,IAEU,MACfD,GACEC,EACA,oGAAoGQ,CAAU,0BAChH,EACAF,EAAQ,mBAAoB,qBAAqB,EAErD,MAAQ,CAER,CAGA,GAAI,CACeJ,GACf,YAAYF,CAAM,kFAClB,CAAE,SAAU,OAAQ,QAAS,GAAK,CACpC,EAAE,KAAK,IAEU,MACfD,GACEC,EACA,4FAA4FQ,CAAU,IACxG,EACAF,EAAQ,mBAAoB,uCAAuC,EAEvE,MAAQ,CAER,CAEA,OAAAA,EAAQ,mBAAoB,kCAAkC,EACvDC,EAAoB,CAC7B,CCvGA,OAAS,cAAAE,GAAY,aAAAC,GAAW,gBAAAC,GAAc,iBAAAC,MAAqB,UAKnE,IAAMC,GAAuB,GAe7B,SAASC,GAAeC,EAA0B,CAChD,IAAMC,EAAc,GAAGD,CAAU,sBACjC,GAAI,CAACE,GAAWD,CAAW,EAAG,CAC5BE,EAAQ,qBAAsB,6BAA6B,EAC3D,MACF,CAEA,GAAI,CACF,IAAMC,EAAUC,GAAaJ,EAAa,OAAO,EAC3CK,EAAwB,KAAK,MAAMF,CAAO,EAE1CG,EAAYD,EAAQ,YAAc,WAAW,IAAI,KAAK,EAAE,YAAY,EAAE,QAAQ,QAAS,GAAG,CAAC,GAC3FE,EAAa,GAAGR,CAAU,oBAChCS,GAAUD,EAAY,CAAE,UAAW,EAAK,CAAC,EAEzC,IAAME,EAAc,GAAGF,CAAU,IAAID,CAAS,QACxCI,EAAW,CACf,GAAGL,EACH,MAAO,IAAI,KAAK,EAAE,YAAY,EAC9B,SAAU,EACZ,EAEAM,EAAcF,EAAa,KAAK,UAAUC,EAAU,KAAM,CAAC,CAAC,EAC5DR,EAAQ,qBAAsB,uBAAuBO,CAAW,EAAE,EAgBlEE,EAAcX,EAAa,KAAK,UAbb,CACjB,QAAS,uBACT,MAAO,CAAE,SAAU,MAAO,aAAc,IAAK,UAAW,QAAS,EACjE,WAAY,KACZ,QAAS,KACT,aAAc,KACd,cAAe,CAAC,EAChB,uBAAwB,CAAC,EACzB,SAAU,CAAC,EACX,WAAY,CAAC,EACb,WAAY,CAAE,MAAO,CAAC,CAAE,CAC1B,EAEsD,KAAM,CAAC,CAAC,EAC9DE,EAAQ,qBAAsB,qBAAqB,CACrD,OAASU,EAAO,CACdV,EAAQ,qBAAsB,4BAA4BU,CAAK,EAAE,CACnE,CACF,CAKA,SAASC,GAAqBd,EAA0B,CACtD,IAAMe,EAAgB,GAAGf,CAAU,mCACnC,GAAKE,GAAWa,CAAa,EAI7B,GAAI,CACF,IAAMX,EAAUC,GAAaU,EAAe,OAAO,EAC7CC,EAAsB,KAAK,MAAMZ,CAAO,EACxCa,EAAYD,EAAK,WAAa,CAAC,EAErC,GAAIC,EAAU,QAAUnB,GACtB,OAGF,IAAMU,EAAa,GAAGR,CAAU,qBAChCS,GAAUD,EAAY,CAAE,UAAW,EAAK,CAAC,EAEzC,IAAMU,EAAM,IAAI,KACVR,EAAc,GAAGF,CAAU,IAAIU,EAAI,YAAY,CAAC,IAAI,OAAOA,EAAI,SAAS,EAAI,CAAC,EAAE,SAAS,EAAG,GAAG,CAAC,QAG/FC,EAAYF,EAAU,MAAM,EAAG,CAACnB,EAAoB,EAC1Dc,EAAcF,EAAa,KAAK,UAAUS,EAAW,KAAM,CAAC,CAAC,EAG7DH,EAAK,UAAYC,EAAU,MAAM,CAACnB,EAAoB,EACtDc,EAAcG,EAAe,KAAK,UAAUC,EAAM,KAAM,CAAC,CAAC,EAE1Db,EAAQ,qBAAsB,YAAYgB,EAAU,MAAM,gBAAgB,CAC5E,OAASN,EAAO,CACdV,EAAQ,qBAAsB,gCAAgCU,CAAK,EAAE,CACvE,CACF,CAMA,SAASO,GAAwBpB,EAA0B,CACzD,IAAMC,EAAc,GAAGD,CAAU,sBACjC,GAAKE,GAAWD,CAAW,EAI3B,GAAI,CACF,IAAMG,EAAUC,GAAaJ,EAAa,OAAO,EAC3CK,EAAU,KAAK,MAAMF,CAAO,EAE5BiB,EAAW,CACf,UAAWf,EAAQ,YAAc,UACjC,YAAa,IAAI,KAAK,EAAE,YAAY,EACpC,cAAeA,EAAQ,wBAA0B,CAAC,GAAG,MAAM,EAAE,EAC7D,cAAeA,EAAQ,eAAiB,CAAC,GAAG,MAAM,GAAG,EACrD,SAAUA,EAAQ,UAAY,CAAC,EAC/B,UAAWA,EAAQ,YAAc,CAAC,CACpC,EAEMgB,EAAc,GAAGtB,CAAU,WACjCS,GAAUa,EAAa,CAAE,UAAW,EAAK,CAAC,EAC1CV,EAAc,GAAGU,CAAW,4BAA6B,KAAK,UAAUD,EAAU,KAAM,CAAC,CAAC,EAC1FlB,EAAQ,qBAAsB,yCAAyCkB,EAAS,SAAS,EAAE,CAC7F,OAASR,EAAO,CACdV,EAAQ,qBAAsB,sCAAsCU,CAAK,EAAE,CAC7E,CACF,CAKO,SAASU,GAAkBC,EAA8B,CAC9DrB,EAAQ,qBAAsB,wCAAwC,EAGtE,IAAMH,EAAa,GADAwB,EAAM,aAAeC,EAAc,CACtB,WAEhC,OAAAL,GAAwBpB,CAAU,EAClCD,GAAeC,CAAU,EACzBc,GAAqBd,CAAU,EAE/BG,EAAQ,qBAAsB,qCAAqC,EAC5DuB,EAAoB,CAC7B,CCtJA,OAAS,cAAAC,EAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UACnE,OAAS,YAAAC,MAAgB,qBAOzB,SAASC,GAAeC,EAA6B,CACnD,IAAMC,EAAc,GAAGD,CAAU,qCAGjC,GAAI,CAACE,EAAWD,CAAW,EACzB,MAAO,GAIT,GAAI,CACF,IAAME,EAASC,EAAS,4BAA6B,CACnD,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAED,GAAI,sBAAsB,KAAKG,CAAM,EACnC,MAAO,EAEX,MAAQ,CAEN,MAAO,EACT,CAEA,OAAAE,EAAQ,kBAAmB,0CAA0C,EAC9D,EACT,CAKA,SAASC,GAASN,EAAoBO,EAA0B,CAC9D,IAAIC,EAAW,EAGf,GACEN,EAAW,GAAGF,CAAU,aAAa,GACrCE,EAAW,GAAGF,CAAU,iBAAiB,GACxCE,EAAW,GAAGF,CAAU,QAAQ,GAAKE,EAAW,GAAGF,CAAU,mBAAmB,EACjF,CACAK,EAAQ,kBAAmB,4CAA4C,EACvE,GAAI,CACFD,EAAS,qCAAsC,CAC7C,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNQ,EAAW,CACb,CACF,CAGA,GAAIN,EAAW,GAAGF,CAAU,eAAe,EAAG,CAC5CK,EAAQ,kBAAmB,6BAA6B,EACxD,GAAI,CAEF,GADoB,KAAK,MAAMI,GAAa,GAAGT,CAAU,gBAAiB,OAAO,CAAC,EAClE,SAAS,KAAM,CAC7BK,EAAQ,kBAAmB,qBAAqB,EAGhD,IAAIK,EAAM,iDACV,GAAI,CACFN,EAAS,aAAc,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EAC5EM,EAAM,6BACR,MAAQ,CACN,GAAI,CACFN,EAAS,aAAc,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EAC5EM,EAAM,6BACR,MAAQ,CAER,CACF,CAEAN,EAASM,EAAK,CACZ,IAAKV,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,CACF,MAAQ,CACNQ,EAAW,CACb,CACF,CAGA,GAAIN,EAAW,GAAGF,CAAU,SAAS,EAAG,CACtCK,EAAQ,kBAAmB,yCAAyC,EACpE,GAAI,CACFD,EAAS,+BAAgC,CACvC,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNQ,EAAW,CACb,CACF,CAGA,GAAIN,EAAW,GAAGF,CAAU,aAAa,EAAG,CAC1CK,EAAQ,kBAAmB,8CAA8C,EACzE,GAAI,CACFD,EAAS,aAAc,CACrB,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNQ,EAAW,CACb,CACF,CAEA,OAAOA,IAAa,CACtB,CAKO,SAASG,GAAcC,EAA8B,CAC1DP,EAAQ,kBAAmB,iCAAiC,EAE5D,IAAML,EAAaY,EAAM,aAAeC,EAAc,EAChDC,EAAS,GAAGd,CAAU,sBAG5B,GAAI,CACFe,GAAUD,EAAQ,CAAE,UAAW,EAAK,CAAC,CACvC,MAAQ,CAER,CAEA,IAAMP,EAAU,GAAGO,CAAM,uBAEzB,GAAI,CAACf,GAAeC,CAAU,EAC5B,OAAOgB,EAAoB,EAK7B,GAFeV,GAASN,EAAYO,CAAO,EAE/B,CACVF,EAAQ,kBAAmB,0BAA0B,EAErD,GAAI,CACFY,GAAc,GAAGH,CAAM,kBAAmB,OAAO,KAAK,IAAI,CAAC,CAAC,CAC9D,MAAQ,CAER,CACF,MACET,EAAQ,kBAAmB,2BAA2B,EAIxD,OAAOW,EAAoB,CAC7B,CCvKA,OAAS,cAAAE,GAAY,gBAAAC,GAAc,cAAAC,GAAY,aAAAC,OAAiB,UAChE,OAAS,YAAAC,MAAgB,qBAiBzB,SAASC,IAAyB,CAChC,GAAI,CACF,OAAAC,EAAS,WAAY,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EAC1EA,EAAS,iBAAkB,CAAE,SAAU,OAAQ,QAAS,IAAM,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EACxF,EACT,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAaC,EAA6B,CACjD,GAAI,CAOF,OANeF,EAAS,4BAA6B,CACnD,IAAKE,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACa,SAAS,QAAQ,CACjC,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAgBC,EAAkBC,EAAuCC,EAA2B,CAC3G,IAAMC,EAAUF,EAAK,SAAW,CAAC,EACjC,GAAIE,EAAQ,SAAW,EACrB,MAAO,GAGT,IAAMC,EAAiBD,EAAQ,IAAKE,GAAM,OAAOA,EAAE,GAAG,OAAOA,EAAE,OAAO,EAAE,EAAE,KAAK;AAAA,CAAI,EAC7EC,EACJL,EAAK,iBAAiB,OAAS,EAC3B;AAAA,EAA4BA,EAAK,gBAAgB,IAAKM,GAAM,SAASA,CAAC,EAAE,EAAE,KAAK;AAAA,CAAI,CAAC,GACpF,GAEN,MAAO;AAAA;AAAA,iBAEQL,EAAU,MAAM,EAAG,CAAC,CAAC;AAAA,gBACtBD,EAAK,QAAU,SAAS;AAAA;AAAA,eAEzBE,EAAQ,MAAM;AAAA,EAC3BC,CAAc;AAAA;AAAA,EAEdE,CAAY;AAAA;AAAA,wEAGd,CAKA,SAASE,GAAYR,EAAkBS,EAA0B,CAC/D,GAAI,CACF,OAAAb,EAAS,oBAAoBI,CAAQ,YAAYS,EAAQ,QAAQ,KAAM,KAAK,CAAC,IAAK,CAChF,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACM,EACT,MAAQ,CACN,MAAO,EACT,CACF,CAKO,SAASC,EAAiBC,EAA8B,CAC7DC,EAAQ,qBAAsB,wDAAwD,EAEtF,IAAMd,EAAaa,EAAM,aAAeE,EAAc,EAChDX,EAAYS,EAAM,YAAcG,EAAa,EAI7CC,EAAa,uBADGb,EAAU,QAAQ,kBAAmB,EAAE,CACN,GACjDc,EAAe,GAAGD,CAAU,uBAGlC,GAAI,CAACE,GAAWD,CAAY,EAC1B,OAAAJ,EAAQ,qBAAsB,6BAA6BI,CAAY,EAAE,EAClEE,EAAoB,EAI7B,GAAI,CAACvB,GAAc,EACjB,OAAAiB,EAAQ,qBAAsB,qDAAqD,EAC5EM,EAAoB,EAI7B,GAAI,CAACrB,GAAaC,CAAU,EAC1B,OAAAc,EAAQ,qBAAsB,mCAAmC,EAC1DM,EAAoB,EAI7B,IAAIC,EACJ,GAAI,CACFA,EAAe,KAAK,MAAMC,GAAaJ,EAAc,OAAO,CAAC,CAC/D,MAAQ,CACN,OAAAJ,EAAQ,qBAAsB,8BAA8B,EACrDM,EAAoB,CAC7B,CAEA,IAAMG,EAASF,EAAa,OAAS,OAAO,KAAKA,EAAa,MAAM,EAAI,CAAC,EACzE,GAAIE,EAAO,SAAW,EACpB,OAAAT,EAAQ,qBAAsB,sBAAsB,EAC7CM,EAAoB,EAI7B,IAAII,EAAc,EAClB,QAAWtB,KAAYqB,EAAQ,CAC7B,IAAME,EAAYJ,EAAa,OAAOnB,CAAQ,EAG9C,IAFgBuB,EAAU,SAAW,CAAC,GAE1B,SAAW,EAAG,CACxBX,EAAQ,qBAAsB,yBAAyBZ,CAAQ,YAAY,EAC3E,QACF,CAGA,GAAI,CACFJ,EAAS,iBAAiBI,CAAQ,iBAAkB,CAClD,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNY,EAAQ,qBAAsB,UAAUZ,CAAQ,wCAAwC,EACxF,QACF,CAGA,IAAMS,EAAUV,GAAgBC,EAAUuB,EAAWrB,CAAS,EAC1DO,GAAWD,GAAYR,EAAUS,CAAO,IAC1Ca,IACAV,EAAQ,qBAAsB,yCAAyCZ,CAAQ,EAAE,EAErF,CAEAY,EAAQ,qBAAsB,+BAA+BU,CAAW,WAAW,EAGnF,GAAI,CACFE,GAAWR,CAAY,EAEvB,GAAI,CACFS,GAAUV,CAAU,CACtB,MAAQ,CAER,CACAH,EAAQ,qBAAsB,0BAA0B,CAC1D,MAAQ,CAER,CAEA,OAAOM,EAAoB,CAC7B,CCpLA,OAAS,cAAAQ,EAAY,gBAAAC,EAAc,aAAAC,GAAW,kBAAAC,EAAgB,iBAAAC,OAAqB,UACnF,OAAS,SAAAC,OAAa,qBAOtB,SAASC,GAAsBC,EAAqBC,EAA2B,CAC7E,GAAI,CAACC,EAAWF,CAAW,EACzB,MAAO,GAGT,GAAI,CAEF,IAAMG,EADY,KAAK,MAAMC,EAAaJ,EAAa,OAAO,CAAC,EAChC,WAAa,CAAC,EAE7C,GAAIE,EAAWD,CAAS,EAAG,CAEzB,IAAMI,EADQ,KAAK,MAAMD,EAAaH,EAAW,OAAO,CAAC,EACjC,kBAAoB,CAAC,EAC7C,OAAOE,EAAa,OAAQG,GAA+B,CAACD,EAAU,SAASC,EAAE,WAAW,CAAC,EAAE,MACjG,CAEA,OAAOH,EAAa,MACtB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASI,GAAqBC,EAA6D,CACzF,GAAI,CAACN,EAAWM,CAAW,EACzB,MAAO,CAAE,MAAO,EAAG,SAAU,CAAC,CAAE,EAGlC,GAAI,CACF,IAAMC,EAAUL,EAAaI,EAAa,OAAO,EAE7CE,EACJ,GAAI,CACFA,EAAWD,EACR,MAAM;AAAA,CAAI,EACV,OAAQE,GAASA,EAAK,KAAK,CAAC,EAC5B,IAAKA,GAAS,KAAK,MAAMA,CAAI,CAAC,CACnC,MAAQ,CACND,EAAW,CAAC,KAAK,MAAMD,CAAO,CAAC,CACjC,CAEA,IAAMG,EAAUF,EAAS,OAAQG,GAAWA,EAAE,eAAiB,EAAI,EACnE,MAAO,CAAE,MAAOD,EAAQ,OAAQ,SAAUA,CAAQ,CACpD,MAAQ,CACN,MAAO,CAAE,MAAO,EAAG,SAAU,CAAC,CAAE,CAClC,CACF,CAKA,SAASE,GAAaC,EAA4B,CAChD,OAAOA,EAAW,MAAM,GAAG,EAAE,IAAI,GAAK,SACxC,CAKA,SAASC,GAAmBD,EAI1B,CACA,IAAIE,EAAc,GACdC,EAAW,GACXC,EAAY,GAEVC,EAAe,GAAGL,CAAU,sCAClC,GAAIb,EAAWkB,CAAY,EACzB,GAAI,CACF,IAAMC,EAAQ,KAAK,MAAMjB,EAAagB,EAAc,OAAO,CAAC,EAC5DH,EAAcI,EAAM,cAAgBA,EAAM,MAAQ,EACpD,MAAQ,CAER,CAGF,IAAMC,EAAc,GAAGP,CAAU,+BACjC,GAAIb,EAAWoB,CAAW,EACxB,GAAI,CAOFJ,EANgBd,EAAakB,EAAa,OAAO,EAE9C,MAAM;AAAA,CAAI,EACV,OAAQX,GAASA,EAAK,KAAK,CAAC,EAC5B,IAAKA,GAAS,KAAK,MAAMA,CAAI,CAAC,EACA,OAAQY,GAAM,CAACA,EAAE,QAAQ,EAAE,MAAM,EAAE,EACtC,IAAKA,GAAMA,EAAE,aAAe,EAAE,EAAE,KAAK,IAAI,CACzE,MAAQ,CAER,CAGF,MAAO,CAAE,YAAAN,EAAa,SAAAC,EAAU,UAAAC,CAAU,CAC5C,CAKO,SAASK,GAAsBC,EAA8B,CAElE,GAAI,CAAC,QAAQ,IAAI,aACf,OAAAC,EAAQ,2BAA4B,iDAAiD,EAC9EC,EAAoB,EAG7B,IAAMZ,EAAaU,EAAM,aAAeG,EAAc,EAChDC,EAAaC,GAAc,EAE3B9B,EAAc,GAAG6B,CAAU,0CAC3BrB,EAAc,GAAGO,CAAU,qCAC3Bd,EAAY,GAAG4B,CAAU,kDAGzBE,EAAgBhC,GAAsBC,EAAaC,CAAS,EAC5D,CAAE,MAAO+B,EAAc,SAAUC,CAAgB,EAAI1B,GAAqBC,CAAW,EAGrF,CAAE,YAAAS,EAAa,SAAAC,EAAU,UAAAC,CAAU,EAAIH,GAAmBD,CAAU,EAG1E,GAAIgB,IAAkB,GAAKC,IAAiB,GAAK,CAACf,EAChD,OAAOU,EAAoB,EAG7B,IAAMO,EAAYpB,GAAaC,CAAU,EACnCoB,EAAU,GAAGpB,CAAU,8BAG7B,GAAI,CACFqB,GAAU,GAAGrB,CAAU,gBAAiB,CAAE,UAAW,EAAK,CAAC,CAC7D,MAAQ,CAER,CAGA,IAAMsB,EAAqB,CAAC,EAI5B,GAHIN,EAAgB,GAClBM,EAAS,KAAK,GAAGN,CAAa,oBAAoB,EAEhDC,EAAe,EAAG,CACpBK,EAAS,KAAK,GAAGL,CAAY,yBAAyB,EAGtD,IAAMM,GAAW,IAAI,IAAIL,EAAgB,IAAKpB,GAAWA,EAAE,UAAYA,EAAE,KAAK,EAAE,OAAO,OAAO,CAAC,EACzF0B,EAAe,MAAM,KAAKD,EAAQ,EAAE,MAAM,EAAG,CAAC,EAChDC,EAAa,OAAS,GACxBF,EAAS,KAAK,WAAWE,EAAa,KAAK,IAAI,CAAC,EAAE,CAEtD,CAEA,IAAMC,GAAUH,EAAS,OAAS,EAAIA,EAAS,KAAK,IAAI,EAAI,mBAGxDI,GAAcxB,GAAe,eAC7Bc,EAAgB,IAClBU,IAAe,KAAKV,CAAa,oBAE/BC,EAAe,IACjBS,IAAe,KAAKT,CAAY,sBAGlC,IAAIU,GAAc,oBAAoBD,EAAW,GAC7CvB,IACFwB,IAAe,gBAAgBxB,CAAQ,IAErCC,IACFuB,IAAe,YAAYvB,CAAS,IAItC,IAAMwB,GAAa,GAAGd,CAAU,iDAC1Be,GAAa,QAAQ,IAAI,aAE3BC,EAEJ,GAAI3C,EAAWyC,EAAU,GAAKC,GAAY,CACxC,IAAME,GAAY,IAAI,KAAK,EAAE,YAAY,EACzC,GAAI,CACFC,EAAeZ,EAAS,IAAIW,EAAS;AAAA,CAA6C,CACpF,MAAQ,CAER,CAGA,IAAME,EAAkB,KAAK,UAAU,CACrC,KAAM,kBACN,OAAQ,cACR,QAASd,EACT,aAAc,CAAC,CAAChB,EAChB,eAAgB,CAAC,CAACC,EAClB,OAAQ,mBACV,CAAC,EAEK8B,EAAQC,GACZ,UACA,CACEP,GACA,SACAD,GACA,YACA,GAAGR,CAAS,cACZ,aACAc,EACA,gBACF,EACA,CACE,SAAU,GACV,MAAO,CAAC,SAAU,OAAQ,MAAM,CAClC,CACF,EAwBA,GAtBAC,EAAM,GAAG,QAAUE,GAAQ,CACzB,IAAMC,EAAe,IAAI,KAAK,EAAE,YAAY,EAC5C,GAAI,CACFL,EAAeZ,EAAS,IAAIiB,CAAY,+BAA+BD,EAAI,OAAO;AAAA,CAAI,CACxF,MAAQ,CAER,CACF,CAAC,EAEDF,EAAM,GAAG,QAAUI,GAAS,CAC1B,IAAMC,EAAiB,IAAI,KAAK,EAAE,YAAY,EAC9C,GAAI,CACED,IAAS,EACXN,EAAeZ,EAAS,IAAImB,CAAc;AAAA,CAAiC,EAE3EP,EAAeZ,EAAS,IAAImB,CAAc,2BAA2BD,CAAI;AAAA,CAAI,CAEjF,MAAQ,CAER,CACF,CAAC,EAEGJ,EAAM,OAAQ,CAChB,IAAIM,EAAa,GACjBN,EAAM,OAAO,GAAG,OAASO,GAAkB,CACzCD,GAAcC,EAAM,SAAS,CAC/B,CAAC,EACDP,EAAM,OAAO,GAAG,MAAO,IAAM,CAC3B,GAAIM,EAAW,KAAK,EAAG,CACrB,IAAMH,EAAe,IAAI,KAAK,EAAE,YAAY,EAC5C,GAAI,CACFL,EAAeZ,EAAS,IAAIiB,CAAY,kBAAkBG,EAAW,KAAK,CAAC;AAAA,CAAI,CACjF,MAAQ,CAER,CACF,CACF,CAAC,CACH,CAKA,GAHAN,EAAM,MAAM,EAGRjB,EAAe,GAAK9B,EAAWM,CAAW,EAC5C,GAAI,CAEF,IAAMiD,EADUrD,EAAaI,EAAa,OAAO,EAE9C,MAAM;AAAA,CAAI,EACV,OAAQG,IAASA,GAAK,KAAK,CAAC,EAC5B,IAAKA,IAAS,CACb,IAAM+C,GAAM,KAAK,MAAM/C,EAAI,EAC3B,OAAA+C,GAAI,aAAe,GACZ,KAAK,UAAUA,EAAG,CAC3B,CAAC,EACA,KAAK;AAAA,CAAI,EACZC,GAAcnD,EAAaiD,CAAO,CACpC,MAAQ,CAER,CAGFZ,EAAW,4BAA4BL,EAAO,EAChD,MACEK,EAAW,eAAeL,EAAO,mDAGnC,OAAAd,EAAQ,2BAA4BmB,CAAQ,EAErC,CACL,SAAU,GACV,cAAeA,CACjB,CACF,CCxSA,OAAS,cAAAe,EAAY,gBAAAC,GAAc,cAAAC,OAAkD,UACrF,OAAS,YAAAC,OAAuB,qBAOhC,SAASC,EAAUC,EAAgBC,EAAmB,CACpD,GAAI,CACFC,GAAS,YAAYF,CAAM,MAAMC,CAAG,IAAK,CACvC,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CAER,CACF,CAKA,SAASE,GAASH,EAAgBI,EAA4B,CAC5D,GAAI,CAKF,OAJeF,GACb,YAAYF,CAAM,sEAAsEI,CAAS,MACjG,CAAE,SAAU,OAAQ,QAAS,IAAM,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CACrE,EAAE,KAAK,IACW,GACpB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAcC,EAA2B,CAChD,IAAMC,EAAU,GAAGD,CAAW,iBAC9B,GAAKE,EAAWD,CAAO,EAIvB,GAAI,CACF,IAAME,EAAM,SAASC,GAAaH,EAAS,OAAO,EAAE,KAAK,EAAG,EAAE,EAC9D,GAAI,CACF,QAAQ,KAAKE,EAAK,CAAC,EACnB,QAAQ,KAAKA,CAAG,EAChBE,EAAQ,yBAA0B,mCAAmCF,CAAG,GAAG,CAC7E,MAAQ,CAER,CACAG,GAAWL,CAAO,CACpB,MAAQ,CAER,CACF,CAKA,SAASM,GAAab,EAAgBc,EAA0B,CAC9DH,EAAQ,yBAA0B,wBAAwB,EAC1DZ,EAAUC,EAAQ,+CAA+Cc,CAAU,IAAI,EAC/EH,EAAQ,yBAA0B,oBAAoB,CACxD,CAKA,SAASI,GAAiBf,EAAgBc,EAA0B,CAClEH,EAAQ,yBAA0B,yBAAyB,EAEvDR,GAASH,EAAQ,aAAa,GAChCD,EACEC,EACA,oGAAoGc,CAAU,0BAChH,EACAH,EAAQ,yBAA0B,qBAAqB,GAEvDA,EAAQ,yBAA0B,gCAAgC,CAEtE,CAKA,SAASK,GAAqBhB,EAAgBc,EAA0B,CAClEX,GAASH,EAAQ,WAAW,GAC9BD,EACEC,EACA,4FAA4Fc,CAAU,IACxG,EACAH,EAAQ,yBAA0B,uCAAuC,GAEzEA,EAAQ,yBAA0B,4CAA4C,CAElF,CAKA,SAASM,GAAkBjB,EAAgBc,EAA0B,CACnE,GAAI,CAACX,GAASH,EAAQ,UAAU,EAAG,CACjCW,EAAQ,yBAA0B,uCAAuC,EACzE,MACF,CAEA,IAAMO,EAAY,OAAO,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,MAAM,EAAG,EAAE,CAAC,GAC1DC,EAAY,IAAI,KAAK,EAAE,YAAY,EACnCC,EAAU,KAAK,UAAU,CAAE,YAAaN,EAAY,UAAAK,CAAU,CAAC,EAAE,QAAQ,KAAM,IAAI,EAEzFpB,EACEC,EACA,6GAA6GkB,CAAS,OAAOJ,CAAU,yBAAyBM,CAAO,iCACzK,EACAT,EAAQ,yBAA0B,yBAAyB,CAC7D,CAKA,SAASU,GAAqBf,EAA2B,CACvD,IAAMgB,EAAgB,CAAC,uBAAwB,cAAe,0BAA0B,EAExF,QAAWC,KAAQD,EAAe,CAChC,IAAME,EAAW,GAAGlB,CAAW,IAAIiB,CAAI,GACvC,GAAI,CACEf,EAAWgB,CAAQ,GACrBZ,GAAWY,CAAQ,CAEvB,MAAQ,CAER,CACF,CAEAb,EAAQ,yBAA0B,2BAA2B,CAC/D,CAKO,SAASc,GAAqBC,EAA8B,CACjE,IAAMC,EAAaD,EAAM,aAAeE,EAAc,EAChDtB,EAAc,GAAGqB,CAAU,aAC3B3B,EAAS,GAAG2B,CAAU,mCAG5B,GAAI,CAACnB,EAAWR,CAAM,EACpB,OAAAW,EAAQ,yBAA0B,4CAA4C,EACvEkB,EAAoB,EAI7B,IAAMC,EAAS,GAAGxB,CAAW,WAC7B,GAAI,CAACE,EAAWsB,CAAM,EACpB,OAAAnB,EAAQ,yBAA0B,wCAAwC,EACnEkB,EAAoB,EAI7B,IAAIf,EACJ,GAAI,CAEFA,EADe,KAAK,MAAMJ,GAAaoB,EAAQ,OAAO,CAAC,EACnC,WACtB,MAAQ,CACN,OAAAnB,EAAQ,yBAA0B,4BAA4B,EACvDkB,EAAoB,CAC7B,CAEA,OAAAlB,EAAQ,yBAA0B,uCAAuCG,CAAU,KAAK,EAGxFT,GAAcC,CAAW,EAGzBO,GAAab,EAAQc,CAAU,EAG/BC,GAAiBf,EAAQc,CAAU,EAGnCG,GAAkBjB,EAAQc,CAAU,EAGpCE,GAAqBhB,EAAQc,CAAU,EAGvCO,GAAqBf,CAAW,EAEhCK,EAAQ,yBAA0B,yBAAyB,EAC3DA,EAAQ,yBAA0B,aAAaG,CAAU,EAAE,EAC3DH,EAAQ,yBAA0B,oBAAoB,EACtDA,EAAQ,yBAA0B,kCAAkC,EAE7DkB,EAAoB,CAC7B,CCpMA,OAAS,cAAAE,EAAY,aAAAC,GAAW,gBAAAC,GAAc,iBAAAC,EAAe,eAAAC,OAAmB,UAChF,OAAS,YAAAC,MAAgB,qBAezB,SAASC,GAAYC,EAAoBC,EAA+D,CACtG,GACE,CAACC,EAAW,GAAGF,CAAU,eAAe,GACvC,CAACE,EAAW,GAAGF,CAAU,oBAAoB,GAC5C,CAACE,EAAW,GAAGF,CAAU,YAAY,GACrC,CAACE,EAAW,GAAGF,CAAU,iBAAiB,EAE5C,OAAO,KAGTG,EAAQ,gBAAiB,sBAAsB,EAC/C,GAAI,CACFC,EAAS,mBAAoB,CAC3B,IAAKJ,EACL,SAAU,OACV,QAAS,KACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,OAASK,EAAY,CAEnB,GAAIA,EAAM,OAAQ,CAChBC,EAAc,GAAGL,CAAU,kBAAmBI,EAAM,MAAM,EAC1D,GAAI,CACF,IAAME,EAAS,KAAK,MAAMF,EAAM,MAAM,EACtC,MAAO,CACL,SAAUE,EAAO,UAAU,iBAAiB,UAAY,EACxD,KAAMA,EAAO,UAAU,iBAAiB,MAAQ,CAClD,CACF,MAAQ,CAER,CACF,CACF,CACA,OAAAJ,EAAQ,gBAAiB,oBAAoB,EACtC,CAAE,SAAU,EAAG,KAAM,CAAE,CAChC,CAKA,SAASK,GAAYR,EAAoBC,EAAmC,CAC1E,GAAI,CAACC,EAAW,GAAGF,CAAU,mBAAmB,GAAK,CAACE,EAAW,GAAGF,CAAU,iBAAiB,EAC7F,OAAO,KAGT,GAAI,CACFI,EAAS,kBAAmB,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,CACnF,MAAQ,CACN,OAAAD,EAAQ,gBAAiB,mCAAmC,EACrD,IACT,CAEAA,EAAQ,gBAAiB,sBAAsB,EAC/C,GAAI,CACF,IAAMI,EAASH,EAAS,0BAA2B,CACjD,IAAKJ,EACL,SAAU,OACV,QAAS,KACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACDM,EAAc,GAAGL,CAAU,kBAAmBM,CAAM,EACpD,IAAME,EAAS,KAAK,MAAMF,CAAM,EAChC,OAAAJ,EAAQ,gBAAiB,oBAAoB,EACtC,MAAM,QAAQM,CAAM,EAAIA,EAAO,OAAS,CACjD,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAWV,EAAoBC,EAAmC,CACzE,GAAI,CACFG,EAAS,gBAAiB,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,CACjF,MAAQ,CACN,OAAAD,EAAQ,gBAAiB,iCAAiC,EACnD,IACT,CAEAA,EAAQ,gBAAiB,oBAAoB,EAC7C,GAAI,CACF,IAAMI,EAASH,EAAS,uCAAwC,CAC9D,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACDM,EAAc,GAAGL,CAAU,gBAAiBM,CAAM,EAElD,IAAMI,GADS,KAAK,MAAMJ,CAAM,EACH,SAAW,CAAC,GAAG,OAAQK,GAAWA,EAAE,OAAO,WAAa,OAAO,EAAE,OAC9F,OAAAT,EAAQ,gBAAiB,kBAAkB,EACpCQ,CACT,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASE,GAAUb,EAAoBC,EAAmC,CAExE,GAAI,CAOF,GAAI,CANcG,EAAS,4CAA6C,CACtE,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAAE,KAAK,GACU,CAACE,EAAW,GAAGF,CAAU,UAAU,EACnD,OAAO,IAEX,MAAQ,CACN,OAAO,IACT,CAEA,GAAI,CACFI,EAAS,eAAgB,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,CAChF,MAAQ,CACN,OAAAD,EAAQ,gBAAiB,gCAAgC,EAClD,IACT,CAEAA,EAAQ,gBAAiB,mBAAmB,EAC5C,GAAI,CACF,OAAAC,EAAS,0BAA0BH,CAAU,eAAgB,CAC3D,IAAKD,EACL,SAAU,OACV,QAAS,KACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACDG,EAAQ,gBAAiB,iBAAiB,EACnC,CACT,MAAQ,CAEN,MAAO,EACT,CACF,CAKA,SAASW,GAAcd,EAAoBC,EAA4B,CACrEE,EAAQ,gBAAiB,6BAA6B,EAEtD,IAAMY,EAAiB,sEACnBC,EAAe,EACbC,EAAkD,CAAC,EAEnDC,EAAa,CAAC,MAAO,MAAO,MAAO,MAAM,EAE/C,SAASC,EAAQC,EAAmB,CAClC,GAAI,CACF,IAAMC,EAAUC,GAAYF,EAAK,CAAE,cAAe,EAAK,CAAC,EACxD,QAAWG,KAASF,EAAS,CAC3B,IAAMG,EAAW,GAAGJ,CAAG,IAAIG,EAAM,IAAI,GAGrC,GAAIA,EAAM,YAAY,EAAG,CAClB,CAAC,eAAgB,OAAQ,OAAQ,OAAO,EAAE,SAASA,EAAM,IAAI,GAChEJ,EAAQK,CAAQ,EAElB,QACF,CAGA,GAAKN,EAAW,KAAMO,GAAQF,EAAM,KAAK,SAASE,CAAG,CAAC,EAItD,GAAI,CACF,IAAMC,EAAUC,GAAaH,EAAU,OAAO,EAC1CT,EAAe,KAAKW,CAAO,IAC7BT,EAAS,KAAK,CAAE,KAAMO,EAAU,KAAM,kBAAmB,CAAC,EAC1DR,IAEJ,MAAQ,CAER,CACF,CACF,MAAQ,CAER,CACF,CAEA,OAAAG,EAAQnB,CAAU,EAElBM,EACE,GAAGL,CAAU,gBACb,KAAK,UAAU,CAAE,SAAAgB,EAAU,MAAOD,CAAa,EAAG,KAAM,CAAC,CAC3D,EAEAb,EAAQ,gBAAiB,8BAA8Ba,CAAY,mBAAmB,EAC/EA,CACT,CAKA,SAASY,GAAiB3B,EAAoB4B,EAAgC,CAC5E1B,EAAQ,gBAAiB,wBAAwB,EAEjD,IAAI2B,EAAgB,EAChBC,EAAY,EAEZF,EAAQ,WACVC,GAAiBD,EAAQ,SAAS,SAClCE,GAAaF,EAAQ,SAAS,MAE5BA,EAAQ,WAAa,OACvBE,GAAaF,EAAQ,UAEnBA,EAAQ,UAAY,OACtBE,GAAaF,EAAQ,SAGvB,IAAMG,EAAiBV,GAAYrB,CAAU,EAC1C,OAAQgC,GAAMA,EAAE,SAAS,OAAO,GAAK,CAACA,EAAE,SAAS,YAAY,CAAC,EAC9D,IAAKA,GAAMA,EAAE,QAAQ,QAAS,EAAE,CAAC,EAE9BC,EAAS,CACb,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,QAAS,CACP,SAAUJ,EACV,KAAMC,EACN,OAAQ,CACV,EACA,gBAAiBC,CACnB,EAEA1B,EAAc,GAAGL,CAAU,0BAA2B,KAAK,UAAUiC,EAAQ,KAAM,CAAC,CAAC,EAErF/B,EAAQ,gBAAiB,gCAAgC,EACzDA,EAAQ,gBAAiB,aAAa2B,CAAa,WAAWC,CAAS,EAAE,EAErED,EAAgB,GAClB,QAAQ,MAAM,aAAaA,CAAa,cAAcC,CAAS,6BAA6B,CAEhG,CAKO,SAASI,GAAuBC,EAA8B,CACnEjC,EAAQ,gBAAiB,+BAA+B,EAExD,IAAMH,EAAaoC,EAAM,aAAeC,EAAc,EAChDpC,EAAa,GAAGD,CAAU,+BAEhCsC,GAAUrC,EAAY,CAAE,UAAW,EAAK,CAAC,EAEzC,IAAM4B,EAA2B,CAC/B,SAAU,KACV,SAAU,KACV,QAAS,KACT,OAAQ,KACR,QAAS,CACX,EAGA,OAAAA,EAAQ,SAAW9B,GAAYC,EAAYC,CAAU,EACrD4B,EAAQ,SAAWrB,GAAYR,EAAYC,CAAU,EACrD4B,EAAQ,QAAUnB,GAAWV,EAAYC,CAAU,EACnD4B,EAAQ,OAAShB,GAAUb,EAAYC,CAAU,EACjD4B,EAAQ,QAAUf,GAAcd,EAAYC,CAAU,EAGtD2B,GAAiB3B,EAAY4B,CAAO,EAE7BU,EAAoB,CAC7B,CCzRA,OAAS,cAAAC,EAAY,aAAAC,EAAW,gBAAAC,EAAc,iBAAAC,MAAqB,UCHnE,OAAS,cAAAC,GAAY,kBAAAC,GAAgB,aAAAC,GAAW,gBAAAC,OAAoB,UCIpE,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UACnE,OAAS,YAAAC,OAAgB,qBACzB,OAAS,cAAAC,OAAkB,cAE3B,UAAYC,OAAQ,UAqEpB,IAAMC,GAAuB,8BACvBC,GAAO,8BAGPC,GAAmC,CACvC,gBAAiB,GACjB,eAAgB,GAChB,gBAAiB,GACjB,kBAAmB,GACnB,kBAAmB,GACnB,cAAe,GACf,mBAAoB,EACtB,EAMIC,EAAsC,KACtCC,EAAwC,KAiB5C,SAASC,EAAoBC,EAAuB,CAClD,OAAOC,GAAW,QAAQ,EACvB,OAAOD,EAAQE,EAAI,EACnB,OAAO,KAAK,EACZ,MAAM,EAAG,EAAE,CAChB,CAKA,SAASC,IAAuB,CAC9B,GAAI,CACF,OAAU,YAAS,CACrB,MAAQ,CACN,MAAO,iBACT,CACF,CAKA,SAASC,GAAeC,EAA+C,CACrE,IAAMC,EAAa,GAAGD,CAAU,IAAIE,EAAoB,GAExD,GAAI,CAACC,GAAWF,CAAU,EACxB,OAAO,KAGT,GAAI,CACF,IAAMG,EAAUC,GAAaJ,EAAY,MAAM,EAC/C,OAAO,KAAK,MAAMG,CAAO,CAC3B,OAASE,EAAO,CACd,OAAAC,EAAQ,gBAAiB,+BAA+BD,CAAK,GAAI,MAAM,EAChE,IACT,CACF,CAKA,SAASE,GAAeR,EAAuD,CAC7E,IAAMS,EAA4C,CAAC,EAEnD,GAAI,CACFA,EAAO,MAAQC,GAAS,wBAAyB,CAC/C,IAAKV,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAAE,KAAK,CACV,MAAQ,CAER,CAEA,GAAI,CACFS,EAAO,KAAOC,GAAS,uBAAwB,CAC7C,IAAKV,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAAE,KAAK,CACV,MAAQ,CAER,CAEA,OAAOS,CACT,CAKA,SAASE,IAAwC,CAE/C,MAAO,CAAE,SADQ,QAAQ,IAAI,MAAQ,QAAQ,IAAI,UAAY,QAAQ,IAAI,OACvD,CACpB,CAWO,SAASC,EAAoBZ,EAAmC,CAErE,GAAIa,EACF,OAAOA,EAGT,IAAMC,EAAMd,GAAce,EAAc,EAClCC,EAAYlB,GAAa,EAGzBmB,EAASlB,GAAee,CAAG,EACjC,GAAIG,GAAQ,QACV,OAAAJ,EAAiB,CACf,QAASI,EAAO,QAChB,aAAcA,EAAO,cAAgBA,EAAO,QAC5C,QAASA,EAAO,QAChB,WAAYD,EACZ,OAAQ,SACR,aAActB,EAAoBuB,EAAO,OAAO,EAChD,MAAOA,EAAO,QAAQ,SAAS,GAAG,EAAIA,EAAO,QAAU,MACzD,EACAV,EAAQ,gBAAiB,yBAAyBM,EAAe,OAAO,GAAI,OAAO,EAC5EA,EAIT,IAAMK,EAAMV,GAAeM,CAAG,EAC9B,GAAII,EAAI,MACN,OAAAL,EAAiB,CACf,QAASK,EAAI,MACb,aAAcA,EAAI,MAAQA,EAAI,MAAM,MAAM,GAAG,EAAE,CAAC,EAChD,QAASD,GAAQ,QACjB,WAAYD,EACZ,OAAQ,MACR,aAActB,EAAoBwB,EAAI,KAAK,EAC3C,MAAOA,EAAI,KACb,EACAX,EAAQ,gBAAiB,sBAAsBM,EAAe,OAAO,GAAI,OAAO,EACzEA,EAIT,IAAMM,EAAMR,GAAe,EAC3B,GAAIQ,EAAI,SAAU,CAChB,IAAMC,EAAS,GAAGD,EAAI,QAAQ,IAAIH,CAAS,GAC3C,OAAAH,EAAiB,CACf,QAASO,EACT,aAAcD,EAAI,SAClB,QAASF,GAAQ,QACjB,WAAYD,EACZ,OAAQ,MACR,aAActB,EAAoB0B,CAAM,CAC1C,EACAb,EAAQ,gBAAiB,sBAAsBM,EAAe,OAAO,GAAI,OAAO,EACzEA,CACT,CAGA,IAAMQ,EAAS3B,EAAoBsB,EAAY,QAAQ,GAAG,EAC1D,OAAAH,EAAiB,CACf,QAAS,QAAQQ,EAAO,MAAM,EAAG,CAAC,CAAC,GACnC,aAAc,YACd,QAASJ,GAAQ,QACjB,WAAYD,EACZ,OAAQ,YACR,aAAcK,CAChB,EACAd,EAAQ,gBAAiB,0BAA0BM,EAAe,OAAO,GAAI,OAAO,EAC7EA,CACT,CASO,SAASS,GAAmBtB,EAAsC,CACvE,GAAIuB,EACF,OAAOA,EAGT,IAAMT,EAAMd,GAAce,EAAc,EAClCE,EAASlB,GAAee,CAAG,EAEjC,OAAAS,EAAgB,CACd,GAAGC,GACH,GAAGP,GAAQ,OACb,EAEOM,CACT,CAKO,SAASE,GACdC,EACAC,EACS,CACT,IAAMC,EAAUN,GAAmB,EAInC,GADIK,IAAU,QAAU,CAACC,EAAQ,iBAC7BD,IAAU,UAAY,CAACC,EAAQ,eAAgB,MAAO,GAG1D,OAAQF,EAAU,CAChB,IAAK,YACH,OAAOE,EAAQ,gBACjB,IAAK,cACH,OAAOA,EAAQ,kBACjB,IAAK,cACH,OAAOA,EAAQ,kBACjB,IAAK,UACH,OAAOA,EAAQ,cACjB,QACE,MAAO,EACX,CACF,CAqEO,SAASC,GAAsC,CACpD,IAAMC,EAAWC,EAAoB,EAErC,MAAO,CACL,WAAYC,EAAa,EACzB,QAASF,EAAS,QAClB,aAAcA,EAAS,aACvB,QAASA,EAAS,QAClB,WAAYA,EAAS,WACrB,gBAAiBA,EAAS,OAC1B,UAAW,IAAI,KAAK,EAAE,YAAY,CACpC,CACF,CDjUA,IAAMG,GAAqB,yBAM3B,SAASC,GAAiBC,EAA4B,CACpD,OAAOF,GAAmB,KAAKE,CAAS,CAC1C,CAOA,SAASC,GAAcD,EAAoBE,EAA6B,CACtE,IAAMC,EAAMH,GAAaI,EAAa,EAChCC,EAAOH,GAAcI,EAAc,EAEzC,GAAI,CAACP,GAAiBI,CAAG,EACvB,MAAM,IAAI,MAAM,2BAA2B,EAE7C,MAAO,GAAGE,CAAI,4BAA4BF,CAAG,EAC/C,CAKA,SAASI,GAAcP,EAAoBE,EAA6B,CACtE,MAAO,GAAGD,GAAcD,EAAWE,CAAU,CAAC,eAChD,CAKA,SAASM,GAAiBR,EAAoBE,EAA2B,CACvE,IAAMO,EAAMR,GAAcD,EAAWE,CAAU,EAC1CQ,GAAWD,CAAG,GACjBE,GAAUF,EAAK,CAAE,UAAW,EAAK,CAAC,CAEtC,CAMA,IAAIG,GAAe,EAKnB,SAASC,IAA0B,CACjC,OAAAD,KACO,OAAO,KAAK,IAAI,CAAC,IAAIA,EAAY,EAC1C,CAaO,SAASE,GACdC,EACAC,EACAC,EAOI,CAAC,EACC,CACN,GAAI,CACF,IAAMC,EAAsB,CAC1B,SAAUL,GAAgB,EAC1B,WAAYE,EACZ,SAAUI,EAAmB,EAC7B,QAAS,CACP,KAAAH,EACA,MAAOI,GAAmBH,EAAQ,KAAK,EACvC,OAAQG,GAAmBH,EAAQ,MAAM,EACzC,YAAaA,EAAQ,YACrB,QAASA,EAAQ,SAAW,GAC5B,QAASA,EAAQ,QAAUI,GAASJ,EAAQ,QAAS,GAAG,EAAI,OAC5D,WAAYA,EAAQ,UACtB,CACF,EAEAT,GAAiB,EACjB,IAAMc,EAAaf,GAAc,EACjCgB,GAAeD,EAAY,KAAK,UAAUJ,CAAK,EAAI;AAAA,CAAI,EAEvDM,EAAQ,kBAAmB,WAAWT,CAAS,KAAKC,CAAI,GAAI,OAAO,CACrE,OAASS,EAAO,CACdD,EAAQ,kBAAmB,0BAA0BC,CAAK,GAAI,MAAM,CACtE,CACF,CA6KO,SAASC,IAAwB,CACtCC,GAAW,cAAe,UAAW,CACnC,QAAS,GACT,MAAO,CAAE,SAAU,IAAI,KAAK,EAAE,YAAY,CAAE,CAC9C,CAAC,CACH,CA0BO,SAASC,GAAkBC,EAAoC,CACpE,IAAMC,EAAaC,GAAcF,CAAS,EAE1C,GAAI,CAACG,GAAWF,CAAU,EACxB,MAAO,CAAC,EAGV,GAAI,CAGF,OAFgBG,GAAaH,EAAY,MAAM,EACzB,KAAK,EAAE,MAAM;AAAA,CAAI,EAAE,OAAO,OAAO,EAC1C,IAAII,GAAQ,KAAK,MAAMA,CAAI,CAAC,CAC3C,OAASC,EAAO,CACd,OAAAC,EAAQ,kBAAmB,kCAAkCD,CAAK,GAAI,MAAM,EACrE,CAAC,CACV,CACF,CAKO,SAASE,GAAuBR,EAAoC,CACzE,IAAMS,EAASV,GAAkBC,CAAS,EACpCU,EAAWC,EAAmB,EAE9BC,EAAgD,CACpD,cAAe,EACf,cAAe,EACf,eAAgB,EAChB,cAAe,EACf,kBAAmB,EACnB,iBAAkB,EAClB,eAAgB,EAChB,UAAW,EACX,cAAe,EACf,YAAa,EACb,6BAA8B,CAChC,EAEMC,EAAa,IAAI,IACjBC,EAAgB,IAAI,IACpBC,EAAiB,IAAI,IAEvBC,EACAC,EAEJ,QAAWC,KAAST,EAGlB,OAFAG,EAAYM,EAAM,UAAU,IAEpBA,EAAM,WAAY,CACxB,IAAK,gBACHL,EAAW,IAAIK,EAAM,QAAQ,IAAI,EACjC,MACF,IAAK,gBACHJ,EAAc,IAAII,EAAM,QAAQ,IAAI,EACpC,MACF,IAAK,iBACHH,EAAe,IAAIG,EAAM,QAAQ,IAAI,EACrC,MACF,IAAK,gBACHF,EAAYE,EAAM,SAAS,UAC3B,MACF,IAAK,cACHD,EAAUC,EAAM,SAAS,UACzB,KACJ,CAGF,IAAMC,EACJH,GAAaC,EACT,IAAI,KAAKA,CAAO,EAAE,QAAQ,EAAI,IAAI,KAAKD,CAAS,EAAE,QAAQ,EAC1D,OAEN,MAAO,CACL,WAAYhB,GAAaU,EAAS,WAClC,QAASA,EAAS,QAClB,aAAcA,EAAS,aACvB,QAASA,EAAS,QAClB,WAAYM,EACZ,SAAUC,EACV,YAAaE,EACb,aAAcP,EACd,YAAa,CAAC,GAAGC,CAAU,EAC3B,eAAgB,CAAC,GAAGC,CAAa,EACjC,gBAAiB,CAAC,GAAGC,CAAc,EACnC,eAAgBH,EAAY,cAC5B,kBAAmBA,EAAY,iBAC/B,gBAAiBA,EAAY,cAC/B,CACF,CAiBA,SAASQ,GAASC,EAAaC,EAAwB,CACrD,OAAID,EAAI,QAAUC,EAAeD,EAC1BA,EAAI,MAAM,EAAGC,EAAS,CAAC,EAAI,KACpC,CAKA,SAASC,GACPC,EACqC,CACrC,GAAI,CAACA,EAAK,OAEV,IAAMC,EAAqC,CAAC,EACtCC,EAAgB,CAAC,WAAY,SAAU,QAAS,MAAO,aAAc,MAAM,EAEjF,OAAW,CAACC,EAAKC,CAAK,IAAK,OAAO,QAAQJ,CAAG,EAAG,CAE9C,GAAIE,EAAc,KAAKG,GAAKF,EAAI,YAAY,EAAE,SAASE,CAAC,CAAC,EAAG,CAC1DJ,EAAUE,CAAG,EAAI,aACjB,QACF,CAGA,GAAI,OAAOC,GAAU,UAAYA,EAAM,OAAS,IAAK,CACnDH,EAAUE,CAAG,EAAIP,GAASQ,EAAO,GAAG,EACpC,QACF,CAGA,GAAI,OAAOA,GAAU,UAAYA,IAAU,MAAQ,CAAC,MAAM,QAAQA,CAAK,EAAG,CACxEH,EAAUE,CAAG,EAAIJ,GAAmBK,CAAgC,EACpE,QACF,CAEAH,EAAUE,CAAG,EAAIC,CACnB,CAEA,OAAOH,CACT,CEzfO,IAAMK,GAAgD,CAE3D,KAAM,SACN,KAAM,SACN,UAAW,MAGX,KAAM,YAGN,MAAO,aAGP,KAAM,YACN,UAAW,YACX,aAAc,YAGd,KAAM,YAGN,KAAM,QACN,MAAO,QAGP,SAAU,MAGV,gBAAiB,cAGjB,WAAY,YACZ,WAAY,YACZ,SAAU,YACV,QAAS,YACT,WAAY,YACZ,SAAU,YAGV,cAAe,cACf,aAAc,aAChB,EAaO,SAASC,GAAgBC,EAAgC,CAC9D,OAAOF,GAAgBE,CAAQ,GAAK,OACtC,CHnCA,SAASC,GAAoBC,EAA6B,CACxD,GAAI,CAACC,EAAWD,CAAW,EACzB,MAAO,GAGT,GAAI,CAEF,IAAME,EAD0B,KAAK,MAAMC,EAAaH,EAAa,OAAO,CAAC,EACvD,OAAS,CAAC,EAKhC,OAJe,OAAO,QAAQE,CAAK,EAChC,KAAK,CAAC,CAAC,CAAEE,CAAC,EAAG,CAAC,CAAEC,CAAC,IAAMA,EAAID,CAAC,EAC5B,MAAM,EAAG,EAAE,EACX,IAAI,CAAC,CAACE,CAAI,IAAMA,CAAI,EACT,KAAK,GAAG,CACxB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAaP,EAA6B,CACjD,GAAI,CAACC,EAAWD,CAAW,EACzB,MAAO,GAGT,GAAI,CAEF,IAAME,EAD0B,KAAK,MAAMC,EAAaH,EAAa,OAAO,CAAC,EACvD,OAAS,CAAC,EAChC,OAAO,OAAO,OAAOE,CAAK,EAAE,OAAO,CAACM,EAAKC,IAAUD,EAAMC,EAAO,CAAC,CACnE,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAmBR,EAAuB,CACjD,OAAIA,EAAM,SAAS,OAAO,GAAKA,EAAM,SAAS,MAAM,GAC9C,2BAA2B,KAAKA,CAAK,EAChC,0BAIPA,EAAM,SAAS,MAAM,GAAKA,EAAM,SAAS,MAAM,EAC1C,mBAGLA,EAAM,SAAS,MAAM,GAAK,CAACA,EAAM,SAAS,OAAO,EAC5C,cAGLA,EAAM,SAAS,OAAO,GAAKA,EAAM,SAAS,MAAM,EAC3C,sBAGLA,EAAM,SAAS,MAAM,GAAK,UAAU,KAAKA,CAAK,EACzC,iBAGF,SACT,CAKA,SAASS,GAAuBT,EAAuB,CAGrD,MAAO,SACT,CAKA,SAASU,GAAoBC,EAAsC,CACjE,GAAIZ,EAAWY,CAAW,EACxB,GAAI,CACF,OAAO,KAAK,MAAMV,EAAaU,EAAa,OAAO,CAAC,CACtD,MAAQ,CAER,CAGF,MAAO,CACL,QAAS,QACT,aAAc,KACd,eAAgB,EAChB,eAAgB,CACd,0BAA2B,EAC3B,mBAAoB,EACpB,YAAa,EACb,sBAAuB,EACvB,iBAAkB,EAClB,QAAS,CACX,EACA,sBAAuB,CAAC,EACxB,mBAAoB,CAClB,OAAQ,EACR,WAAY,EACZ,WAAY,EACZ,GAAI,EACJ,KAAM,EACN,QAAS,CACX,EACA,0BAA2B,EAC3B,iCAAkC,EAClC,eAAgB,CAAC,CACnB,CACF,CAKA,SAASC,GACPD,EACAE,EACAC,EACAC,EACAC,EACM,CACN,IAAMC,EAAUP,GAAoBC,CAAW,EACzCO,EAAY,IAAI,KAAK,EAAE,YAAY,EAiBzC,GAfAD,EAAQ,aAAeC,EACvBD,EAAQ,gBAAkB,EAG1BA,EAAQ,eAAeJ,CAAY,GAAKI,EAAQ,eAAeJ,CAAY,GAAK,GAAK,EAGrFI,EAAQ,mBAAmBH,CAAY,GAAKG,EAAQ,mBAAmBH,CAAY,GAAK,GAAK,EAG7FG,EAAQ,2BACLA,EAAQ,2BAA6BA,EAAQ,eAAiB,GAAKF,GAAaE,EAAQ,eAGrED,EAAa,MAAM,GAAG,EAAE,OAAO,OAAO,EAC1C,OAAS,EAAG,CAC5B,IAAMG,EAAS,IAAI,IAAI,CAACH,EAAc,GAAGC,EAAQ,qBAAqB,CAAC,EACvEA,EAAQ,sBAAwB,MAAM,KAAKE,CAAM,EAAE,MAAM,EAAG,EAAE,CAChE,CAEAC,EAAUT,EAAY,QAAQ,WAAY,EAAE,EAAG,CAAE,UAAW,EAAK,CAAC,EAClEU,EAAcV,EAAa,KAAK,UAAUM,EAAS,KAAM,CAAC,CAAC,CAC7D,CAKA,SAASK,GAAiBC,EAAuC,CAC/D,GAAIxB,EAAWwB,CAAY,EACzB,GAAI,CACF,OAAO,KAAK,MAAMtB,EAAasB,EAAc,OAAO,CAAC,CACvD,MAAQ,CAER,CAGF,MAAO,CACL,QAAS,MACT,QAAS,GACT,SAAU,CAAC,EACX,WAAY,CAAC,EACb,MAAO,CACL,MAAO,EACP,UAAW,EACX,SAAU,CACZ,CACF,CACF,CAUA,SAASC,IAGP,CACA,IAAMC,EAA0D,CAAC,EAEjE,GAAI,CAEF,IAAMC,EADSC,GAAkB,EACP,OAAOC,GAAKA,EAAE,aAAe,WAAW,EAElE,QAAWC,KAASH,EAAY,CAC9B,IAAMI,EAAWD,EAAM,QAAQ,KAEzBE,EAAYF,EAAM,QAAQ,OAAmC,UAC9DG,GAAgBF,CAAQ,EAExBL,EAAgBM,CAAQ,IAC3BN,EAAgBM,CAAQ,EAAI,CAAC,GAE/BN,EAAgBM,CAAQ,EAAED,CAAQ,GAAKL,EAAgBM,CAAQ,EAAED,CAAQ,GAAK,GAAK,CACrF,CACF,MAAQ,CAER,CAGA,IAAMG,EAAsC,CAAC,EAC7C,OAAW,CAACF,EAAU/B,CAAK,IAAK,OAAO,QAAQyB,CAAe,EAAG,CAC/D,IAAMS,EAAS,OAAO,QAAQlC,CAAK,EAAE,KAAK,CAAC,CAAC,CAAEE,CAAC,EAAG,CAAC,CAAEC,CAAC,IAAMA,EAAID,CAAC,EAC7DgC,EAAO,OAAS,IAClBD,EAAYF,CAAQ,EAAIG,EAAO,CAAC,EAAE,CAAC,EAEvC,CAEA,MAAO,CAAE,gBAAAT,EAAiB,YAAAQ,CAAY,CACxC,CAKA,SAASE,GAAsBC,EAA0B,CACvD,GAAM,CAAE,gBAAAX,EAAiB,YAAAQ,CAAY,EAAIT,GAAyB,EAElE,GAAI,OAAO,KAAKS,CAAW,EAAE,SAAW,EAAG,CACzCI,EAAQ,mBAAoB,4BAA4B,EACxD,MACF,CAGA,IAAMC,EAAY,GAAGF,CAAU,0CAE3BG,EAMA,CACF,QAAS,QACT,QAAS,GACT,kBAAmB,CAAC,EACpB,YAAa,CAAC,EACd,oBAAqB,CACvB,EAGA,GAAIxC,EAAWuC,CAAS,EACtB,GAAI,CACFC,EAAgB,KAAK,MAAMtC,EAAaqC,EAAW,OAAO,CAAC,CAC7D,MAAQ,CAER,CAIF,OAAW,CAACP,EAAU/B,CAAK,IAAK,OAAO,QAAQyB,CAAe,EAAG,CAC1Dc,EAAc,kBAAkBR,CAAQ,IAC3CQ,EAAc,kBAAkBR,CAAQ,EAAI,CAAC,GAE/C,OAAW,CAAC3B,EAAMG,CAAK,IAAK,OAAO,QAAQP,CAAK,EAC9CuC,EAAc,kBAAkBR,CAAQ,EAAE3B,CAAI,GAC3CmC,EAAc,kBAAkBR,CAAQ,EAAE3B,CAAI,GAAK,GAAKG,CAE/D,CAGA,OAAW,CAACwB,EAAU/B,CAAK,IAAK,OAAO,QAAQuC,EAAc,iBAAiB,EAAG,CAC/E,IAAML,EAAS,OAAO,QAAQlC,CAAK,EAAE,KAAK,CAAC,CAAC,CAAEE,CAAC,EAAG,CAAC,CAAEC,CAAC,IAAMA,EAAID,CAAC,EAC7DgC,EAAO,OAAS,IAClBK,EAAc,YAAYR,CAAQ,EAAIG,EAAO,CAAC,EAAE,CAAC,EAErD,CAEAK,EAAc,QAAU,IAAI,KAAK,EAAE,YAAY,EAC/CA,EAAc,qBAAuB,EAErCnB,EAAU,GAAGgB,CAAU,oBAAqB,CAAE,UAAW,EAAK,CAAC,EAC/Df,EAAciB,EAAW,KAAK,UAAUC,EAAe,KAAM,CAAC,CAAC,EAE/D,IAAMC,EAAY,OAAO,KAAKD,EAAc,WAAW,EAAE,OACzDF,EAAQ,mBAAoB,6BAA6BG,CAAS,aAAa,CACjF,CAKA,SAASC,GAAcL,EAA0B,CAC/C,IAAMM,EAAY,GAAGN,CAAU,wCACzBb,EAAe,GAAGa,CAAU,0CAElC,GAAI,CAACrC,EAAW2C,CAAS,EAAG,CAC1BL,EAAQ,mBAAoB,yBAAyB,EACrD,MACF,CAEA,IAAIM,EACJ,GAAI,CACFA,EAAQ,KAAK,MAAM1C,EAAayC,EAAW,OAAO,CAAC,CACrD,MAAQ,CACNL,EAAQ,mBAAoB,gCAAgC,EAC5D,MACF,CAEA,IAAMO,EAAaD,EAAM,UAAU,QAAU,EAC7C,GAAIC,IAAe,EAAG,CACpBP,EAAQ,mBAAoB,yBAAyB,EACrD,MACF,CAEAA,EAAQ,mBAAoB,cAAcO,CAAU,qBAAqB,EAEzE,IAAMC,EAAWvB,GAAiBC,CAAY,EACxCuB,EAAM,IAAI,KAAK,EAAE,YAAY,EAG7BC,EAAc,CAAC,GAAGF,EAAS,SAAU,GAAGF,EAAM,QAAQ,EACtDK,EAAa,IAAI,IACvB,QAAWC,KAAKF,EACdC,EAAW,IAAIC,EAAE,KAAMA,CAAC,EAE1B,IAAMC,EAAiB,MAAM,KAAKF,EAAW,OAAO,CAAC,EAG/CG,EAAYD,EAAe,OAAQD,GAAMA,EAAE,UAAY,SAAS,EAAE,OAClEG,EAAWF,EAAe,OAAQD,GAAMA,EAAE,UAAY,QAAQ,EAAE,OAGhEI,EAAqC,CAAC,EAC5C,QAAWJ,KAAKC,EACdG,EAAWJ,EAAE,QAAQ,GAAKI,EAAWJ,EAAE,QAAQ,GAAK,GAAK,EAG3D,IAAMK,EAA2B,CAC/B,QAAS,MACT,QAASR,EACT,SAAUI,EACV,WAAAG,EACA,MAAO,CACL,MAAOH,EAAe,OACtB,UAAAC,EACA,SAAAC,CACF,CACF,EAEAhC,EAAUG,EAAa,QAAQ,WAAY,EAAE,EAAG,CAAE,UAAW,EAAK,CAAC,EACnEF,EAAcE,EAAc,KAAK,UAAU+B,EAAS,KAAM,CAAC,CAAC,EAC5DjB,EAAQ,mBAAoB,8BAA8B,EAG1DhB,EAAcqB,EAAW,KAAK,UAAU,CAAE,SAAU,CAAC,CAAE,CAAC,CAAC,CAC3D,CAKO,SAASa,EAAgBC,EAA8B,CAC5DnB,EAAQ,mBAAoB,wCAAwC,EAEpE,IAAMD,EAAaoB,EAAM,aAAeC,EAAc,EAChD3D,EAAc,mCACd4D,EAAkB,GAAGtB,CAAU,2CAGrChB,EAAU,GAAGgB,CAAU,oBAAqB,CAAE,UAAW,EAAK,CAAC,EAC/DhB,EAAU,GAAGgB,CAAU,gBAAiB,CAAE,UAAW,EAAK,CAAC,EAG3D,IAAMrB,EAAYV,GAAaP,CAAW,EAE1C,GAAIiB,GAAa,EAAG,CAClB,IAAMC,EAAenB,GAAoBC,CAAW,EAC9Ce,EAAeL,GAAmBQ,CAAY,EAC9CF,EAAeL,GAAuBO,CAAY,EAExDJ,GAAsB8C,EAAiB7C,EAAcC,EAAcC,EAAWC,CAAY,EAE1FqB,EAAQ,mBAAoB,2BAA2BxB,CAAY,SAASC,CAAY,UAAUC,CAAS,EAAE,CAC/G,MACEsB,EAAQ,mBAAoB,mDAAmDtB,CAAS,GAAG,EAI7F,OAAAoB,GAAsBC,CAAU,EAGhCK,GAAcL,CAAU,EAExBC,EAAQ,mBAAoB,6BAA6B,EAElDsB,EAAoB,CAC7B,CIzbA,OAAS,cAAAC,GAAY,gBAAAC,OAAoB,UCOzC,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UAuCnE,SAASC,IAA0B,CACjC,IAAMC,EAAYC,EAAa,EAC/B,MAAO,GAAGC,EAAc,CAAC,wCAAwCF,CAAS,OAC5E,CAEA,SAASG,IAAkB,CACzB,IAAMC,EAAM,GAAGF,EAAc,CAAC,yBAC9B,GAAI,CAACG,GAAWD,CAAG,EACjB,GAAI,CACFE,GAAUF,EAAK,CAAE,UAAW,EAAK,CAAC,CACpC,MAAQ,CAER,CAEJ,CAEA,SAASG,IAA6B,CACpC,IAAMC,EAAOT,GAAgB,EAE7B,GAAIM,GAAWG,CAAI,EACjB,GAAI,CACF,OAAO,KAAK,MAAMC,GAAaD,EAAM,MAAM,CAAC,CAC9C,MAAQ,CAER,CAGF,MAAO,CACL,cAAe,QACf,UAAWP,EAAa,EACxB,MAAO,CAAC,EACR,UAAW,CAAC,EACZ,UAAW,IAAI,KAAK,EAAE,YAAY,CACpC,CACF,CAEA,SAASS,GAAaC,EAA8B,CAClDR,GAAU,EACV,IAAMK,EAAOT,GAAgB,EAC7BY,EAAS,UAAY,IAAI,KAAK,EAAE,YAAY,EAE5C,GAAI,CACFC,GAAcJ,EAAM,KAAK,UAAUG,EAAU,KAAM,CAAC,CAAC,CACvD,OAASE,EAAK,CACZC,EAAQ,mBAAoB,4BAA4BD,CAAG,EAAE,CAC/D,CACF,CAyHO,SAASE,GAA0BC,EAAgBC,EAAwB,CAChF,MAAO;AAAA;AAAA;AAAA;AAAA,aAIID,CAAM;AAAA;AAAA;AAAA;AAAA,cAILC,CAAM,EACpB,CAwHO,SAASC,IAAgC,CAC9C,IAAMC,EAAWC,GAAa,EACxBC,EAAY,IAAI,IACpBF,EAAS,MAAM,OAAOG,GAAKA,EAAE,SAAW,QAAQ,EAAE,IAAIA,GAAKA,EAAE,MAAM,CACrE,EAEA,OAAID,EAAU,OAAS,EAAU,CAAC,EAE3BF,EAAS,MAAM,OAAOG,GACvBA,EAAE,SAAW,WAAa,CAACA,EAAE,WAAaA,EAAE,UAAU,SAAW,EAC5D,GAGFA,EAAE,UAAU,MAAMC,GAAMF,EAAU,IAAIE,CAAE,CAAC,CACjD,CACH,CA0GO,SAASC,GAAgBC,EAAmB,KAAU,GAAK,IAAY,CAC5E,IAAMC,EAAWC,GAAa,EACxBC,EAAS,KAAK,IAAI,EAAIH,EAE5BC,EAAS,MAAQA,EAAS,MAAM,OAAOG,GACjCA,EAAE,SAAW,WAAaA,EAAE,SAAW,cAAsB,GAChD,IAAI,KAAKA,EAAE,SAAS,EAAE,QAAQ,EAC7BD,CACnB,EAEDF,EAAS,UAAYA,EAAS,UAAU,OAAOI,GACzCA,EAAE,SAAW,UAAkB,GACd,IAAI,KAAKA,EAAE,SAAS,EAAE,QAAQ,EAC7BF,CACvB,EAEDG,GAAaL,CAAQ,CACvB,CDpdO,SAASM,GAAoBC,EAA8B,CAChEC,EAAQ,wBAAyB,sCAAsC,EAEvE,IAAMC,EAAqB,CAAC,EAGtBC,EAAaH,EAAM,aAAeI,EAAc,EAChDC,EAAYL,EAAM,YAAcM,EAAa,EAC7CC,EAAe,GAAGJ,CAAU,wCAAwCE,CAAS,QAEnF,GAAIG,GAAWD,CAAY,EACzB,GAAI,CAEF,IAAME,GADW,KAAK,MAAMC,GAAaH,EAAc,OAAO,CAAC,EAClC,OAAS,CAAC,GAAG,OACvCI,GAA0BA,EAAE,SAAW,aAC1C,EACIF,EAAW,OAAS,IACtBR,EAAQ,wBAAyB,YAAYQ,EAAW,MAAM,wCAAwC,EACtGP,EAAS,KAAK,GAAGO,EAAW,MAAM,0DAA0D,EAEhG,OAASG,EAAO,CACdX,EAAQ,wBAAyB,2BAA2BW,CAAK,EAAE,CACrE,CAIF,IAAMC,EAAUC,GAAiB,EAC7BC,EAAqB,GACzB,GAAIF,EAAQ,OAAS,EAAG,CACtBZ,EAAQ,wBAAyB,SAASY,EAAQ,MAAM,iBAAiB,EACzEE,EAAqB;AAAA;AAAA;AAAA;AAAA;AAAA,EACrB,QAAWC,KAAUH,EACnBE,GAAsB;AAAA,EAAKE,GAA0BD,EAAO,OAAQ,gCAAgC,CAAC,EAEzG,CAGA,IAAME,EAAY,gCAClB,GAAIV,GAAWU,CAAS,EACtB,GAAI,CAEF,IAAMT,EADoB,KAAK,MAAMC,GAAaQ,EAAW,OAAO,CAAC,EAC5C,OAAQP,GAAMA,EAAE,SAAW,aAAa,EAC7DF,EAAW,OAAS,IACtBR,EAAQ,wBAAyB,YAAYQ,EAAW,MAAM,mCAAmC,EACjGP,EAAS,KAAK,GAAGO,EAAW,MAAM,mCAAmC,EAEzE,OAASG,EAAO,CACdX,EAAQ,wBAAyB,+BAA+BW,CAAK,EAAE,CACzE,CAGF,GAAIV,EAAS,OAAS,GAAKa,EAAoB,CAC7C,IAAII,EAAU;AAAA;AAAA,EAAiCjB,EAAS,IAAIkB,GAAK,KAAKA,CAAC,EAAE,EAAE,KAAK;AAAA,CAAI,CAAC,GACrF,OAAIL,IACFI,GAAWJ,GAENM,GAAkBF,CAAO,CAClC,CAEA,OAAOG,EAAoB,CAC7B,CEpEA,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UAanE,SAASC,IAAsB,CAC7B,MAAO,GAAGC,EAAc,CAAC,wBAC3B,CAEA,SAASC,IAAuB,CAC9B,IAAMC,EAAYC,EAAa,EAC/B,MAAO,GAAGJ,GAAY,CAAC,YAAYG,CAAS,OAC9C,CAEA,SAASE,IAAwB,CAC/B,MAAO,GAAGJ,EAAc,CAAC,oCAC3B,CAuOA,IAAMK,GAA6C,CACjD,mBAAoB,GACpB,qBAAsB,GACtB,wBAAyB,IACzB,kBAAmB,GACnB,gBAAiB,GACjB,WAAY,EACZ,iBAAkB,GACpB,EAKO,SAASC,IAAkC,CAChD,IAAMC,EAAaC,GAAc,EAEjC,GAAIC,GAAWF,CAAU,EACvB,GAAI,CACF,IAAMG,EAAOC,GAAaJ,EAAY,MAAM,EAC5C,MAAO,CAAE,GAAGF,GAAuB,GAAG,KAAK,MAAMK,CAAI,CAAE,CACzD,MAAQ,CAER,CAGF,OAAOL,EACT,CAyBO,SAASO,IAA0B,CACxC,IAAMC,EAAYC,GAAa,EAE/B,GAAI,CACF,GAAIC,GAAWF,CAAS,EAAG,CACzB,GAAM,CAAE,WAAAG,CAAW,EAAI,GAAQ,SAAS,EACxCA,EAAWH,CAAS,EACpBI,EAAQ,sBAAuB,uBAAuB,CACxD,CACF,MAAQ,CAER,CACF,CAKO,SAASC,IAAyB,CACvC,IAAMC,EAAMC,GAAY,EAExB,GAAKL,GAAWI,CAAG,EAEnB,GAAI,CACF,GAAM,CAAE,YAAAE,EAAa,SAAAC,EAAU,WAAAN,CAAW,EAAI,GAAQ,SAAS,EACzDO,EAAQF,EAAYF,CAAG,EAC1B,OAAQK,GAAcA,EAAE,WAAW,UAAU,GAAKA,EAAE,SAAS,OAAO,CAAC,EACrE,IAAKA,IAAe,CACnB,KAAMA,EACN,KAAM,GAAGL,CAAG,IAAIK,CAAC,GACjB,MAAOF,EAAS,GAAGH,CAAG,IAAIK,CAAC,EAAE,EAAE,MAAM,QAAQ,CAC/C,EAAE,EACD,KAAK,CAACC,EAAsBC,IAAyBA,EAAE,MAAQD,EAAE,KAAK,EAGzE,QAAWE,KAAQJ,EAAM,MAAM,CAAC,EAC9B,GAAI,CACFP,EAAWW,EAAK,IAAI,EACpBV,EAAQ,sBAAuB,yBAAyBU,EAAK,IAAI,EAAE,CACrE,MAAQ,CAER,CAEJ,MAAQ,CAER,CACF,CC/UA,IAAMC,GAAoB,IAAU,GAAK,GAAK,IAS9C,SAASC,GAAkBC,EAAoD,CAC7E,IAAMC,EAAS,KAAK,IAAI,EAAIH,GAEtBI,EAASF,EAAK,QAAQ,OAC5BA,EAAK,QAAUA,EAAK,QAAQ,OAAOG,GACd,IAAI,KAAKA,EAAE,SAAS,EAAE,QAAQ,EAC7BF,CACrB,EACD,IAAMG,EAAQJ,EAAK,QAAQ,OAEvBE,IAAWE,GACbC,EAAQ,sBAAuB,cAAcH,EAASE,CAAK,cAAc,CAE7E,CAKA,SAASE,GAAgBN,EAAsD,CAC7E,IAAMO,EAAQP,EAAK,MACbQ,EAAYD,EAAM,UACrB,MAAM,EAAG,CAAC,EACV,IAAIE,GAAK,GAAGA,EAAE,KAAK,IAAI,KAAK,MAAMA,EAAE,YAAc,GAAG,CAAC,IAAI,EAC1D,KAAK,IAAI,EAEZ,MAAO,wBAAwBF,EAAM,eAAe,gBAC/C,KAAK,MAAMA,EAAM,YAAc,GAAG,CAAC,mBACnCP,EAAK,YAAY,MAAM,oCACXQ,GAAa,MAAM,EACtC,CAeO,SAASE,EAAmBC,EAA+B,CAGhE,GAAI,CADWC,GAAW,EACd,kBAEV,OAAAC,GAAkB,EAClBC,GAAiB,EACVC,EAAoB,EAG7BV,EAAQ,sBAAuB,mDAAmD,EAElF,GAAI,CAEF,IAAML,EAAOgB,EAAoB,EAGjCC,GAAWjB,CAAI,EAGfD,GAAkBC,CAAI,EAGtBkB,GAAoBlB,CAAI,EAGxB,IAAMmB,EAAUb,GAAgBN,CAAI,EACpCK,EAAQ,sBAAuBc,CAAO,CAExC,OAASC,EAAK,CACZf,EAAQ,sBAAuB,qCAAqCe,CAAG,EAAE,CAC3E,CAGA,GAAI,CACFP,GAAkB,EAClBC,GAAiB,EACjBO,GAAgB,EAChBhB,EAAQ,sBAAuB,0BAA0B,CAC3D,OAASe,EAAK,CACZf,EAAQ,sBAAuB,+BAA+Be,CAAG,EAAE,CACrE,CAEA,OAAOL,EAAoB,CAC7B,CC5GA,OAAS,cAAAO,EAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UACnE,OAAS,QAAAC,EAAM,WAAAC,OAAe,YCH9B,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,GAAW,kBAAAC,OAAsB,UACnF,OAAS,QAAAC,GAAM,WAAAC,OAAe,YA+G9B,SAASC,GAAgBC,EAA2B,CAClD,OAAOC,GAAKC,EAAc,EAAG,UAAW,SAAU,QAAS,GAAGF,CAAS,OAAO,CAChF,CAKA,SAASG,IAAgC,CACvC,OAAOF,GAAKC,EAAc,EAAG,UAAW,SAAU,uBAAuB,CAC3E,CAKO,SAASE,GAAiBJ,EAAwC,CACvE,IAAMK,EAAWN,GAAgBC,CAAS,EAE1C,GAAI,CAACM,GAAWD,CAAQ,EACtB,OAAO,KAGT,GAAI,CACF,IAAME,EAAUC,GAAaH,EAAU,OAAO,EAC9C,OAAO,KAAK,MAAME,CAAO,CAC3B,OAASE,EAAK,CACZ,OAAAC,EAAQ,wBAAyB,2BAA2BV,CAAS,KAAKS,CAAG,GAAI,MAAM,EAChF,IACT,CACF,CAyBA,SAASE,GAAYC,EAA6B,CAChD,IAAMC,EAAcC,GAAsB,EAE1C,GAAI,CACF,IAAMC,EAAMC,GAAQH,CAAW,EAC1BI,GAAWF,CAAG,GACjBG,GAAUH,EAAK,CAAE,UAAW,EAAK,CAAC,EAGpC,IAAMI,EAAO,KAAK,UAAUP,CAAI,EAAI;AAAA,EACpC,OAAAQ,GAAeP,EAAaM,CAAI,EACzB,EACT,OAASE,EAAK,CACZ,OAAAC,EAAQ,wBAAyB,2BAA2BD,CAAG,GAAI,MAAM,EAClE,EACT,CACF,CA0FO,SAASE,GAAqBC,EAAwC,CAC3E,GAAIA,EAAQ,OAAS,EACnB,MAAO,QAIT,IAAMC,EAAS,CACb,YAAa,EACb,aAAc,EACd,QAAS,EACT,SAAU,EACV,MAAO,EACP,UAAW,EACX,IAAK,EACL,MAAO,CACT,EAEA,QAAWC,KAAUF,EACnBC,EAAOC,EAAO,QAAQ,IAKxB,GAAID,EAAO,SAAW,EAAG,CACvB,IAAME,EAAcH,EACjB,IAAI,CAACI,EAAG,IAAOA,EAAE,WAAa,UAAY,EAAI,EAAG,EACjD,OAAOC,GAAKA,GAAK,CAAC,EACfC,EAAeN,EAClB,IAAI,CAACI,EAAG,IAAOA,EAAE,WAAa,eAAiB,EAAI,EAAG,EACtD,OAAOC,GAAKA,GAAK,CAAC,EAErB,GAAIF,EAAY,QAAU,GAAKG,EAAa,OAAS,GAE/CH,EAAY,CAAC,EAAIG,EAAa,CAAC,EACjC,MAAO,YAGb,CAIA,GAAIL,EAAO,aAAe,GAAKA,EAAO,aAAe,GAChCM,GAAmBP,EAAS,aAAa,GAC1C,EAChB,MAAO,gBAMX,GAAIC,EAAO,cAAgB,GAAMA,EAAO,UAAYA,EAAO,SAAY,GACjDO,GAAkBR,EAAS,eAAgB,CAAC,YAAa,SAAS,CAAC,GACpE,EACjB,MAAO,eAKX,GAAIC,EAAO,OAAS,GAAKA,EAAO,MAAQD,EAAQ,OAAS,GACvD,MAAO,iBAKT,GAAIC,EAAO,cAAgB,GAAKA,EAAO,UAAY,EAAG,CACpD,IAAMQ,EAAWT,EAAQ,IAAI,CAACI,EAAGC,IAAOD,EAAE,WAAa,UAAYC,EAAI,EAAG,EAAE,OAAOA,GAAKA,GAAK,CAAC,EAAE,IAAI,EACpG,GAAII,GAAYA,EAAWT,EAAQ,OAAS,EAC1C,MAAO,UAEX,CAEA,MAAO,OACT,CAKA,SAASO,GAAmBP,EAAuBU,EAAkC,CACnF,IAAIC,EAAS,EACTC,EAAa,EAEjB,QAAWV,KAAUF,EACfE,EAAO,WAAaQ,GACtBE,IACAD,EAAS,KAAK,IAAIA,EAAQC,CAAU,GAEpCA,EAAa,EAIjB,OAAOD,CACT,CAKA,SAASH,GACPR,EACAa,EACAC,EACQ,CACR,IAAIC,EAAe,EACfC,EAAW,GAEf,QAAWd,KAAUF,EAAS,CAC5B,IAAMiB,EAAMf,EAAO,WAAaW,EAC1BK,EAAMJ,EAAY,SAASZ,EAAO,QAAQ,EAE5Ce,GAAO,CAACD,EACVA,EAAW,GACFE,GAAOF,IAChBD,IACAC,EAAW,GAEf,CAEA,OAAOD,CACT,CASA,SAASI,GAAenB,EAAkC,CACxD,IAAMoB,EAAYpB,EAAQ,OAAOI,GAAKA,EAAE,SAAW,SAAS,EAAE,OAE9D,MAAO,CACL,cAAeJ,EAAQ,OACvB,MAAOA,EAAQ,OAAOI,GAAKA,EAAE,WAAa,aAAa,EAAE,OACzD,OAAQJ,EAAQ,OAAOI,GAAKA,EAAE,WAAa,cAAc,EAAE,OAC3D,MAAOJ,EAAQ,OAAOI,GAAKA,EAAE,WAAa,SAAS,EAAE,OACrD,OAAQJ,EAAQ,OAAOI,GAAKA,EAAE,WAAa,UAAU,EAAE,OACvD,aAAcJ,EAAQ,OAAOI,GAAKA,EAAE,WAAa,OAAO,EAAE,OAC1D,aAAcJ,EAAQ,OAAS,EAAIoB,EAAYpB,EAAQ,OAAS,CAClE,CACF,CAmEO,SAASqB,EAAoBC,EAAwC,CAC1E,IAAMC,EAAOC,GAAiBF,CAAS,EAEvC,OAAKC,GAKLA,EAAK,iBAAmBE,GAAqBF,EAAK,OAAO,EACzDA,EAAK,MAAQG,GAAeH,EAAK,OAAO,EAEjCA,GAPE,IAQX,CAKO,SAASI,GAAqBL,EAA4B,CAC/D,IAAMC,EAAOC,GAAiBF,CAAS,EAEvC,GAAI,CAACC,EACH,MAAO,GAITA,EAAK,iBAAmBE,GAAqBF,EAAK,OAAO,EACzDA,EAAK,MAAQG,GAAeH,EAAK,OAAO,EAGxC,IAAMK,EAAWC,GAAYN,CAAI,EAEjC,OAAIK,GACFE,EACE,wBACA,sBAAsBR,CAAS,KAAKC,EAAK,QAAQ,MAAM,sBAAsBA,EAAK,gBAAgB,GAClG,MACF,EAGKK,CACT,CDpbA,IAAMG,GAAqE,CACzE,aAAc,2CACd,gBAAiB,4CACjB,eAAgB,2CAChB,WAAY,mCACZ,iBAAkB,wCAClB,MAAS,yBACX,EAKA,SAASC,GAAmBC,EAAkCC,EAAsD,CAClH,IAAMC,EAAWD,EAAiB,KAAKE,GAAKA,EAAE,OAASH,CAAW,EAC5DI,EAAYF,EAAW,KAAK,IAAI,EAAGA,EAAS,UAAY,EAAG,EAAI,GAErE,MAAO,CACL,KAAMF,EACN,YAAaF,GAA8BE,CAAW,EACtD,UAAAI,EACA,eAAgB,CAAC,CACnB,CACF,CA0DA,IAAMC,GAAkB,EAWxB,SAASC,IAAqB,CAC5B,OAAO,QAAQ,IAAI,MAAQ,QAAQ,IAAI,aAAe,MACxD,CAKA,SAASC,IAA2B,CAClC,OAAOC,EAAKF,GAAW,EAAG,UAAW,YAAY,CACnD,CAKA,SAASG,GAAkBC,EAAwB,CACjD,IAAMC,EAAkBD,EAAO,QAAQ,oBAAqB,GAAG,EAC/D,OAAOF,EAAKD,GAAiB,EAAG,QAASI,CAAe,CAC1D,CAKA,SAASC,GAAmBF,EAAwB,CAClD,OAAOF,EAAKC,GAAkBC,CAAM,EAAG,cAAc,CACvD,CAKA,SAASG,GAAqBH,EAAwB,CACpD,IAAMC,EAAkBD,EAAO,QAAQ,oBAAqB,GAAG,EAC/D,OAAOF,EAAKM,EAAc,EAAG,UAAW,SAAU,QAASH,EAAiB,cAAc,CAC5F,CAMA,SAASI,GAAuBL,EAAyB,CACvD,IAAMM,EAAaH,GAAqBH,CAAM,EACxCO,EAAUL,GAAmBF,CAAM,EAGzC,GAAIQ,EAAWD,CAAO,EACpB,MAAO,GAIT,GAAIC,EAAWF,CAAU,EACvB,GAAI,CACF,IAAMG,EAASC,GAAQH,CAAO,EACzBC,EAAWC,CAAM,GACpBE,GAAUF,EAAQ,CAAE,UAAW,EAAK,CAAC,EAIvC,IAAMG,EAAUC,GAAaP,EAAY,MAAM,EACzCQ,EAAU,KAAK,MAAMF,CAAO,EAGlC,OAAAG,GAAcR,EAAS,KAAK,UAAUO,EAAS,KAAM,CAAC,CAAC,EAEvDE,EAAQ,eAAgB,wBAAwBhB,CAAM,4BAA6B,MAAM,EAClF,EACT,OAASiB,EAAO,CACd,OAAAD,EAAQ,eAAgB,8BAA8BC,CAAK,GAAI,MAAM,EAC9D,EACT,CAGF,MAAO,EACT,CASA,SAASC,GAAmBlB,EAA6B,CACvD,IAAMmB,EAAWC,EAAoB,EAC/BC,EAAM,IAAI,KAAK,EAAE,YAAY,EAEnC,MAAO,CACL,QAASrB,EACT,aAAcmB,EAAS,aACvB,aAAcA,EAAS,aACvB,QAASA,EAAS,QAClB,eAAgB,EAChB,WAAYE,EACZ,UAAWA,EACX,QAASC,GACT,YAAa,CAAC,EACd,YAAa,CAAC,EACd,WAAY,CAAC,EACb,UAAW,CAAC,EACZ,YAAa,CAAC,EACd,kBAAmB,CAAC,EACpB,oBAAqB,CAAC,CACxB,CACF,CAKO,SAASC,GAAgBvB,EAA8B,CAE5D,IAAMwB,EAAMxB,GAAUoB,EAAoB,EAAE,QAC5Cf,GAAuBmB,CAAG,EAE1B,IAAMC,EAAcvB,GAAmBsB,CAAG,EAG1C,GAAI,CAAChB,EAAWiB,CAAW,EACzB,OAAOP,GAAmBM,CAAG,EAG/B,GAAI,CACF,IAAMZ,EAAUC,GAAaY,EAAa,MAAM,EAC1CX,EAAU,KAAK,MAAMF,CAAO,EAGlC,OAAIE,EAAQ,QAAUQ,KAEpBR,EAAQ,QAAUQ,IAGbR,CACT,OAASG,EAAO,CACd,OAAAD,EAAQ,eAAgB,2BAA2BC,CAAK,GAAI,MAAM,EAC3DC,GAAmBM,CAAG,CAC/B,CACF,CAKO,SAASE,GAAgBZ,EAA+B,CAC7D,IAAMa,EAAa5B,GAAkBe,EAAQ,OAAO,EAC9CW,EAAcvB,GAAmBY,EAAQ,OAAO,EAEtD,GAAI,CACF,OAAKN,EAAWmB,CAAU,GACxBhB,GAAUgB,EAAY,CAAE,UAAW,EAAK,CAAC,EAG3Cb,EAAQ,UAAY,IAAI,KAAK,EAAE,YAAY,EAC3CC,GAAcU,EAAa,KAAK,UAAUX,EAAS,KAAM,CAAC,CAAC,EAE3DE,EAAQ,eAAgB,qBAAqBF,EAAQ,OAAO,GAAI,OAAO,EAChE,EACT,OAASG,EAAO,CACd,OAAAD,EAAQ,eAAgB,2BAA2BC,CAAK,GAAI,OAAO,EAC5D,EACT,CACF,CASA,SAASW,GACPC,EACAC,EACAC,EACY,CACZ,IAAMV,EAAM,IAAI,KAAK,EAAE,YAAY,EAEnC,GAAI,CAACQ,EACH,MAAO,CACL,MAAO,EACP,aAAcC,EAAU,EAAI,EAC5B,gBAAiBC,EACjB,WAAYV,EACZ,UAAWA,CACb,EAGF,IAAMW,EAAWH,EAAS,MAAQ,EAE5BI,GADe,KAAK,MAAMJ,EAAS,aAAeA,EAAS,KAAK,GAAKC,EAAU,EAAI,IACnDE,EAElCE,EAAiBL,EAAS,gBAC9B,OAAIE,IAAe,SACbF,EAAS,kBAAoB,OAC/BK,GACGL,EAAS,gBAAkBA,EAAS,MAAQE,GAAcC,EAE7DE,EAAiBH,GAId,CACL,MAAOC,EACP,aAAcC,EACd,gBAAiBC,EACjB,WAAYL,EAAS,WACrB,UAAWR,CACb,CACF,CAKO,SAASc,GACdrB,EACAsB,EACa,CAEb,GAAItB,EAAQ,oBAAoB,SAASsB,EAAQ,UAAU,EACzD,OAAApB,EAAQ,eAAgB,WAAWoB,EAAQ,UAAU,sBAAuB,OAAO,EAC5EtB,EAITA,EAAQ,iBACRA,EAAQ,oBAAoB,KAAKsB,EAAQ,UAAU,EAGnD,QAAWC,KAASD,EAAQ,YAC1BtB,EAAQ,YAAYuB,CAAK,EAAIT,GAC3Bd,EAAQ,YAAYuB,CAAK,EACzB,EACF,EAIF,QAAWC,KAASF,EAAQ,eAC1BtB,EAAQ,YAAYwB,CAAK,EAAIV,GAC3Bd,EAAQ,YAAYwB,CAAK,EACzB,EACF,EAIF,GAAI,CACF,IAAMC,EAAOC,EAAoBJ,EAAQ,UAAU,EACnD,GAAIG,GAAM,kBAAoBA,EAAK,mBAAqB,QAAS,CAE/D,IAAME,EAAcF,EAAK,iBACnBG,EAAgB5B,EAAQ,kBAAkB,UAAU6B,GAAKA,EAAE,OAASF,CAAW,EAErF,GAAIC,IAAkB,GAAI,CAExB,IAAMb,EAAWf,EAAQ,kBAAkB4B,CAAa,EACxDb,EAAS,UAAY,KAAK,IAAI,EAAGA,EAAS,UAAY,EAAG,EACzDf,EAAQ,kBAAkB,OAAO4B,EAAe,CAAC,EACjD5B,EAAQ,kBAAkB,QAAQe,CAAQ,CAC5C,KAAO,CAEL,IAAMe,EAAaC,GAAmBJ,EAAa3B,EAAQ,iBAAiB,EAC5EA,EAAQ,kBAAkB,QAAQ8B,CAAU,CAC9C,CAGI9B,EAAQ,kBAAkB,OAAS,KACrCA,EAAQ,kBAAoBA,EAAQ,kBAAkB,MAAM,EAAG,EAAE,GAEnEE,EAAQ,eAAgB,gCAAgCyB,CAAW,GAAI,OAAO,CAChF,CACF,OAASxB,EAAO,CAEdD,EAAQ,eAAgB,yCAAyCC,CAAK,GAAI,OAAO,CACnF,CAGA,IAAM6B,EAA0B,IAChC,OAAIhC,EAAQ,oBAAoB,OAASgC,IACvChC,EAAQ,oBAAsBA,EAAQ,oBAAoB,MACxD,CAACgC,CACH,GAGKhC,CACT,CA0KO,SAASiC,GAAgBC,EAI9B,CAEA,IAAMC,EAAgBD,EAAQ,UAAU,IAAIE,GAAK,CAC/C,GAAM,CAAE,QAAAC,EAAS,GAAGC,CAAK,EAAIF,EAC7B,OAAOE,CACT,CAAC,EAED,MAAO,CACL,aAAcJ,EAAQ,aACtB,UAAWC,EACX,YAAaD,EAAQ,WACvB,CACF,CE5mBO,SAASK,GAAyBC,EAA8B,CACrE,GAAI,CAKF,IAAMC,EAAWC,EAAoB,EACrCC,EAAQ,6BAA8B,2BAA2BF,EAAS,OAAO,GAAI,OAAO,EAG5F,IAAMG,EAAUC,GAAuB,EAGvC,GACED,EAAQ,YAAY,SAAW,GAC/BA,EAAQ,eAAe,SAAW,GAClCA,EAAQ,iBAAmB,EAE3B,OAAAD,EAAQ,6BAA8B,sCAAuC,OAAO,EAC7EG,EAAoB,EAI7B,IAAMC,EAAUC,GAAgBP,EAAS,OAAO,EAC1CQ,EAAiBC,GAAiBH,EAASH,CAAO,EAIxD,GAAI,CADUO,GAAgBF,CAAc,EAE1C,OAAAN,EAAQ,6BAA8B,yBAA0B,MAAM,EAC/DG,EAAoB,EAW7B,GARAH,EACE,6BACA,uBAAuBC,EAAQ,YAAY,MAAM,YAAYA,EAAQ,eAAe,MAAM,YAAYA,EAAQ,cAAc,aAC5H,MACF,EAGgBQ,GAAmB,EACvB,gBAAkBC,GAAS,YAAa,QAAQ,EAAG,CAI7D,IAAMC,EAHeC,GAAgBN,CAAc,EAGP,UAAU,OACpDO,GAAKA,EAAE,YAAc,IAAOA,EAAE,SAChC,EAEIF,EAAuB,OAAS,GAClCX,EACE,6BACA,GAAGW,EAAuB,MAAM,yCAChC,MACF,CAGJ,CAEA,OAAOR,EAAoB,CAC7B,OAASW,EAAO,CACd,OAAAd,EAAQ,6BAA8B,8BAA8Bc,CAAK,GAAI,OAAO,EAC7EX,EAAoB,CAC7B,CACF,CC/EO,SAASY,GAAmBC,EAA+B,CAChE,GAAI,CACF,OAAAC,GAAgB,EAChBC,EAAQ,uBAAwB,sBAAuB,OAAO,EACvDC,EAAoB,CAC7B,OAASC,EAAO,CACd,OAAAF,EAAQ,uBAAwB,UAAUE,CAAK,GAAI,MAAM,EAClDD,EAAoB,CAC7B,CACF,CCPA,OAAS,cAAAE,GAAY,gBAAAC,GAAc,cAAAC,OAAkB,UACrD,OAAS,QAAAC,OAAY,YAYrB,SAASC,IAA4B,CACnC,OAAOC,GAAKC,EAAc,EAAG,UAAW,SAAU,mBAAmB,CACvE,CAaA,SAASC,IAA+C,CACtD,IAAMC,EAAYJ,GAAkB,EAEpC,GAAI,CAACK,GAAWD,CAAS,EACvB,MAAO,CAAC,EAGV,GAAI,CAEF,IAAME,EADUC,GAAaH,EAAW,MAAM,EACxB,KAAK,EAAE,MAAM;AAAA,CAAI,EAAE,OAAOI,GAAQA,EAAK,KAAK,CAAC,EAE7DC,EAAqC,CAAC,EAC5C,QAAWD,KAAQF,EACjB,GAAI,CACF,IAAMI,EAAK,KAAK,MAAMF,CAAI,EAC1BC,EAAW,KAAKC,CAAE,CACpB,MAAQ,CACNC,EAAQ,mBAAoB,+BAA+BH,EAAK,MAAM,EAAG,GAAG,CAAC,GAAI,MAAM,CACzF,CAGF,OAAOC,CACT,OAASG,EAAO,CACd,OAAAD,EAAQ,mBAAoB,yBAAyBC,CAAK,GAAI,MAAM,EAC7D,CAAC,CACV,CACF,CAKA,SAASC,IAAmB,CAC1B,IAAMT,EAAYJ,GAAkB,EAEpC,GAAIK,GAAWD,CAAS,EACtB,GAAI,CACFU,GAAWV,CAAS,EACpBO,EAAQ,mBAAoB,sBAAuB,OAAO,CAC5D,OAASC,EAAO,CACdD,EAAQ,mBAAoB,0BAA0BC,CAAK,GAAI,MAAM,CACvE,CAEJ,CAUA,SAASG,GAAoBN,EAI3B,CACA,IAAMO,EAA0B,CAAC,EAC3BC,EAA6B,CAAC,EAC9BC,EAAkE,CAAC,EAGnEC,EAAe,IAAI,IACnBC,EAAgB,IAAI,IAE1B,QAAWV,KAAMD,EAAY,CAC3B,GAAIC,EAAG,OAAS,mBAAqBA,EAAG,QAAQ,SAC9C,QAAWW,KAAUX,EAAG,QAAQ,SACzBS,EAAa,IAAIE,EAAO,IAAI,IAC/BL,EAAS,KAAKK,CAAM,EACpBF,EAAa,IAAIE,EAAO,IAAI,GAKlC,GAAIX,EAAG,OAAS,oBAAsBA,EAAG,QAAQ,UAC/C,QAAWY,KAAOZ,EAAG,QAAQ,UAAW,CACtC,IAAMa,EAAM,GAAGD,EAAI,IAAI,IAAIA,EAAI,YAAY,IAAIA,EAAI,EAAE,GAChDF,EAAc,IAAIG,CAAG,IACxBN,EAAU,KAAKK,CAAG,EAClBF,EAAc,IAAIG,CAAG,EAEzB,CAGF,GAAIb,EAAG,OAAS,oBAAsBA,EAAG,QAAQ,aAE/C,QAAWc,KAAOd,EAAG,QAAQ,aAAc,CACzC,IAAMe,EAAWP,EAAa,KAAKQ,GAAKA,EAAE,aAAeF,EAAI,UAAU,EACnEC,EACFA,EAAS,SAAS,KAAK,GAAGD,EAAI,QAAQ,EAEtCN,EAAa,KAAK,CAAE,GAAGM,CAAI,CAAC,CAEhC,CAEJ,CAEA,MAAO,CAAE,SAAAR,EAAU,UAAAC,EAAW,aAAAC,CAAa,CAC7C,CASA,SAASS,GAAsBC,EAIpB,CACT,GAAM,CAAE,SAAAZ,EAAU,UAAAC,EAAW,aAAAC,CAAa,EAAIU,EAE9C,GAAIZ,EAAS,SAAW,GAAKC,EAAU,SAAW,GAAKC,EAAa,SAAW,EAC7E,MAAO,GAGT,IAAMW,EAAkB,CACtB,uBACA,GACA,mEACA,mEACA,EACF,EAEA,OAAIb,EAAS,OAAS,IACpBa,EAAM,KAAK,qBAAqB,EAChCA,EAAM,KAAK,SAAS,EACpBA,EAAM,KAAK,gCAAgC,EAC3CA,EAAM,KAAK,iBAAiB,KAAK,UAAUb,EAAU,KAAM,CAAC,EAAE,MAAM;AAAA,CAAI,EAAE,IAAI,CAACc,EAAGC,IAAMA,IAAM,EAAID,EAAI,KAAOA,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC,EAAE,EAC5HD,EAAM,KAAK,IAAI,EACfA,EAAM,KAAK,KAAK,EAChBA,EAAM,KAAK,EAAE,GAGXZ,EAAU,OAAS,IACrBY,EAAM,KAAK,sBAAsB,EACjCA,EAAM,KAAK,SAAS,EACpBA,EAAM,KAAK,iCAAiC,EAC5CA,EAAM,KAAK,kBAAkB,KAAK,UAAUZ,EAAW,KAAM,CAAC,EAAE,MAAM;AAAA,CAAI,EAAE,IAAI,CAACa,EAAGC,IAAMA,IAAM,EAAID,EAAI,KAAOA,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC,EAAE,EAC9HD,EAAM,KAAK,IAAI,EACfA,EAAM,KAAK,KAAK,EAChBA,EAAM,KAAK,EAAE,GAGXX,EAAa,OAAS,IACxBW,EAAM,KAAK,sBAAsB,EACjCA,EAAM,KAAK,SAAS,EACpBA,EAAM,KAAK,iCAAiC,EAC5CA,EAAM,KAAK,qBAAqB,KAAK,UAAUX,EAAc,KAAM,CAAC,EAAE,MAAM;AAAA,CAAI,EAAE,IAAI,CAACY,EAAGC,IAAMA,IAAM,EAAID,EAAI,KAAOA,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC,EAAE,EACpID,EAAM,KAAK,IAAI,EACfA,EAAM,KAAK,KAAK,EAChBA,EAAM,KAAK,EAAE,GAGfA,EAAM,KAAK,gBAAgBb,EAAS,MAAM,cAAcC,EAAU,MAAM,eAAeC,EAAa,MAAM,wBAAwB,EAE3HW,EAAM,KAAK;AAAA,CAAI,CACxB,CAeO,SAASG,GAAeC,EAA+B,CAE5D,IAAMxB,EAAaN,GAAqB,EAExC,GAAIM,EAAW,SAAW,EACxB,OAAAE,EAAQ,mBAAoB,6BAA8B,OAAO,EAC1DuB,EAAoB,EAG7BvB,EAAQ,mBAAoB,cAAcF,EAAW,MAAM,qBAAsB,MAAM,EAGvF,IAAMmB,EAAab,GAAoBN,CAAU,EAG3C0B,EAAgBR,GAAsBC,CAAU,EAKtD,OAFAf,GAAW,EAENsB,EAKE,CACL,SAAU,GACV,cAAAA,CACF,EAPSD,EAAoB,CAQ/B,CCrNA,OAAS,cAAAE,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UACnE,OAAS,QAAAC,GAAM,WAAAC,OAAe,YAM9B,IAAMC,EAAY,8BACZC,GAA0B,EA+ChC,SAASC,IAAqC,CAC5C,OAAOJ,GAAKK,EAAc,EAAG,UAAW,SAAU,2BAA2B,CAC/E,CAKA,SAASC,IAAmD,CAC1D,IAAMC,EAAWH,GAA2B,EAE5C,GAAI,CAACR,GAAWW,CAAQ,EACtB,OAAOC,GAA+B,EAGxC,GAAI,CACF,IAAMC,EAAUZ,GAAaU,EAAU,OAAO,EAC9C,OAAO,KAAK,MAAME,CAAO,CAC3B,MAAQ,CACN,OAAOD,GAA+B,CACxC,CACF,CAKA,SAASE,GAAwBC,EAAwC,CACvE,IAAMJ,EAAWH,GAA2B,EAE5C,GAAI,CACF,IAAMQ,EAAMX,GAAQM,CAAQ,EAC5B,OAAKX,GAAWgB,CAAG,GACjBb,GAAUa,EAAK,CAAE,UAAW,EAAK,CAAC,EAGpCd,GAAcS,EAAU,KAAK,UAAUI,EAAM,KAAM,CAAC,CAAC,EAC9C,EACT,OAASE,EAAK,CACZ,OAAAC,EAAQZ,EAAW,wCAAwCW,CAAG,GAAI,MAAM,EACjE,EACT,CACF,CAKA,SAASL,IAA0D,CACjE,IAAMO,EAA8B,CAClC,aAAc,gBAAiB,eAAgB,WAAY,iBAAkB,OAC/E,EAEMC,EAAkD,CAAC,EACnDC,EAA2D,CAAC,EAElE,QAAWC,KAAWH,EACpBC,EAAeE,CAAO,EAAI,EAC1BD,EAAsBC,CAAO,EAAI,CAAC,EAGpC,MAAO,CACL,eAAAF,EACA,sBAAAC,EACA,eAAgB,EAChB,YAAa,CAAC,EACd,WAAY,IAAI,KAAK,EAAE,YAAY,CACrC,CACF,CASA,SAASE,GAA6BR,EAAqD,CACzF,IAAMS,EAAoC,CAAC,EACrCC,EAAY,IAAI,KAAK,EAAE,YAAY,EAEzC,OAAW,CAACH,EAASI,CAAK,IAAK,OAAO,QAAQX,EAAK,cAAc,EAAG,CAClE,GAAIW,IAAU,EAAG,SAEjB,IAAMC,EAAeZ,EAAK,sBAAsBO,CAA0B,GAAK,CAAC,EAC1EM,EAAiBD,EAAa,OAAS,EACzCA,EAAa,OAAO,CAACE,EAAGC,IAAMD,EAAIC,EAAG,CAAC,EAAIH,EAAa,OACvD,EAEJH,EAAY,KAAK,CACf,QAASF,EACT,UAAWP,EAAK,eAAiB,EAAIW,EAAQX,EAAK,eAAiB,EACnE,MAAAW,EACA,eAAgBX,EAAK,eACrB,iBAAkBa,EAClB,WAAYH,CACd,CAAC,CACH,CAGA,OAAAD,EAAY,KAAK,CAACK,EAAGC,IAAMA,EAAE,UAAYD,EAAE,SAAS,EAE7CL,CACT,CAKA,SAASO,GACPhB,EACAiB,EACM,CACN,GAAI,CAACA,EAAK,iBAAkB,OAE5B,IAAMV,EAAUU,EAAK,iBACfC,EAAcD,EAAK,MAAM,aAG/BjB,EAAK,eAAeO,CAAO,GAAKP,EAAK,eAAeO,CAAO,GAAK,GAAK,EACrEP,EAAK,iBAGAA,EAAK,sBAAsBO,CAAO,IACrCP,EAAK,sBAAsBO,CAAO,EAAI,CAAC,GAEzCP,EAAK,sBAAsBO,CAAO,EAAE,KAAKW,CAAW,EAChDlB,EAAK,sBAAsBO,CAAO,EAAE,OAAS,KAC/CP,EAAK,sBAAsBO,CAAO,EAAIP,EAAK,sBAAsBO,CAAO,EAAE,MAAM,GAAG,GAIrFP,EAAK,YAAcQ,GAA6BR,CAAI,EACpDA,EAAK,WAAa,IAAI,KAAK,EAAE,YAAY,CAC3C,CASO,SAASmB,GAA0BC,EAA8B,CACtE,IAAMC,EAAYD,EAAM,YAAcE,EAAa,EAG7CL,EAAOM,EAAoBF,CAAS,EAE1C,GAAI,CAACJ,EACH,OAAAd,EAAQZ,EAAW,sCAAsC8B,CAAS,GAAI,OAAO,EACtEG,EAAoB,EAI7B,GAAIP,EAAK,QAAQ,OAASzB,GACxB,OAAAW,EAAQZ,EAAW,oBAAoB0B,EAAK,QAAQ,MAAM,0BAA2B,OAAO,EACrFO,EAAoB,EAO7B,GAHAC,GAAqBJ,CAAS,EAG1BJ,EAAK,mBAAqB,QAC5B,OAAOO,EAAoB,EAI7B,IAAMxB,EAAOL,GAAwB,EACrCqB,GAA0BhB,EAAMiB,CAAI,EACpClB,GAAwBC,CAAI,EAG5BG,EACEZ,EACA,oBAAoB0B,EAAK,gBAAgB,KAAKA,EAAK,QAAQ,MAAM,cAAcA,EAAK,MAAM,aAAe,KAAK,QAAQ,CAAC,CAAC,aACxH,MACF,EAGA,IAAMS,EAAU1B,EAAK,YAAY,CAAC,EAClC,OAAI0B,GAAWA,EAAQ,UAAY,IAAOA,EAAQ,OAAS,GACzDvB,EACEZ,EACA,+BAA+BmC,EAAQ,OAAO,MAAMA,EAAQ,UAAY,KAAK,QAAQ,CAAC,CAAC,iBACvF,MACF,EAGKF,EAAoB,CAC7B,CClQA,OAAS,cAAAG,GAAY,gBAAAC,GAAc,cAAAC,OAAkB,UACrD,OAAS,QAAAC,OAAY,YC+ErB,IAAMC,GAAgD,CAIpD,WAAY,CACV,UAAW,aACX,QAAS,CAAC,WAAY,KAAM,MAAM,EAClC,SAAU,WACV,WAAY,aACZ,YAAa,gCACf,EACA,SAAU,CACR,UAAW,WACX,QAAS,CAAC,WAAW,EACrB,SAAU,WACV,WAAY,aACZ,YAAa,6BACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,aAAa,EACvB,SAAU,WACV,WAAY,aACZ,YAAa,4BACf,EACA,QAAS,CACP,UAAW,UACX,QAAS,CAAC,OAAO,EACjB,SAAU,WACV,WAAY,aACZ,YAAa,2BACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,SAAS,EACnB,SAAU,WACV,WAAY,aACZ,YAAa,0BACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,SAAS,EACnB,SAAU,WACV,WAAY,aACZ,YAAa,2BACf,EACA,SAAU,CACR,UAAW,WACX,QAAS,CAAC,QAAQ,EAClB,SAAU,WACV,WAAY,aACZ,YAAa,6BACf,EAKA,QAAS,CACP,UAAW,UACX,QAAS,CAAC,UAAU,EACpB,SAAU,UACV,WAAY,aACZ,YAAa,8BACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,aAAa,EACvB,SAAU,UACV,WAAY,aACZ,YAAa,6BACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,EACV,SAAU,UACV,WAAY,aACZ,YAAa,6BACf,EACA,QAAS,CACP,UAAW,UACX,QAAS,CAAC,YAAa,YAAY,EACnC,SAAU,UACV,WAAY,aACZ,YAAa,8BACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,UAAW,MAAM,EAC3B,SAAU,UACV,WAAY,aACZ,YAAa,yBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,SAAU,SAAS,EAC7B,SAAU,UACV,WAAY,aACZ,YAAa,0BACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,cAAe,YAAY,EACrC,SAAU,UACV,WAAY,aACZ,YAAa,uBACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,gBAAiB,KAAK,EAChC,SAAU,UACV,WAAY,aACZ,YAAa,yBACf,EAKA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,UAAW,UAAU,EAC/B,SAAU,WACV,WAAY,aACZ,YAAa,kBACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,QAAS,QAAQ,EAC3B,SAAU,WACV,WAAY,aACZ,YAAa,kBACf,EACA,QAAS,CACP,UAAW,UACX,QAAS,CAAC,WAAW,EACrB,SAAU,WACV,WAAY,aACZ,YAAa,mBACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,WAAW,EACrB,SAAU,WACV,WAAY,aACZ,YAAa,kBACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,UAAW,UAAU,EAC/B,SAAU,WACV,WAAY,aACZ,YAAa,mBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,aACZ,YAAa,gBACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,aACZ,YAAa,2BACf,EAKA,WAAY,CACV,UAAW,aACX,QAAS,CAAC,IAAI,EACd,SAAU,WACV,WAAY,aACZ,YAAa,qBACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,KAAM,SAAS,EACzB,SAAU,WACV,WAAY,aACZ,YAAa,iBACf,EACA,WAAY,CACV,UAAW,aACX,QAAS,CAAC,KAAM,YAAY,EAC5B,SAAU,WACV,WAAY,aACZ,YAAa,qBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,UAAU,EACpB,SAAU,WACV,WAAY,aACZ,YAAa,eACf,EACA,GAAI,CACF,UAAW,KACX,QAAS,CAAC,QAAQ,EAClB,SAAU,WACV,WAAY,aACZ,YAAa,aACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,KAAK,EACf,SAAU,WACV,WAAY,aACZ,YAAa,eACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,IAAI,EACd,SAAU,WACV,WAAY,aACZ,YAAa,iBACf,EAKA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,gBAAgB,EAC1B,SAAU,OACV,WAAY,aACZ,YAAa,iBACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,QAAS,MAAM,EACzB,SAAU,OACV,WAAY,aACZ,YAAa,oBACf,EACA,SAAU,CACR,UAAW,WACX,QAAS,CAAC,WAAY,OAAO,EAC7B,SAAU,OACV,WAAY,aACZ,YAAa,yBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,OAAO,EACjB,SAAU,OACV,WAAY,aACZ,YAAa,qBACf,EAKA,UAAW,CACT,UAAW,YACX,QAAS,CAAC,YAAY,EACtB,SAAU,QACV,WAAY,aACZ,YAAa,yBACf,EACA,UAAW,CACT,UAAW,YACX,QAAS,CAAC,YAAY,EACtB,SAAU,QACV,WAAY,aACZ,YAAa,2BACf,EACA,SAAU,CACR,UAAW,WACX,QAAS,CAAC,WAAW,EACrB,SAAU,QACV,WAAY,aACZ,YAAa,4BACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,MAAO,SAAS,EAC1B,SAAU,QACV,WAAY,aACZ,YAAa,mBACf,EACA,UAAW,CACT,UAAW,YACX,QAAS,CAAC,QAAQ,EAClB,SAAU,QACV,WAAY,aACZ,YAAa,yBACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,SAAU,QAAQ,EAC5B,SAAU,QACV,WAAY,aACZ,YAAa,mBACf,EAKA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,WAAW,EACrB,SAAU,iBACV,WAAY,aACZ,YAAa,yBACf,EACA,WAAY,CACV,UAAW,aACX,QAAS,CAAC,MAAO,MAAM,EACvB,SAAU,iBACV,WAAY,aACZ,YAAa,0BACf,EACA,UAAW,CACT,UAAW,YACX,QAAS,CAAC,IAAI,EACd,SAAU,iBACV,WAAY,aACZ,YAAa,eACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,qBAAqB,EAC/B,SAAU,iBACV,WAAY,aACZ,YAAa,qBACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,eAAgB,uBAAuB,EACjD,SAAU,iBACV,WAAY,aACZ,YAAa,uBACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,iBAAiB,EAC3B,SAAU,iBACV,WAAY,aACZ,YAAa,iBACf,EAKA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,SAAS,EACnB,SAAU,UACV,WAAY,aACZ,YAAa,0BACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,UACV,WAAY,aACZ,YAAa,8BACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,WAAW,EACrB,SAAU,UACV,WAAY,aACZ,YAAa,4BACf,EACA,WAAY,CACV,UAAW,aACX,QAAS,CAAC,EACV,SAAU,UACV,WAAY,aACZ,YAAa,wBACf,EACA,QAAS,CACP,UAAW,UACX,QAAS,CAAC,EACV,SAAU,UACV,WAAY,aACZ,YAAa,qBACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,qBAAqB,EAC/B,SAAU,UACV,WAAY,aACZ,YAAa,qBACf,EAKA,QAAS,CACP,UAAW,UACX,QAAS,CAAC,EACV,SAAU,aACV,WAAY,aACZ,YAAa,iBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,QAAQ,EAClB,SAAU,aACV,WAAY,aACZ,YAAa,iBACf,EACA,QAAS,CACP,UAAW,UACX,QAAS,CAAC,EACV,SAAU,aACV,WAAY,aACZ,YAAa,iBACf,EACA,UAAW,CACT,UAAW,YACX,QAAS,CAAC,EACV,SAAU,aACV,WAAY,aACZ,YAAa,mBACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,OAAO,EACjB,SAAU,aACV,WAAY,aACZ,YAAa,aACf,CACF,EAMMC,GAAyC,CAC7C,oBAAqB,CACnB,UAAW,oBACX,SAAU,CAAC,oBAAqB,mBAAmB,EACnD,SAAU,qBACV,WAAY,UACZ,YAAa,iCACf,EACA,oBAAqB,CACnB,UAAW,oBACX,SAAU,CAAC,oBAAqB,mBAAmB,EACnD,SAAU,qBACV,WAAY,UACZ,YAAa,iCACf,EACA,oBAAqB,CACnB,UAAW,oBACX,SAAU,CAAC,oBAAqB,mBAAmB,EACnD,SAAU,qBACV,WAAY,UACZ,YAAa,iCACf,EACA,qBAAsB,CACpB,UAAW,qBACX,SAAU,CAAC,qBAAsB,oBAAoB,EACrD,SAAU,uBACV,WAAY,UACZ,YAAa,2BACf,EACA,gBAAiB,CACf,UAAW,gBACX,SAAU,CAAC,gBAAiB,eAAe,EAC3C,SAAU,uBACV,WAAY,UACZ,YAAa,uBACf,EACA,qBAAsB,CACpB,UAAW,qBACX,SAAU,CAAC,qBAAsB,oBAAoB,EACrD,SAAU,uBACV,WAAY,UACZ,YAAa,4BACf,EACA,uBAAwB,CACtB,UAAW,uBACX,SAAU,CAAC,uBAAwB,KAAM,sBAAsB,EAC/D,SAAU,uBACV,WAAY,UACZ,YAAa,8BACf,EACA,iBAAkB,CAChB,UAAW,iBACX,SAAU,CAAC,iBAAkB,gBAAgB,EAC7C,SAAU,uBACV,WAAY,UACZ,YAAa,wBACf,EACA,KAAQ,CACN,UAAW,OACX,SAAU,CAAC,0CAA0C,EACrD,SAAU,uBACV,WAAY,UACZ,YAAa,cACf,EACA,eAAgB,CACd,UAAW,eACX,SAAU,CAAC,eAAgB,eAAgB,MAAM,EACjD,SAAU,mBACV,WAAY,UACZ,YAAa,2CACf,EACA,kBAAmB,CACjB,UAAW,kBACX,SAAU,CAAC,kBAAmB,iBAAiB,EAC/C,SAAU,uBACV,WAAY,UACZ,YAAa,yBACf,EACA,gBAAiB,CACf,UAAW,gBACX,SAAU,CAAC,gBAAiB,gBAAiB,YAAY,EACzD,SAAU,cACV,WAAY,UACZ,YAAa,uBACf,EACA,gBAAiB,CACf,UAAW,gBACX,SAAU,CAAC,gBAAiB,gBAAiB,OAAO,EACpD,SAAU,uBACV,WAAY,UACZ,YAAa,eACf,EACA,cAAe,CACb,UAAW,cACX,SAAU,CAAC,cAAe,cAAe,cAAc,EACvD,SAAU,kBACV,WAAY,UACZ,YAAa,qBACf,EACA,gBAAiB,CACf,UAAW,gBACX,SAAU,CAAC,gBAAiB,eAAe,EAC3C,SAAU,kBACV,WAAY,UACZ,YAAa,6BACf,EACA,eAAgB,CACd,UAAW,eACX,SAAU,CAAC,eAAgB,cAAc,EACzC,SAAU,kBACV,WAAY,UACZ,YAAa,4BACf,EACA,IAAO,CACL,UAAW,MACX,SAAU,CAAC,gCAAgC,EAC3C,SAAU,mBACV,WAAY,UACZ,YAAa,gCACf,EACA,kBAAmB,CACjB,UAAW,kBACX,SAAU,CAAC,kBAAmB,iBAAiB,EAC/C,SAAU,mBACV,WAAY,UACZ,YAAa,yBACf,EACA,gBAAiB,CACf,UAAW,gBACX,SAAU,CAAC,gBAAiB,eAAe,EAC3C,SAAU,mBACV,WAAY,UACZ,YAAa,uBACf,EACA,IAAO,CACL,UAAW,MACX,SAAU,CAAC,yBAAyB,EACpC,SAAU,mBACV,WAAY,UACZ,YAAa,yBACf,EACA,IAAO,CACL,UAAW,MACX,SAAU,CAAC,6BAA6B,EACxC,SAAU,mBACV,WAAY,UACZ,YAAa,6BACf,EACA,IAAO,CACL,UAAW,MACX,SAAU,CAAC,sBAAsB,EACjC,SAAU,uBACV,WAAY,UACZ,YAAa,sBACf,EACA,cAAiB,CACf,UAAW,gBACX,SAAU,CAAC,iBAAkB,gBAAgB,EAC7C,SAAU,uBACV,WAAY,UACZ,YAAa,4BACf,EACA,SAAY,CACV,UAAW,WACX,SAAU,CAAC,YAAY,EACvB,SAAU,uBACV,WAAY,UACZ,YAAa,yBACf,EACA,WAAc,CACZ,UAAW,aACX,SAAU,CAAC,OAAQ,uBAAuB,EAC1C,SAAU,qBACV,WAAY,UACZ,YAAa,yBACf,EACA,KAAQ,CACN,UAAW,OACX,SAAU,CAAC,UAAW,UAAU,EAChC,SAAU,cACV,WAAY,UACZ,YAAa,kBACf,EACA,QAAW,CACT,UAAW,UACX,SAAU,CAAC,UAAU,EACrB,SAAU,cACV,WAAY,UACZ,YAAa,qBACf,EACA,KAAQ,CACN,UAAW,OACX,SAAU,CAAC,OAAO,EAClB,SAAU,cACV,WAAY,UACZ,YAAa,eACf,EACA,UAAa,CACX,UAAW,YACX,SAAU,CAAC,aAAc,YAAY,EACrC,SAAU,cACV,WAAY,UACZ,YAAa,oBACf,EACA,IAAO,CACL,UAAW,MACX,SAAU,CAAC,oBAAoB,EAC/B,SAAU,cACV,WAAY,UACZ,YAAa,oBACf,CACF,EAMMC,GAAmC,CACvC,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,UAAW,IAAI,EACzB,SAAU,WACV,WAAY,OACZ,YAAa,qBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,OACZ,YAAa,yBACf,EACA,MAAO,CACL,UAAW,QACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,OACZ,YAAa,yBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,OACZ,YAAa,yBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,OACZ,YAAa,yBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,QAAS,IAAI,EACvB,SAAU,WACV,WAAY,OACZ,YAAa,YACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,OACZ,YAAa,6BACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,SAAS,EACnB,SAAU,WACV,WAAY,OACZ,YAAa,wBACf,EACA,GAAI,CACF,UAAW,KACX,QAAS,CAAC,YAAY,EACtB,SAAU,WACV,WAAY,OACZ,YAAa,0BACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,sBAAsB,EAChC,SAAU,kBACV,WAAY,OACZ,YAAa,yBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,kBACV,WAAY,OACZ,YAAa,sBACf,EACA,KAAM,CACJ,UAAW,OACX,QAAS,CAAC,EACV,SAAU,kBACV,WAAY,OACZ,YAAa,sBACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,cAAe,YAAY,EACrC,SAAU,WACV,WAAY,OACZ,YAAa,iBACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,EACV,SAAU,WACV,WAAY,OACZ,YAAa,oBACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,UAAW,oBAAoB,EACzC,SAAU,WACV,WAAY,OACZ,YAAa,2BACf,EACA,IAAK,CACH,UAAW,MACX,QAAS,CAAC,IAAI,EACd,SAAU,WACV,WAAY,OACZ,YAAa,sBACf,EACA,OAAQ,CACN,UAAW,SACX,QAAS,CAAC,OAAQ,SAAS,EAC3B,SAAU,WACV,WAAY,OACZ,YAAa,iBACf,CACF,EASA,SAASC,GACPC,EACqB,CACrB,IAAMC,EAAM,IAAI,IAEhB,QAAWC,KAAS,OAAO,OAAOF,CAAQ,EAAG,CAE3CC,EAAI,IAAIC,EAAM,UAAU,YAAY,EAAGA,EAAM,SAAS,EAGtD,QAAWC,KAASD,EAAM,QACxBD,EAAI,IAAIE,EAAM,YAAY,EAAGD,EAAM,SAAS,CAEhD,CAEA,OAAOD,CACT,CAKA,SAASG,GACPJ,EACqB,CACrB,IAAMC,EAAM,IAAI,IAEhB,QAAWC,KAAS,OAAO,OAAOF,CAAQ,EAAG,CAE3CC,EAAI,IAAIC,EAAM,UAAU,YAAY,EAAGA,EAAM,SAAS,EAGtD,QAAWG,KAAWH,EAAM,SAC1BD,EAAI,IAAII,EAAQ,YAAY,EAAGH,EAAM,SAAS,CAElD,CAEA,OAAOD,CACT,CAGA,IAAMK,GAAiBP,GAAcH,EAAY,EAC3CW,GAAiBR,GAAcD,EAAK,EACpCU,GAAsBJ,GAAuBP,EAAQ,ECxfpD,SAASY,IAA4B,CAC1C,MAAO,CAAC,CAAC,QAAQ,IAAI,YACvB,CFpWA,SAASC,IAA2B,CAClC,OAAOC,GAAKC,EAAc,EAAG,UAAW,SAAU,kBAAkB,CACtE,CASA,SAASC,IAAyC,CAChD,IAAMC,EAAYJ,GAAiB,EAEnC,GAAI,CAACK,GAAWD,CAAS,EACvB,MAAO,CAAC,EAGV,GAAI,CAEF,IAAME,EADUC,GAAaH,EAAW,MAAM,EACxB,KAAK,EAAE,MAAM;AAAA,CAAI,EAAE,OAAOI,GAAQA,EAAK,KAAK,CAAC,EAE7DC,EAA+B,CAAC,EACtC,QAAWD,KAAQF,EACjB,GAAI,CACF,IAAMI,EAAS,KAAK,MAAMF,CAAI,EAE1BE,EAAO,MAAQA,EAAO,QACxBD,EAAS,KAAKC,CAAM,EAEpBC,EAAQ,kBAAmB,oDAAqD,MAAM,CAE1F,MAAQ,CACNA,EAAQ,kBAAmB,+BAA+BH,EAAK,MAAM,EAAG,GAAG,CAAC,GAAI,MAAM,CACxF,CAGF,OAAOC,CACT,OAASG,EAAO,CACd,OAAAD,EAAQ,kBAAmB,yBAAyBC,CAAK,GAAI,MAAM,EAC5D,CAAC,CACV,CACF,CAKA,SAASC,IAAmB,CAC1B,IAAMT,EAAYJ,GAAiB,EAEnC,GAAIK,GAAWD,CAAS,EACtB,GAAI,CACFU,GAAWV,CAAS,EACpBO,EAAQ,kBAAmB,qBAAsB,OAAO,CAC1D,OAASC,EAAO,CACdD,EAAQ,kBAAmB,0BAA0BC,CAAK,GAAI,MAAM,CACtE,CAEJ,CASA,SAASG,GAAcN,EAA+D,CACpF,IAAMO,EAAS,IAAI,IAEnB,QAAWN,KAAUD,EAAU,CAC7B,IAAMQ,EAAWD,EAAO,IAAIN,EAAO,OAAO,GAAK,CAAC,EAChDO,EAAS,KAAKP,CAAM,EACpBM,EAAO,IAAIN,EAAO,QAASO,CAAQ,CACrC,CAEA,OAAOD,CACT,CAKA,SAASE,GAAoBT,EAAkD,CAC7E,IAAMU,EAAO,IAAI,IAEjB,QAAWT,KAAUD,EAAU,CAE7B,IAAMW,EAAMV,EAAO,KAAK,KAAK,EAAE,YAAY,EACrCO,EAAWE,EAAK,IAAIC,CAAG,GAGzB,CAACH,GAAYP,EAAO,UAAYO,EAAS,YAC3CE,EAAK,IAAIC,EAAKV,CAAM,CAExB,CAEA,OAAO,MAAM,KAAKS,EAAK,OAAO,CAAC,CACjC,CASA,SAASE,GAAsBZ,EAAsC,CACnE,GAAIA,EAAS,SAAW,EACtB,MAAO,GAIT,IAAMa,EAAUP,GAAcN,CAAQ,EAEhCc,EAAkB,CACtB,4BACA,GACA,mEACA,iEACA,EACF,EAGIC,EAAY,EAChB,OAAW,CAACC,EAAQC,CAAY,IAAKJ,EAAS,CAC5CC,EAAM,KAAK,cAAcE,CAAM,EAAE,EACjCF,EAAM,KAAK,EAAE,EAEb,QAAWb,KAAUgB,EACnBH,EAAM,KAAK,YAAYC,CAAS,KAAK,EACrCD,EAAM,KAAK,SAAS,EACpBA,EAAM,KAAK,yBAAyB,EACpCA,EAAM,KAAK,aAAa,KAAK,UAAUb,EAAO,IAAI,CAAC,GAAG,EACtDa,EAAM,KAAK,gBAAgB,KAAK,UAAUb,EAAO,OAAO,CAAC,GAAG,EAC5Da,EAAM,KAAK,iBAAiB,KAAK,UAAUb,EAAO,SAAU,KAAM,CAAC,EAAE,MAAM;AAAA,CAAI,EAAE,IAAI,CAAC,EAAGiB,IAAMA,IAAM,EAAI,EAAI,KAAO,CAAC,EAAE,KAAK;AAAA,CAAI,CAAC,EAAE,EACnIJ,EAAM,KAAK,IAAI,EACfA,EAAM,KAAK,KAAK,EAChBA,EAAM,KAAK,EAAE,EACbC,GAEJ,CAGA,IAAMI,EAAa,IAAI,IAAInB,EAAS,IAAIoB,GAAKA,EAAE,SAAS,QAAQ,EAAE,OAAO,OAAO,CAAC,EACjF,OAAAN,EAAM,KAAK,gBAAgBd,EAAS,MAAM,4BAA4Ba,EAAQ,IAAI,YAAY,EAC1FM,EAAW,KAAO,GACpBL,EAAM,KAAK,eAAe,MAAM,KAAKK,CAAU,EAAE,KAAK,IAAI,CAAC,EAAE,EAGxDL,EAAM,KAAK;AAAA,CAAI,CACxB,CAgBO,SAASO,GAAcC,EAA+B,CAE3D,GAAI,CAACC,GAAiB,EACpB,OAAArB,EAAQ,kBAAmB,wCAAyC,OAAO,EACpEsB,EAAoB,EAI7B,IAAMC,EAAc/B,GAAmB,EAEvC,GAAI+B,EAAY,SAAW,EACzB,OAAAvB,EAAQ,kBAAmB,0BAA2B,OAAO,EACtDsB,EAAoB,EAG7BtB,EAAQ,kBAAmB,cAAcuB,EAAY,MAAM,mBAAoB,MAAM,EAGrF,IAAMzB,EAAWS,GAAoBgB,CAAW,EAC5CzB,EAAS,OAASyB,EAAY,QAChCvB,EACE,kBACA,gBAAgBuB,EAAY,MAAM,WAAMzB,EAAS,MAAM,YACvD,OACF,EAIF,IAAM0B,EAAgBd,GAAsBZ,CAAQ,EAKpD,OAFAI,GAAW,EAENsB,EAKE,CACL,SAAU,GACV,cAAAA,CACF,EAPSF,EAAoB,CAQ/B,CGlOA,IAAMG,GAAsB,CAC1B,CAAE,KAAM,oBAAqB,GAAIC,CAAgB,EACjD,CAAE,KAAM,mBAAoB,GAAIC,CAAgB,EAChD,CAAE,KAAM,qBAAsB,GAAIC,CAAiB,EACnD,CAAE,KAAM,sBAAuB,GAAIC,CAAmB,EACtD,CAAE,KAAM,6BAA8B,GAAIC,EAAyB,EACnE,CAAE,KAAM,uBAAwB,GAAIC,EAAmB,EAEvD,CAAE,KAAM,mBAAoB,GAAIC,EAAe,EAE/C,CAAE,KAAM,8BAA+B,GAAIC,EAA0B,EAErE,CAAE,KAAM,kBAAmB,GAAIC,EAAc,CAC/C,EAYA,eAAsBC,GAAsBC,EAAuC,CAmBjF,IAAMC,GAjBU,MAAM,QAAQ,WAC5BC,GAAM,IAAI,MAAMC,GAAQ,CACtB,GAAI,CACF,IAAMC,EAASD,EAAK,GAAGH,CAAK,EAC5B,OAAII,aAAkB,SACpB,MAAMA,EAED,CAAE,KAAMD,EAAK,KAAM,OAAQ,SAAU,CAC9C,OAASE,EAAO,CACd,IAAMC,EAAUD,aAAiB,MAAQA,EAAM,QAAU,OAAOA,CAAK,EACrE,OAAAE,EAAQ,kBAAmB,GAAGJ,EAAK,IAAI,YAAYG,CAAO,EAAE,EACrD,CAAE,KAAMH,EAAK,KAAM,OAAQ,QAAS,QAAAG,CAAQ,CACrD,CACF,CAAC,CACH,GAGuB,OACrB,GAAK,EAAE,SAAW,YAAe,EAAE,SAAW,aAAe,EAAE,MAAM,SAAW,OAClF,EAEA,OAAIL,EAAO,OAAS,GAClBM,EAAQ,kBAAmB,GAAGN,EAAO,MAAM,IAAIC,GAAM,MAAM,mBAAmB,EAGzEM,EAAoB,CAC7B,CC3DO,IAAMC,GAAgC,CAC3C,gCAAiCC,GACjC,yBAA0BC,EAC1B,wBAAyBC,GACzB,0BAA2BC,GAC3B,uBAAwBC,GACxB,0BAA2BC,EAC3B,gCAAiCC,GACjC,8BAA+BC,GAC/B,gCAAiCC,GACjC,wBAAyBC,EACzB,6BAA8BC,GAC9B,2BAA4BC,EAC5B,0BAA2BC,GAE3B,mCAAoCC,GACpC,wBAAyBC,GACzB,4BAA6BC,EAC/B,EAEO,SAASC,GAAQC,EAAkC,CACxD,OAAOlB,GAAMkB,CAAI,CACnB,CAEO,SAASC,IAAsB,CACpC,OAAO,OAAO,KAAKnB,EAAK,CAC1B",
  "names": ["isBashInput", "input", "isWriteInput", "isEditInput", "isReadInput", "appendFileSync", "existsSync", "statSync", "renameSync", "mkdirSync", "readSync", "execSync", "getLogDir", "getProjectDir", "getPluginRoot", "getSessionId", "getCachedBranch", "projectDir", "branch", "getLogLevel", "shouldLog", "level", "levels", "outputSilentSuccess", "outputSilentAllow", "outputBlock", "reason", "outputWithContext", "ctx", "outputPromptContext", "outputAllowWithContext", "systemMessage", "result", "outputError", "message", "outputWarning", "outputDeny", "LOG_ROTATION_MAX_SIZE", "PERMISSION_LOG_MAX_SIZE", "rotateLogFile", "logFile", "maxSize", "rotated", "ensureDir", "dir", "logHook", "hookName", "logDir", "timestamp", "logPermissionFeedback", "decision", "input", "toolName", "sessionId", "estimateTokenCount", "content", "charsPerToken", "outputPromptContextBudgeted", "category", "budgetChecker", "tokenTracker", "tokens", "readHookInput", "chunks", "buf", "bytesRead", "fd", "getField", "path", "parts", "value", "part", "normalizeCommand", "command", "escapeRegex", "str", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "createHash", "MAX_RECORDS", "MIN_SAMPLES_FOR_ADJUSTMENT", "MAX_ADJUSTMENT", "ADJUSTMENT_STEP", "DECAY_FACTOR", "getCalibrationFile", "getProjectDir", "ensureDir", "dir", "existsSync", "mkdirSync", "loadCalibrationData", "file", "readFileSync", "logHook", "saveCalibrationData", "data", "writeFileSync", "err", "hashPrompt", "prompt", "createHash", "recordOutcome", "agent", "matchedKeywords", "confidence", "outcome", "durationMs", "feedback", "record", "getSessionId", "updateAdjustments", "updateStats", "isPositive", "isNegative", "adjustmentDelta", "keyword", "existing", "a", "applyDecay", "now", "dayMs", "adj", "age", "records", "successful", "r", "avgConf", "sum", "agentStats", "stat", "b", "getAdjustments", "getAgentSuccessRate", "agentRecords", "getCalibrationStats", "hasMinimalCalibrationData", "autoRememberContinuity", "input", "logHook", "projectId", "getProjectDir", "mem0Hint", "promptMsg", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "autoSaveContext", "input", "logHook", "sessionDir", "getProjectDir", "sessionState", "existsSync", "mkdirSync", "timestamp", "content", "readFileSync", "state", "updated", "writeFileSync", "error", "outputSilentSuccess", "existsSync", "readFileSync", "execSync", "getInstanceId", "projectDir", "idFile", "existsSync", "readFileSync", "runSqlite", "dbPath", "sql", "execSync", "cleanupInstance", "input", "getProjectDir", "logHook", "outputSilentSuccess", "instanceId", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "MAX_ACTIVE_DECISIONS", "archiveSession", "contextDir", "sessionFile", "existsSync", "logHook", "content", "readFileSync", "session", "sessionId", "archiveDir", "mkdirSync", "archiveFile", "archived", "writeFileSync", "error", "compressOldDecisions", "decisionsFile", "data", "decisions", "now", "toArchive", "writeCompactionManifest", "manifest", "manifestDir", "contextCompressor", "input", "getProjectDir", "outputSilentSuccess", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "execSync", "shouldRunTests", "projectDir", "lastRunFile", "existsSync", "result", "execSync", "logHook", "runTests", "logFile", "exitCode", "readFileSync", "cmd", "fullTestSuite", "input", "getProjectDir", "logDir", "mkdirSync", "outputSilentSuccess", "writeFileSync", "existsSync", "readFileSync", "unlinkSync", "rmdirSync", "execSync", "isGhAvailable", "execSync", "isGitHubRepo", "projectDir", "generateComment", "issueNum", "data", "sessionId", "commits", "commitsSection", "c", "tasksSection", "t", "postComment", "comment", "issueWorkSummary", "input", "logHook", "getProjectDir", "getSessionId", "sessionDir", "progressFile", "existsSync", "outputSilentSuccess", "progressJson", "readFileSync", "issues", "postedCount", "issueData", "unlinkSync", "rmdirSync", "existsSync", "readFileSync", "mkdirSync", "appendFileSync", "writeFileSync", "spawn", "countPendingDecisions", "decisionLog", "syncState", "existsSync", "decisionList", "readFileSync", "syncedIds", "d", "countPendingPatterns", "patternsLog", "content", "patterns", "line", "pending", "p", "getProjectId", "projectDir", "extractSessionInfo", "currentTask", "blockers", "nextSteps", "sessionState", "state", "blockersLog", "b", "mem0PreCompactionSync", "input", "logHook", "outputSilentSuccess", "getProjectDir", "pluginRoot", "getPluginRoot", "decisionCount", "patternCount", "pendingPatterns", "projectId", "logFile", "mkdirSync", "msgParts", "agentSet", "uniqueAgents", "summary", "summaryText", "sessionText", "scriptPath", "mem0ApiKey", "skillMsg", "timestamp", "appendFileSync", "sessionMetadata", "child", "spawn", "err", "errTimestamp", "code", "closeTimestamp", "stderrData", "chunk", "updated", "obj", "writeFileSync", "existsSync", "readFileSync", "unlinkSync", "execSync", "runSqlite", "dbPath", "sql", "execSync", "hasTable", "tableName", "stopHeartbeat", "instanceDir", "pidFile", "existsSync", "pid", "readFileSync", "logHook", "unlinkSync", "releaseLocks", "instanceId", "handleWorkClaims", "updateInstanceStatus", "broadcastShutdown", "messageId", "timestamp", "payload", "cleanupInstanceFiles", "filesToRemove", "file", "filePath", "multiInstanceCleanup", "input", "projectDir", "getProjectDir", "outputSilentSuccess", "idFile", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "readdirSync", "execSync", "runNpmAudit", "projectDir", "resultsDir", "existsSync", "logHook", "execSync", "error", "writeFileSync", "result", "runPipAudit", "parsed", "runSemgrep", "highSeverity", "r", "runBandit", "runSecretScan", "secretPatterns", "secretsFound", "findings", "extensions", "scanDir", "dir", "entries", "readdirSync", "entry", "fullPath", "ext", "content", "readFileSync", "aggregateResults", "results", "totalCritical", "totalHigh", "scansCompleted", "f", "report", "securityScanAggregator", "input", "getProjectDir", "mkdirSync", "outputSilentSuccess", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "existsSync", "appendFileSync", "mkdirSync", "readFileSync", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "execSync", "createHash", "os", "IDENTITY_CONFIG_FILE", "SALT", "DEFAULT_PRIVACY", "cachedIdentity", "cachedPrivacy", "generateAnonymousId", "input", "createHash", "SALT", "getMachineId", "readUserConfig", "projectDir", "configPath", "IDENTITY_CONFIG_FILE", "existsSync", "content", "readFileSync", "error", "logHook", "getGitIdentity", "result", "execSync", "getEnvIdentity", "resolveUserIdentity", "cachedIdentity", "dir", "getProjectDir", "machineId", "config", "git", "env", "userId", "anonId", "getPrivacySettings", "cachedPrivacy", "DEFAULT_PRIVACY", "canShare", "dataType", "scope", "privacy", "getIdentityContext", "identity", "resolveUserIdentity", "getSessionId", "SESSION_ID_PATTERN", "isValidSessionId", "sessionId", "getSessionDir", "projectDir", "sid", "getSessionId", "pDir", "getProjectDir", "getEventsPath", "ensureSessionDir", "dir", "existsSync", "mkdirSync", "eventCounter", "generateEventId", "trackEvent", "eventType", "name", "options", "event", "getIdentityContext", "sanitizeForStorage", "truncate", "eventsPath", "appendFileSync", "logHook", "error", "trackSessionEnd", "trackEvent", "loadSessionEvents", "sessionId", "eventsPath", "getEventsPath", "existsSync", "readFileSync", "line", "error", "logHook", "generateSessionSummary", "events", "identity", "getIdentityContext", "eventCounts", "skillsUsed", "agentsSpawned", "hooksTriggered", "startTime", "endTime", "event", "durationMs", "truncate", "str", "maxLen", "sanitizeForStorage", "obj", "sanitized", "sensitiveKeys", "key", "value", "s", "TOOL_CATEGORIES", "getToolCategory", "toolName", "extractToolSequence", "metricsFile", "existsSync", "tools", "readFileSync", "a", "b", "tool", "getToolCount", "sum", "count", "detectWorkflowType", "detectDominantLanguage", "initWorkflowProfile", "profilePath", "updateWorkflowProfile", "workflowType", "dominantLang", "toolCount", "toolSequence", "profile", "timestamp", "seqSet", "mkdirSync", "writeFileSync", "initPatternsFile", "patternsPath", "aggregateToolPreferences", "usageByCategory", "toolEvents", "loadSessionEvents", "e", "event", "toolName", "category", "getToolCategory", "preferences", "sorted", "updateToolPreferences", "projectDir", "logHook", "prefsPath", "existingPrefs", "prefCount", "mergePatterns", "queuePath", "queue", "queueCount", "existing", "now", "allPatterns", "patternMap", "p", "mergedPatterns", "successes", "failures", "categories", "updated", "sessionPatterns", "input", "getProjectDir", "workflowProfile", "outputSilentSuccess", "existsSync", "readFileSync", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "getRegistryFile", "sessionId", "getSessionId", "getProjectDir", "ensureDir", "dir", "existsSync", "mkdirSync", "loadRegistry", "file", "readFileSync", "saveRegistry", "registry", "writeFileSync", "err", "logHook", "formatTaskDeleteForClaude", "taskId", "reason", "getOrphanedTasks", "registry", "loadRegistry", "failedIds", "t", "id", "cleanupOldTasks", "maxAgeMs", "registry", "loadRegistry", "cutoff", "t", "p", "saveRegistry", "taskCompletionCheck", "input", "logHook", "warnings", "projectDir", "getProjectDir", "sessionId", "getSessionId", "registryFile", "existsSync", "inProgress", "readFileSync", "t", "error", "orphans", "getOrphanedTasks", "orphanInstructions", "orphan", "formatTaskDeleteForClaude", "todosFile", "context", "w", "outputWithContext", "outputSilentSuccess", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "getStateDir", "getProjectDir", "getStateFile", "sessionId", "getSessionId", "getConfigFile", "DEFAULT_CONFIG_VALUES", "loadConfig", "configFile", "getConfigFile", "existsSync", "data", "readFileSync", "clearSessionState", "stateFile", "getStateFile", "existsSync", "unlinkSync", "logHook", "cleanupOldStates", "dir", "getStateDir", "readdirSync", "statSync", "files", "f", "a", "b", "file", "MAX_RECORD_AGE_MS", "cleanupOldRecords", "data", "cutoff", "before", "r", "after", "logHook", "generateSummary", "stats", "topAgents", "a", "calibrationPersist", "_input", "loadConfig", "clearSessionState", "cleanupOldStates", "outputSilentSuccess", "loadCalibrationData", "applyDecay", "saveCalibrationData", "summary", "err", "cleanupOldTasks", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "join", "dirname", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "appendFileSync", "join", "dirname", "getFlowFilePath", "sessionId", "join", "getProjectDir", "getCompletedFlowsPath", "loadDecisionFlow", "filePath", "existsSync", "content", "readFileSync", "err", "logHook", "archiveFlow", "flow", "archivePath", "getCompletedFlowsPath", "dir", "dirname", "existsSync", "mkdirSync", "line", "appendFileSync", "err", "logHook", "inferWorkflowPattern", "actions", "counts", "action", "testIndices", "a", "i", "writeIndices", "findConsecutiveRun", "countAlternations", "lastTest", "category", "maxRun", "currentRun", "categoryA", "categoriesB", "alternations", "lastWasA", "isA", "isB", "calculateStats", "successes", "analyzeDecisionFlow", "sessionId", "flow", "loadDecisionFlow", "inferWorkflowPattern", "calculateStats", "completeDecisionFlow", "archived", "archiveFlow", "logHook", "WORKFLOW_PATTERN_DESCRIPTIONS", "convertFlowPattern", "flowPattern", "existingPatterns", "existing", "p", "frequency", "PROFILE_VERSION", "getHomeDir", "getOrchestKitDir", "join", "getUserProfileDir", "userId", "sanitizedUserId", "getUserProfilePath", "getLegacyProfilePath", "getProjectDir", "migrateProfileIfNeeded", "legacyPath", "newPath", "existsSync", "newDir", "dirname", "mkdirSync", "content", "readFileSync", "profile", "writeFileSync", "logHook", "error", "createEmptyProfile", "identity", "resolveUserIdentity", "now", "PROFILE_VERSION", "loadUserProfile", "uid", "profilePath", "saveUserProfile", "profileDir", "updateUsageStats", "existing", "success", "durationMs", "newCount", "newSuccessRate", "newAvgDuration", "aggregateSession", "summary", "skill", "agent", "flow", "analyzeDecisionFlow", "patternName", "existingIndex", "p", "newPattern", "convertFlowPattern", "MAX_AGGREGATED_SESSIONS", "exportForGlobal", "profile", "anonDecisions", "d", "project", "rest", "sessionProfileAggregator", "input", "identity", "resolveUserIdentity", "logHook", "summary", "generateSessionSummary", "outputSilentSuccess", "profile", "loadUserProfile", "updatedProfile", "aggregateSession", "saveUserProfile", "getPrivacySettings", "canShare", "generalizableDecisions", "exportForGlobal", "d", "error", "sessionEndTracking", "_input", "trackSessionEnd", "logHook", "outputSilentSuccess", "error", "existsSync", "readFileSync", "unlinkSync", "join", "getGraphQueuePath", "join", "getProjectDir", "readQueuedOperations", "queuePath", "existsSync", "lines", "readFileSync", "line", "operations", "op", "logHook", "error", "clearQueue", "unlinkSync", "aggregateOperations", "entities", "relations", "observations", "seenEntities", "seenRelations", "entity", "rel", "key", "obs", "existing", "o", "generateSystemMessage", "aggregated", "parts", "l", "i", "graphQueueSync", "_input", "outputSilentSuccess", "systemMessage", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "join", "dirname", "HOOK_NAME", "MIN_ACTIONS_FOR_PATTERN", "getWorkflowPreferencesPath", "getProjectDir", "loadWorkflowPreferences", "filePath", "createEmptyWorkflowPreferences", "content", "saveWorkflowPreferences", "data", "dir", "err", "logHook", "patterns", "pattern_counts", "pattern_success_rates", "pattern", "calculateWorkflowPreferences", "preferences", "timestamp", "count", "successRates", "avgSuccessRate", "a", "b", "updateWorkflowPreferences", "flow", "successRate", "workflowPreferenceLearner", "input", "sessionId", "getSessionId", "analyzeDecisionFlow", "outputSilentSuccess", "completeDecisionFlow", "topPref", "existsSync", "readFileSync", "unlinkSync", "join", "TECHNOLOGIES", "PATTERNS", "TOOLS", "buildAliasMap", "registry", "map", "entry", "alias", "buildPatternVariantMap", "variant", "TECH_ALIAS_MAP", "TOOL_ALIAS_MAP", "PATTERN_VARIANT_MAP", "isMem0Configured", "getMem0QueuePath", "join", "getProjectDir", "readQueuedMemories", "queuePath", "existsSync", "lines", "readFileSync", "line", "memories", "memory", "logHook", "error", "clearQueue", "unlinkSync", "groupByUserId", "groups", "existing", "deduplicateMemories", "seen", "key", "generateSystemMessage", "grouped", "parts", "callIndex", "userId", "userMemories", "i", "categories", "m", "mem0QueueSync", "_input", "isMem0Configured", "outputSilentSuccess", "rawMemories", "systemMessage", "HOOKS", "autoSaveContext", "sessionPatterns", "issueWorkSummary", "calibrationPersist", "sessionProfileAggregator", "sessionEndTracking", "graphQueueSync", "workflowPreferenceLearner", "mem0QueueSync", "unifiedStopDispatcher", "input", "errors", "HOOKS", "hook", "result", "error", "message", "logHook", "outputSilentSuccess", "hooks", "autoRememberContinuity", "autoSaveContext", "cleanupInstance", "contextCompressor", "fullTestSuite", "issueWorkSummary", "mem0PreCompactionSync", "multiInstanceCleanup", "securityScanAggregator", "sessionPatterns", "taskCompletionCheck", "calibrationPersist", "unifiedStopDispatcher", "workflowPreferenceLearner", "graphQueueSync", "sessionEndTracking", "getHook", "name", "listHooks"]
}
