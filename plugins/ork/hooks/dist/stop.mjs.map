{
  "version": 3,
  "sources": ["../src/types.ts", "../src/lib/common.ts", "../src/lib/calibration-engine.ts", "../src/stop/auto-remember-continuity.ts", "../src/stop/auto-save-context.ts", "../src/stop/cleanup-instance.ts", "../src/stop/context-compressor.ts", "../src/stop/full-test-suite.ts", "../src/stop/issue-work-summary.ts", "../src/stop/mem0-pre-compaction-sync.ts", "../src/stop/multi-instance-cleanup.ts", "../src/stop/security-scan-aggregator.ts", "../src/stop/session-patterns.ts", "../src/stop/task-completion-check.ts", "../src/lib/task-integration.ts", "../src/lib/orchestration-state.ts", "../src/stop/calibration-persist.ts", "../src/stop/unified-dispatcher.ts", "../src/entries/stop.ts"],
  "sourcesContent": ["/**\n * TypeScript type definitions for Claude Code hooks\n * CC 2.1.9 compliant with additionalContext support\n */\n\n/**\n * Hook events supported by Claude Code\n */\nexport type HookEvent =\n  | 'PreToolUse'\n  | 'PostToolUse'\n  | 'PermissionRequest'\n  | 'UserPromptSubmit'\n  | 'SessionStart'\n  | 'SessionEnd'\n  | 'Stop'\n  | 'SubagentStart'\n  | 'SubagentStop'\n  | 'Setup'\n  | 'Notification';\n\n/**\n * Hook input envelope from Claude Code (sent via stdin as JSON)\n */\nexport interface HookInput {\n  /** The hook event type */\n  hook_event?: HookEvent;\n  /** The tool being invoked */\n  tool_name: string;\n  /** Session ID (CC 2.1.9 guarantees availability) */\n  session_id: string;\n  /** Tool-specific input parameters */\n  tool_input: ToolInput;\n  /** Tool output (PostToolUse only) */\n  tool_output?: unknown;\n  /** Tool error message if any */\n  tool_error?: string;\n  /** Tool exit code */\n  exit_code?: number;\n  /** User prompt (UserPromptSubmit only) */\n  prompt?: string;\n  /** Project directory */\n  project_dir?: string;\n\n  // SubagentStart/SubagentStop specific fields\n  /** Agent type for subagent hooks */\n  subagent_type?: string;\n  /** Agent type (alternative field name) */\n  agent_type?: string;\n  /** Agent ID */\n  agent_id?: string;\n  /** Agent output (SubagentStop) */\n  agent_output?: string;\n  /** Output (alternative field name) */\n  output?: string;\n  /** Error from subagent */\n  error?: string;\n  /** Duration in milliseconds */\n  duration_ms?: number;\n  /** Tool result \u2014 string from most hooks, object from Skill PostToolUse */\n  tool_result?: string | { is_error?: boolean; content?: string };\n\n  // Notification specific fields\n  /** Notification message */\n  message?: string;\n  /** Notification type */\n  notification_type?: string;\n}\n\n/**\n * Tool input types - union of all tool inputs\n */\nexport interface ToolInput {\n  /** Bash command (Bash tool) */\n  command?: string;\n  /** Timeout in ms (Bash tool) */\n  timeout?: number;\n  /** File path (Write/Edit/Read tools) */\n  file_path?: string;\n  /** File content (Write tool) */\n  content?: string;\n  /** Old text to replace (Edit tool) */\n  old_string?: string;\n  /** New text (Edit tool) */\n  new_string?: string;\n  /** Pattern (Glob/Grep tools) */\n  pattern?: string;\n  /** Allow additional properties */\n  [key: string]: unknown;\n}\n\n/**\n * Hook-specific output for CC 2.1.9\n */\nexport interface HookSpecificOutput {\n  /** Hook event name for context */\n  hookEventName?: 'PreToolUse' | 'PostToolUse' | 'PermissionRequest' | 'UserPromptSubmit';\n  /** Permission decision (PermissionRequest hooks) */\n  permissionDecision?: 'allow' | 'deny';\n  /** Reason for permission decision */\n  permissionDecisionReason?: string;\n  /** Additional context injected before tool execution (CC 2.1.9) */\n  additionalContext?: string;\n}\n\n/**\n * Hook result - output JSON to stdout\n * CC 2.1.7+ compliant\n */\nexport interface HookResult {\n  /** Whether to continue execution */\n  continue: boolean;\n  /** Suppress hook output from user */\n  suppressOutput?: boolean;\n  /** System message shown to user */\n  systemMessage?: string;\n  /** Reason for stopping (when continue is false) */\n  stopReason?: string;\n  /** Hook-specific output fields */\n  hookSpecificOutput?: HookSpecificOutput;\n}\n\n/**\n * Hook function signature\n */\nexport type HookFn = (input: HookInput) => Promise<HookResult> | HookResult;\n\n/**\n * Hook metadata for auto-discovery and governance\n * Co-export alongside hook functions for single-source-of-truth registration\n */\nexport interface HookMeta {\n  /** Full hook name path (e.g., 'pretool/bash/dangerous-command-blocker') */\n  name: string;\n  /** Human-readable description */\n  description: string;\n  /** Hook event type */\n  event: HookEvent;\n  /** Tool matcher patterns for hooks.json (e.g., 'Bash', 'Write|Edit') */\n  matchers?: string[];\n  /** Run asynchronously (non-blocking) */\n  async?: boolean;\n  /** Only run once per session */\n  once?: boolean;\n  /** Timeout in seconds (async hooks only) */\n  timeout?: number;\n  /** Risk category for prioritization */\n  tier?: 'security-critical' | 'data-loss' | 'quality-gate' | 'standard';\n}\n\n/**\n * Hook overrides configuration for per-project toggle/customization\n * Stored at .claude/hook-overrides.json (gitignored)\n */\nexport interface HookOverrides {\n  /** Hook names to disable entirely */\n  disabled?: string[];\n  /** Per-hook timeout overrides (seconds) */\n  timeouts?: Record<string, number>;\n}\n\n/**\n * Hook registration entry\n */\nexport interface HookRegistration {\n  /** Hook name (e.g., 'permission/auto-approve-readonly') */\n  name: string;\n  /** Hook event type */\n  event: HookEvent;\n  /** Tool matcher (string pattern or regex) */\n  matcher?: string | RegExp;\n  /** Hook implementation function */\n  fn: HookFn;\n}\n\n/**\n * Bash tool input (type guard helper)\n */\nexport interface BashToolInput extends ToolInput {\n  command: string;\n  timeout?: number;\n}\n\n/**\n * Write tool input (type guard helper)\n */\nexport interface WriteToolInput extends ToolInput {\n  file_path: string;\n  content: string;\n}\n\n/**\n * Edit tool input (type guard helper)\n */\nexport interface EditToolInput extends ToolInput {\n  file_path: string;\n  old_string: string;\n  new_string: string;\n}\n\n/**\n * Read tool input (type guard helper)\n */\nexport interface ReadToolInput extends ToolInput {\n  file_path: string;\n  offset?: number;\n  limit?: number;\n}\n\n/**\n * Type guards for tool inputs\n */\nexport function isBashInput(input: ToolInput): input is BashToolInput {\n  return typeof input.command === 'string';\n}\n\nexport function isWriteInput(input: ToolInput): input is WriteToolInput {\n  return typeof input.file_path === 'string' && typeof input.content === 'string';\n}\n\nexport function isEditInput(input: ToolInput): input is EditToolInput {\n  return (\n    typeof input.file_path === 'string' &&\n    typeof input.old_string === 'string' &&\n    typeof input.new_string === 'string'\n  );\n}\n\nexport function isReadInput(input: ToolInput): input is ReadToolInput {\n  return typeof input.file_path === 'string' && input.content === undefined;\n}\n", "/**\n * Common utilities for TypeScript hooks\n * Ported from hooks/_lib/common.sh\n */\n\nimport { appendFileSync, existsSync, statSync, renameSync, mkdirSync, readSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookResult, HookInput } from '../types.js';\n\n// -----------------------------------------------------------------------------\n// Environment and Paths\n// All functions read env vars dynamically to support testing\n// -----------------------------------------------------------------------------\n\n/**\n * Get the log directory path\n */\nexport function getLogDir(): string {\n  if (process.env.CLAUDE_PLUGIN_ROOT) {\n    return `${process.env.HOME || '/tmp'}/.claude/logs/ork`;\n  }\n  return `${getProjectDir()}/.claude/logs`;\n}\n\n/**\n * Get the project directory\n * Read dynamically to support testing\n */\nexport function getProjectDir(): string {\n  return process.env.CLAUDE_PROJECT_DIR || '.';\n}\n\n/**\n * Get the plugin root directory\n * Read dynamically to support testing\n */\nexport function getPluginRoot(): string {\n  return process.env.CLAUDE_PLUGIN_ROOT || process.env.CLAUDE_PROJECT_DIR || '.';\n}\n\n/**\n * Get the session ID\n * CC 2.1.9+ should guarantee CLAUDE_SESSION_ID availability, but we add\n * a defensive fallback to prevent hook crashes during edge cases.\n * Read dynamically to support testing.\n */\nexport function getSessionId(): string {\n  return process.env.CLAUDE_SESSION_ID || `fallback-${process.pid}-${Date.now()}`;\n}\n\n/**\n * Get cached git branch (set at session start or first call)\n * Caches result in process.env to avoid repeated execSync calls\n */\nexport function getCachedBranch(projectDir?: string): string {\n  if (process.env.ORCHESTKIT_BRANCH) {\n    return process.env.ORCHESTKIT_BRANCH;\n  }\n\n  try {\n    const branch = execSync('git branch --show-current', {\n      cwd: projectDir || getProjectDir(),\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    }).trim();\n    process.env.ORCHESTKIT_BRANCH = branch;\n    return branch;\n  } catch {\n    return 'unknown';\n  }\n}\n\n/**\n * Get log level (debug|info|warn|error, default: warn)\n */\nexport function getLogLevel(): string {\n  return process.env.ORCHESTKIT_LOG_LEVEL || 'warn';\n}\n\n/**\n * Check if should log at given level\n */\nexport function shouldLog(level: 'debug' | 'info' | 'warn' | 'error'): boolean {\n  const levels = ['debug', 'info', 'warn', 'error'];\n  return levels.indexOf(level) >= levels.indexOf(getLogLevel());\n}\n\n// -----------------------------------------------------------------------------\n// Output Helpers (CC 2.1.7+ compliant)\n// -----------------------------------------------------------------------------\n\n/**\n * Output silent success - hook completed without errors, no user-visible output\n */\nexport function outputSilentSuccess(): HookResult {\n  return { continue: true, suppressOutput: true };\n}\n\n/**\n * Output silent allow - permission hook approves silently\n */\nexport function outputSilentAllow(): HookResult {\n  return {\n    continue: true,\n    suppressOutput: true,\n    hookSpecificOutput: { permissionDecision: 'allow' },\n  };\n}\n\n/**\n * Output block - stops the operation with an error\n */\nexport function outputBlock(reason: string): HookResult {\n  return {\n    continue: false,\n    stopReason: reason,\n    hookSpecificOutput: {\n      permissionDecision: 'deny',\n      permissionDecisionReason: reason,\n    },\n  };\n}\n\n/**\n * Output with additionalContext - injects context before tool execution (CC 2.1.9)\n * For PostToolUse hooks (hookEventName optional)\n */\nexport function outputWithContext(ctx: string): HookResult {\n  return {\n    continue: true,\n    suppressOutput: true,\n    hookSpecificOutput: {\n      hookEventName: 'PostToolUse',\n      additionalContext: ctx,\n    },\n  };\n}\n\n/**\n * Output with additionalContext for UserPromptSubmit hooks (CC 2.1.9)\n * hookEventName is REQUIRED for UserPromptSubmit\n */\nexport function outputPromptContext(ctx: string): HookResult {\n  return {\n    continue: true,\n    suppressOutput: true,\n    hookSpecificOutput: {\n      hookEventName: 'UserPromptSubmit',\n      additionalContext: ctx,\n    },\n  };\n}\n\n/**\n * Output allow with additionalContext - permission hook approves with context (CC 2.1.9)\n */\nexport function outputAllowWithContext(ctx: string, systemMessage?: string): HookResult {\n  const result: HookResult = {\n    continue: true,\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      additionalContext: ctx,\n      permissionDecision: 'allow',\n    },\n  };\n\n  if (systemMessage) {\n    result.systemMessage = systemMessage;\n  } else {\n    result.suppressOutput = true;\n  }\n\n  return result;\n}\n\n/**\n * Output error message - only use when there's an actual problem\n */\nexport function outputError(message: string): HookResult {\n  return { continue: true, systemMessage: message };\n}\n\n/**\n * Output warning message - CC 2.1.7 compliant (no ANSI in JSON)\n */\nexport function outputWarning(message: string): HookResult {\n  return { continue: true, systemMessage: `\\u26a0 ${message}` };\n}\n\n/**\n * Output deny with feedback logging (CC 2.1.7)\n */\nexport function outputDeny(reason: string): HookResult {\n  return {\n    continue: false,\n    stopReason: reason,\n    hookSpecificOutput: {\n      hookEventName: 'PreToolUse',\n      permissionDecision: 'deny',\n      permissionDecisionReason: reason,\n    },\n  };\n}\n\n// -----------------------------------------------------------------------------\n// Logging (with log level guard for performance)\n// -----------------------------------------------------------------------------\n\nconst LOG_ROTATION_MAX_SIZE = 200 * 1024; // 200KB\nconst PERMISSION_LOG_MAX_SIZE = 100 * 1024; // 100KB\n\n/**\n * Rotate log file if it exceeds size limit\n */\nfunction rotateLogFile(logFile: string, maxSize: number): void {\n  if (!existsSync(logFile)) return;\n\n  try {\n    const stats = statSync(logFile);\n    if (stats.size > maxSize) {\n      const rotated = `${logFile}.old.${Date.now()}`;\n      renameSync(logFile, rotated);\n    }\n  } catch {\n    // Ignore rotation errors\n  }\n}\n\n/**\n * Ensure directory exists\n */\nfunction ensureDir(dir: string): void {\n  if (!existsSync(dir)) {\n    mkdirSync(dir, { recursive: true });\n  }\n}\n\n/**\n * Log to hook log file with automatic rotation\n * Respects ORCHESTKIT_LOG_LEVEL (default: warn, skips debug logs in production)\n */\nexport function logHook(hookName: string, message: string, level: 'debug' | 'info' | 'warn' | 'error' = 'debug'): void {\n  // Skip if below log level threshold (big perf win - avoids I/O)\n  if (!shouldLog(level)) {\n    return;\n  }\n\n  const logDir = getLogDir();\n  const logFile = `${logDir}/hooks.log`;\n\n  try {\n    ensureDir(logDir);\n    rotateLogFile(logFile, LOG_ROTATION_MAX_SIZE);\n\n    const timestamp = new Date().toISOString().replace('T', ' ').slice(0, 19);\n    appendFileSync(logFile, `[${timestamp}] [${level.toUpperCase()}] [${hookName}] ${message}\\n`);\n  } catch {\n    // Ignore logging errors - don't block hook execution\n  }\n}\n\n/**\n * Log permission decision for audit trail (CC 2.1.7 feature)\n * Always logs (security audit trail) - not affected by log level\n */\nexport function logPermissionFeedback(\n  decision: 'allow' | 'deny' | 'warn',\n  reason: string,\n  input?: HookInput | Record<string, unknown>\n): void {\n  const logDir = getLogDir();\n  const logFile = `${logDir}/permission-feedback.log`;\n\n  try {\n    ensureDir(logDir);\n    rotateLogFile(logFile, PERMISSION_LOG_MAX_SIZE);\n\n    const timestamp = new Date().toISOString();\n    const toolName = (input as HookInput)?.tool_name || process.env.HOOK_TOOL_NAME || 'unknown';\n    const sessionId = (input as HookInput)?.session_id || getSessionId();\n\n    appendFileSync(\n      logFile,\n      `${timestamp} | ${decision} | ${reason} | tool=${toolName} | session=${sessionId}\\n`\n    );\n  } catch {\n    // Ignore logging errors\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Input Helpers\n// -----------------------------------------------------------------------------\n\n/**\n * Read hook input from stdin synchronously\n * Returns parsed JSON or empty object on failure\n */\nexport function readHookInput(): HookInput {\n  try {\n    // Read from stdin synchronously\n    const chunks: Buffer[] = [];\n    const BUFSIZE = 256;\n    const buf = Buffer.allocUnsafe(BUFSIZE);\n\n    let bytesRead: number;\n    const fd = 0; // stdin\n\n    while (true) {\n      try {\n        bytesRead = readSync(fd, buf, 0, BUFSIZE, null);\n        if (bytesRead === 0) break;\n        chunks.push(Buffer.from(buf.subarray(0, bytesRead)));\n      } catch {\n        break;\n      }\n    }\n\n    const input = Buffer.concat(chunks).toString('utf8').trim();\n    if (!input) {\n      return { tool_name: '', session_id: getSessionId(), tool_input: {} };\n    }\n\n    return JSON.parse(input);\n  } catch {\n    return { tool_name: '', session_id: getSessionId(), tool_input: {} };\n  }\n}\n\n/**\n * Get field from hook input using optional chaining\n */\nexport function getField<T>(input: HookInput, path: string): T | undefined {\n  const parts = path.replace(/^\\./, '').split('.');\n  let value: unknown = input;\n\n  for (const part of parts) {\n    if (value === null || value === undefined) return undefined;\n    value = (value as Record<string, unknown>)[part];\n  }\n\n  return value as T;\n}\n\n// -----------------------------------------------------------------------------\n// String Utilities\n// -----------------------------------------------------------------------------\n\n/**\n * Normalize command: remove line continuations and collapse whitespace\n * Prevents bypassing detection with backslash-newline tricks (CC 2.1.6 fix)\n */\nexport function normalizeCommand(command: string): string {\n  return command\n    .replace(/\\\\\\s*[\\r\\n]+/g, ' ') // Remove line continuations\n    .replace(/\\n/g, ' ') // Replace newlines with spaces\n    .replace(/\\s+/g, ' ') // Collapse whitespace\n    .trim();\n}\n\n/**\n * Escape string for use in regex\n */\nexport function escapeRegex(str: string): string {\n  return str.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\n", "/**\n * Calibration Engine - Outcome-based learning for intent classification\n * Issue #197: Agent Orchestration Layer\n *\n * Learns from agent dispatch outcomes to improve classification accuracy:\n * - Records dispatch-outcome pairs\n * - Calculates keyword-agent boost/penalty adjustments\n * - Provides calibration data for intent classifier\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { createHash } from 'node:crypto';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport type {\n  CalibrationRecord,\n  CalibrationAdjustment,\n  CalibrationData,\n  AgentOutcome,\n} from './orchestration-types.js';\n\n// -----------------------------------------------------------------------------\n// Constants\n// -----------------------------------------------------------------------------\n\n/** Maximum records to keep in calibration data */\nconst MAX_RECORDS = 500;\n\n/** Minimum samples needed before applying adjustments */\nconst MIN_SAMPLES_FOR_ADJUSTMENT = 3;\n\n/** Maximum adjustment magnitude */\nconst MAX_ADJUSTMENT = 15;\n\n/** Adjustment step per outcome */\nconst ADJUSTMENT_STEP = 3;\n\n/** Decay factor for old records (applied to adjustments) */\nconst DECAY_FACTOR = 0.9;\n\n// -----------------------------------------------------------------------------\n// File Management\n// -----------------------------------------------------------------------------\n\nfunction getCalibrationFile(): string {\n  return `${getProjectDir()}/.claude/feedback/calibration-data.json`;\n}\n\nfunction ensureDir(): void {\n  const dir = `${getProjectDir()}/.claude/feedback`;\n  if (!existsSync(dir)) {\n    try {\n      mkdirSync(dir, { recursive: true });\n    } catch {\n      // Ignore\n    }\n  }\n}\n\n/**\n * Load calibration data from file\n */\nexport function loadCalibrationData(): CalibrationData {\n  const file = getCalibrationFile();\n\n  if (existsSync(file)) {\n    try {\n      return JSON.parse(readFileSync(file, 'utf8'));\n    } catch {\n      logHook('calibration-engine', 'Failed to load calibration data, using defaults');\n    }\n  }\n\n  return {\n    schemaVersion: '1.0.0',\n    createdAt: new Date().toISOString(),\n    updatedAt: new Date().toISOString(),\n    records: [],\n    adjustments: [],\n    stats: {\n      totalDispatches: 0,\n      successRate: 0,\n      avgConfidence: 0,\n      topAgents: [],\n    },\n  };\n}\n\n/**\n * Save calibration data to file\n */\nexport function saveCalibrationData(data: CalibrationData): void {\n  ensureDir();\n  const file = getCalibrationFile();\n\n  data.updatedAt = new Date().toISOString();\n\n  try {\n    writeFileSync(file, JSON.stringify(data, null, 2));\n    logHook('calibration-engine', 'Saved calibration data');\n  } catch (err) {\n    logHook('calibration-engine', `Failed to save calibration data: ${err}`);\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Recording\n// -----------------------------------------------------------------------------\n\n/**\n * Create a hash of prompt for deduplication\n */\nexport function hashPrompt(prompt: string): string {\n  return createHash('sha256').update(prompt.toLowerCase().trim()).digest('hex').slice(0, 16);\n}\n\n/**\n * Record a dispatch outcome\n */\nexport function recordOutcome(\n  prompt: string,\n  agent: string,\n  matchedKeywords: string[],\n  confidence: number,\n  outcome: AgentOutcome,\n  durationMs?: number,\n  feedback?: 'positive' | 'negative' | 'neutral'\n): void {\n  const data = loadCalibrationData();\n\n  const record: CalibrationRecord = {\n    timestamp: new Date().toISOString(),\n    sessionId: getSessionId(),\n    agent,\n    promptHash: hashPrompt(prompt),\n    matchedKeywords,\n    dispatchConfidence: confidence,\n    outcome,\n    durationMs,\n    feedback,\n  };\n\n  data.records.push(record);\n\n  // Trim old records\n  if (data.records.length > MAX_RECORDS) {\n    data.records = data.records.slice(-MAX_RECORDS);\n  }\n\n  // Update adjustments\n  updateAdjustments(data, record);\n\n  // Update stats\n  updateStats(data);\n\n  saveCalibrationData(data);\n\n  logHook(\n    'calibration-engine',\n    `Recorded outcome: ${agent} -> ${outcome} (conf: ${confidence})`\n  );\n}\n\n// -----------------------------------------------------------------------------\n// Adjustment Calculation\n// -----------------------------------------------------------------------------\n\n/**\n * Update adjustments based on new record\n */\nfunction updateAdjustments(data: CalibrationData, record: CalibrationRecord): void {\n  const isPositive = record.outcome === 'success';\n  const isNegative = record.outcome === 'failure' || record.outcome === 'rejected';\n\n  if (!isPositive && !isNegative) {\n    // Partial outcomes don't affect adjustments\n    return;\n  }\n\n  const adjustmentDelta = isPositive ? ADJUSTMENT_STEP : -ADJUSTMENT_STEP;\n\n  for (const keyword of record.matchedKeywords) {\n    const existing = data.adjustments.find(\n      a => a.keyword === keyword && a.agent === record.agent\n    );\n\n    if (existing) {\n      // Update existing adjustment\n      existing.adjustment = Math.max(\n        -MAX_ADJUSTMENT,\n        Math.min(MAX_ADJUSTMENT, existing.adjustment + adjustmentDelta)\n      );\n      existing.sampleCount++;\n      existing.lastUpdated = new Date().toISOString();\n    } else {\n      // Create new adjustment\n      data.adjustments.push({\n        keyword,\n        agent: record.agent,\n        adjustment: adjustmentDelta,\n        sampleCount: 1,\n        lastUpdated: new Date().toISOString(),\n      });\n    }\n  }\n}\n\n/**\n * Apply decay to old adjustments\n */\nexport function applyDecay(data: CalibrationData): void {\n  const now = Date.now();\n  const dayMs = 24 * 60 * 60 * 1000;\n\n  for (const adj of data.adjustments) {\n    const age = now - new Date(adj.lastUpdated).getTime();\n    const daysOld = Math.floor(age / dayMs);\n\n    if (daysOld > 7) {\n      // Apply decay for adjustments older than 7 days\n      adj.adjustment = Math.round(adj.adjustment * DECAY_FACTOR);\n\n      // Remove zero adjustments\n      if (Math.abs(adj.adjustment) < 1) {\n        adj.adjustment = 0;\n      }\n    }\n  }\n\n  // Remove zero adjustments\n  data.adjustments = data.adjustments.filter(a => a.adjustment !== 0);\n}\n\n// -----------------------------------------------------------------------------\n// Statistics\n// -----------------------------------------------------------------------------\n\n/**\n * Update aggregate statistics\n */\nfunction updateStats(data: CalibrationData): void {\n  const records = data.records;\n  if (records.length === 0) return;\n\n  // Total dispatches\n  data.stats.totalDispatches = records.length;\n\n  // Success rate\n  const successful = records.filter(r => r.outcome === 'success').length;\n  data.stats.successRate = successful / records.length;\n\n  // Average confidence\n  const avgConf = records.reduce((sum, r) => sum + r.dispatchConfidence, 0) / records.length;\n  data.stats.avgConfidence = Math.round(avgConf);\n\n  // Top agents by count and success rate\n  const agentStats = new Map<string, { count: number; success: number }>();\n  for (const record of records) {\n    const stat = agentStats.get(record.agent) || { count: 0, success: 0 };\n    stat.count++;\n    if (record.outcome === 'success') stat.success++;\n    agentStats.set(record.agent, stat);\n  }\n\n  data.stats.topAgents = Array.from(agentStats.entries())\n    .map(([agent, stat]) => ({\n      agent,\n      count: stat.count,\n      successRate: stat.success / stat.count,\n    }))\n    .sort((a, b) => b.count - a.count)\n    .slice(0, 10);\n}\n\n// -----------------------------------------------------------------------------\n// Query Functions\n// -----------------------------------------------------------------------------\n\n/**\n * Get adjustments for intent classifier\n */\nexport function getAdjustments(): CalibrationAdjustment[] {\n  const data = loadCalibrationData();\n\n  // Only return adjustments with sufficient samples\n  return data.adjustments.filter(a => a.sampleCount >= MIN_SAMPLES_FOR_ADJUSTMENT);\n}\n\n/**\n * Get success rate for a specific agent\n */\nexport function getAgentSuccessRate(agent: string): number | null {\n  const data = loadCalibrationData();\n  const agentRecords = data.records.filter(r => r.agent === agent);\n\n  if (agentRecords.length < MIN_SAMPLES_FOR_ADJUSTMENT) {\n    return null;\n  }\n\n  const successful = agentRecords.filter(r => r.outcome === 'success').length;\n  return successful / agentRecords.length;\n}\n\n/**\n * Get calibration stats\n */\nexport function getCalibrationStats(): CalibrationData['stats'] {\n  return loadCalibrationData().stats;\n}\n\n/**\n * Check if we have enough data for meaningful calibration\n */\nexport function hasMinimalCalibrationData(): boolean {\n  const data = loadCalibrationData();\n  return data.records.length >= MIN_SAMPLES_FOR_ADJUSTMENT;\n}\n", "/**\n * Auto-Remember Continuity - Stop Hook\n * Prompts Claude to store session context before end\n *\n * Graph-First Architecture (v2.1):\n * - ALWAYS works - knowledge graph requires no configuration\n * - Primary: Store in knowledge graph (mcp__memory__*)\n * - Optional: Also sync to mem0 cloud if configured\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir } from '../lib/common.js';\n\n/**\n * Generate stop prompt for session continuity\n */\nexport function autoRememberContinuity(input: HookInput): HookResult {\n  logHook('auto-remember-continuity', 'Hook triggered');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const projectId = projectDir.split('/').pop() || 'project';\n\n  // Check if mem0 is available (by checking env var)\n  const mem0Available = !!process.env.MEM0_API_KEY;\n  const mem0Hint = mem0Available\n    ? '\\n   [Optional] Also sync to mem0 cloud with `--mem0` flag for semantic search'\n    : '';\n\n  const promptMsg = `Before ending this session, consider preserving important context in the knowledge graph:\n\n1. **Session Continuity** - If there's unfinished work or next steps:\n   \\`mcp__memory__create_entities\\` with:\n   \\`\\`\\`json\n   {\"entities\": [{\n     \"name\": \"session-${projectId}\",\n     \"entityType\": \"Session\",\n     \"observations\": [\"What was done: [...]\", \"Next steps: [...]\"]\n   }]}\n   \\`\\`\\`${mem0Hint}\n\n2. **Important Decisions** - If architectural/design decisions were made:\n   \\`mcp__memory__create_entities\\` with:\n   \\`\\`\\`json\n   {\"entities\": [{\n     \"name\": \"decision-[topic]\",\n     \"entityType\": \"Decision\",\n     \"observations\": [\"Decided: [...]\", \"Rationale: [...]\"]\n   }]}\n   \\`\\`\\`\n\n3. **Patterns Learned** - If something worked well or failed:\n   - Use \\`/remember --success \"pattern that worked\"\\`\n   - Use \\`/remember --failed \"pattern that caused issues\"\\`\n\nSkip if this was just a quick question/answer session.`;\n\n  logHook('auto-remember-continuity', 'Outputting memory prompt for session end');\n\n  return {\n    continue: true,\n    suppressOutput: true,\n    // Note: stopPrompt is handled by the CC runtime, we just return continue: true\n  };\n}\n", "/**\n * Auto-Save Context - Saves session context before stop\n * Hook: Stop\n * CC 2.1.6 Compliant - Context Protocol 2.0\n *\n * Ensures state.json always has required fields:\n * - $schema: For schema validation\n * - _meta: For attention positioning and token budgets\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\ninterface SessionState {\n  $schema: string;\n  _meta: {\n    position: string;\n    token_budget: number;\n    auto_load: string;\n    compress: string;\n    description: string;\n  };\n  session_id: string | null;\n  started: string | null;\n  last_activity: string;\n  current_task: {\n    description: string;\n    status: string;\n  };\n  next_steps: string[];\n  blockers: string[];\n}\n\n/**\n * Auto-save context on session stop\n */\nexport function autoSaveContext(input: HookInput): HookResult {\n  logHook('auto-save-context', 'Stop hook - auto-saving context (Protocol 2.0)');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const sessionDir = `${projectDir}/.claude/context/session`;\n  const sessionState = `${sessionDir}/state.json`;\n\n  // Ensure session directory exists\n  try {\n    if (!existsSync(sessionDir)) {\n      mkdirSync(sessionDir, { recursive: true });\n    }\n  } catch {\n    // Ignore directory creation errors\n  }\n\n  const timestamp = new Date().toISOString();\n\n  try {\n    if (existsSync(sessionState)) {\n      // Update existing session state\n      const content = readFileSync(sessionState, 'utf-8');\n      const state: Partial<SessionState> = JSON.parse(content);\n\n      // Ensure required fields exist\n      const updated: SessionState = {\n        $schema: state.$schema || 'context://session/v1',\n        _meta: state._meta || {\n          position: 'END',\n          token_budget: 500,\n          auto_load: 'always',\n          compress: 'on_threshold',\n          description: 'Session state and progress - ALWAYS loaded at END of context',\n        },\n        session_id: state.session_id || null,\n        started: state.started || null,\n        last_activity: timestamp,\n        current_task: state.current_task || { description: 'No active task', status: 'pending' },\n        next_steps: state.next_steps || [],\n        blockers: state.blockers || [],\n      };\n\n      writeFileSync(sessionState, JSON.stringify(updated, null, 2));\n      logHook('auto-save-context', 'Updated session state timestamp');\n    } else {\n      // Create new session state\n      const newState: SessionState = {\n        $schema: 'context://session/v1',\n        _meta: {\n          position: 'END',\n          token_budget: 500,\n          auto_load: 'always',\n          compress: 'on_threshold',\n          description: 'Session state and progress - ALWAYS loaded at END of context',\n        },\n        session_id: null,\n        started: timestamp,\n        last_activity: timestamp,\n        current_task: {\n          description: 'No active task',\n          status: 'pending',\n        },\n        next_steps: [],\n        blockers: [],\n      };\n\n      writeFileSync(sessionState, JSON.stringify(newState, null, 2));\n      logHook('auto-save-context', 'Created new session state (Protocol 2.0 compliant)');\n    }\n  } catch (error) {\n    logHook('auto-save-context', `Error saving context: ${error}`);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Cleanup Instance - Stop Hook\n * Releases all locks and unregisters instance when Claude Code exits\n * CC 2.1.6 Compliant\n *\n * Part of Multi-Worktree Coordination System\n */\n\nimport { existsSync, readFileSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Get instance ID from identity file\n */\nfunction getInstanceId(projectDir: string): string | null {\n  const idFile = `${projectDir}/.instance/id.json`;\n  try {\n    if (!existsSync(idFile)) {\n      return null;\n    }\n    const content = JSON.parse(readFileSync(idFile, 'utf-8'));\n    return content.instance_id || null;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Execute SQLite command\n */\nfunction runSqlite(dbPath: string, sql: string): void {\n  try {\n    execSync(`sqlite3 \"${dbPath}\" \"${sql}\"`, {\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n  } catch {\n    // Ignore SQLite errors\n  }\n}\n\n/**\n * Cleanup instance on stop\n */\nexport function cleanupInstance(input: HookInput): HookResult {\n  const projectDir = input.project_dir || getProjectDir();\n  const dbPath = `${projectDir}/.claude/coordination/.claude.db`;\n\n  // Check if coordination is enabled\n  if (!existsSync(dbPath)) {\n    logHook('cleanup-instance', 'No coordination database, skipping cleanup');\n    return outputSilentSuccess();\n  }\n\n  // Get instance ID\n  const instanceId = getInstanceId(projectDir);\n  if (!instanceId) {\n    logHook('cleanup-instance', 'No instance ID to clean up');\n    return outputSilentSuccess();\n  }\n\n  logHook('cleanup-instance', `Cleaning up instance: ${instanceId}`);\n\n  // Release all locks held by this instance\n  logHook('cleanup-instance', 'Releasing all locks...');\n  runSqlite(dbPath, `DELETE FROM file_locks WHERE instance_id = '${instanceId}';`);\n  logHook('cleanup-instance', 'All locks released');\n\n  // Handle work claims if table exists\n  try {\n    const hasTable = execSync(\n      `sqlite3 \"${dbPath}\" \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='work_claims';\"`,\n      { encoding: 'utf8', timeout: 5000 }\n    ).trim();\n\n    if (hasTable === '1') {\n      runSqlite(\n        dbPath,\n        `UPDATE work_claims SET status = 'abandoned', completed_at = datetime('now') WHERE instance_id = '${instanceId}' AND status = 'active';`\n      );\n      logHook('cleanup-instance', 'Work claims handled');\n    }\n  } catch {\n    // Ignore table check errors\n  }\n\n  // Update instance status if table exists\n  try {\n    const hasTable = execSync(\n      `sqlite3 \"${dbPath}\" \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='instances';\"`,\n      { encoding: 'utf8', timeout: 5000 }\n    ).trim();\n\n    if (hasTable === '1') {\n      runSqlite(\n        dbPath,\n        `UPDATE instances SET status = 'terminated', last_heartbeat = datetime('now') WHERE id = '${instanceId}';`\n      );\n      logHook('cleanup-instance', 'Instance status updated to terminated');\n    }\n  } catch {\n    // Ignore table check errors\n  }\n\n  logHook('cleanup-instance', 'Multi-instance cleanup completed');\n  return outputSilentSuccess();\n}\n", "/**\n * Context Compressor - Session End Hook\n * CC 2.1.7 Compliant\n * Compresses and archives context at end of session\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n// Configuration\nconst MAX_ACTIVE_DECISIONS = 10;\n\ninterface SessionState {\n  session_id?: string;\n  [key: string]: unknown;\n}\n\ninterface DecisionsFile {\n  decisions: unknown[];\n  [key: string]: unknown;\n}\n\n/**\n * Archive current session\n */\nfunction archiveSession(contextDir: string): void {\n  const sessionFile = `${contextDir}/session/state.json`;\n  if (!existsSync(sessionFile)) {\n    logHook('context-compressor', 'No session state to archive');\n    return;\n  }\n\n  try {\n    const content = readFileSync(sessionFile, 'utf-8');\n    const session: SessionState = JSON.parse(content);\n\n    const sessionId = session.session_id || `session-${new Date().toISOString().replace(/[:.]/g, '-')}`;\n    const archiveDir = `${contextDir}/archive/sessions`;\n    mkdirSync(archiveDir, { recursive: true });\n\n    const archiveFile = `${archiveDir}/${sessionId}.json`;\n    const archived = {\n      ...session,\n      ended: new Date().toISOString(),\n      archived: true,\n    };\n\n    writeFileSync(archiveFile, JSON.stringify(archived, null, 2));\n    logHook('context-compressor', `Archived session to ${archiveFile}`);\n\n    // Reset session state\n    const resetState = {\n      $schema: 'context://session/v1',\n      _meta: { position: 'END', token_budget: 500, auto_load: 'always' },\n      session_id: null,\n      started: null,\n      current_task: null,\n      files_touched: [],\n      decisions_this_session: [],\n      blockers: [],\n      next_steps: [],\n      scratchpad: { notes: [] },\n    };\n\n    writeFileSync(sessionFile, JSON.stringify(resetState, null, 2));\n    logHook('context-compressor', 'Reset session state');\n  } catch (error) {\n    logHook('context-compressor', `Error archiving session: ${error}`);\n  }\n}\n\n/**\n * Compress old decisions\n */\nfunction compressOldDecisions(contextDir: string): void {\n  const decisionsFile = `${contextDir}/knowledge/decisions/active.json`;\n  if (!existsSync(decisionsFile)) {\n    return;\n  }\n\n  try {\n    const content = readFileSync(decisionsFile, 'utf-8');\n    const data: DecisionsFile = JSON.parse(content);\n    const decisions = data.decisions || [];\n\n    if (decisions.length <= MAX_ACTIVE_DECISIONS) {\n      return;\n    }\n\n    const archiveDir = `${contextDir}/archive/decisions`;\n    mkdirSync(archiveDir, { recursive: true });\n\n    const now = new Date();\n    const archiveFile = `${archiveDir}/${now.getFullYear()}-${String(now.getMonth() + 1).padStart(2, '0')}.json`;\n\n    // Archive old decisions\n    const toArchive = decisions.slice(0, -MAX_ACTIVE_DECISIONS);\n    writeFileSync(archiveFile, JSON.stringify(toArchive, null, 2));\n\n    // Keep only recent decisions\n    data.decisions = decisions.slice(-MAX_ACTIVE_DECISIONS);\n    writeFileSync(decisionsFile, JSON.stringify(data, null, 2));\n\n    logHook('context-compressor', `Archived ${toArchive.length} old decisions`);\n  } catch (error) {\n    logHook('context-compressor', `Error compressing decisions: ${error}`);\n  }\n}\n\n/**\n * Write compaction manifest for session resume (CC 2.1.20)\n * Provides structured context for session-context-loader to pick up\n */\nfunction writeCompactionManifest(contextDir: string): void {\n  const sessionFile = `${contextDir}/session/state.json`;\n  if (!existsSync(sessionFile)) {\n    return;\n  }\n\n  try {\n    const content = readFileSync(sessionFile, 'utf-8');\n    const session = JSON.parse(content);\n\n    const manifest = {\n      sessionId: session.session_id || 'unknown',\n      compactedAt: new Date().toISOString(),\n      keyDecisions: (session.decisions_this_session || []).slice(-5),\n      filesTouched: (session.files_touched || []).slice(-20),\n      blockers: session.blockers || [],\n      nextSteps: session.next_steps || [],\n    };\n\n    const manifestDir = `${contextDir}/session`;\n    mkdirSync(manifestDir, { recursive: true });\n    writeFileSync(`${manifestDir}/compaction-manifest.json`, JSON.stringify(manifest, null, 2));\n    logHook('context-compressor', `Wrote compaction manifest for session ${manifest.sessionId}`);\n  } catch (error) {\n    logHook('context-compressor', `Error writing compaction manifest: ${error}`);\n  }\n}\n\n/**\n * Main context compression function\n */\nexport function contextCompressor(input: HookInput): HookResult {\n  logHook('context-compressor', 'Starting end-of-session compression...');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const contextDir = `${projectDir}/context`;\n\n  writeCompactionManifest(contextDir);\n  archiveSession(contextDir);\n  compressOldDecisions(contextDir);\n\n  logHook('context-compressor', 'End-of-session compression complete');\n  return outputSilentSuccess();\n}\n", "/**\n * Full Test Suite Runner - Stop Hook\n * CC 2.1.3 Compliant - Uses 10-minute hook timeout\n *\n * Runs the complete test suite on conversation stop.\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Check if we should run tests\n */\nfunction shouldRunTests(projectDir: string): boolean {\n  const lastRunFile = `${projectDir}/.claude/hooks/logs/.last-test-run`;\n\n  // Always run if no previous run\n  if (!existsSync(lastRunFile)) {\n    return true;\n  }\n\n  // Check if any code files changed since last run\n  try {\n    const result = execSync('git diff --name-only HEAD', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n\n    if (/\\.(py|js|ts|go|rs)$/.test(result)) {\n      return true;\n    }\n  } catch {\n    // On error, run tests anyway\n    return true;\n  }\n\n  logHook('full-test-suite', 'No code changes detected, skipping tests');\n  return false;\n}\n\n/**\n * Detect project type and run appropriate tests\n */\nfunction runTests(projectDir: string, logFile: string): boolean {\n  let exitCode = 0;\n\n  // Python project (pytest)\n  if (\n    existsSync(`${projectDir}/pytest.ini`) ||\n    existsSync(`${projectDir}/pyproject.toml`) ||\n    (existsSync(`${projectDir}/tests`) && existsSync(`${projectDir}/requirements.txt`))\n  ) {\n    logHook('full-test-suite', 'Detected Python project, running pytest...');\n    try {\n      execSync('pytest --tb=short --timeout=300 -q', {\n        cwd: projectDir,\n        encoding: 'utf8',\n        timeout: 300000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  // Node.js project (npm/yarn/pnpm)\n  if (existsSync(`${projectDir}/package.json`)) {\n    logHook('full-test-suite', 'Detected Node.js project...');\n    try {\n      const packageJson = JSON.parse(readFileSync(`${projectDir}/package.json`, 'utf-8'));\n      if (packageJson.scripts?.test) {\n        logHook('full-test-suite', 'Running npm test...');\n\n        // Try different package managers\n        let cmd = 'npm test -- --passWithNoTests --watchAll=false';\n        try {\n          execSync('which pnpm', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n          cmd = 'pnpm test --passWithNoTests';\n        } catch {\n          try {\n            execSync('which yarn', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n            cmd = 'yarn test --passWithNoTests';\n          } catch {\n            // Use npm\n          }\n        }\n\n        execSync(cmd, {\n          cwd: projectDir,\n          encoding: 'utf8',\n          timeout: 300000,\n          stdio: ['pipe', 'pipe', 'pipe'],\n        });\n      }\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  // Go project\n  if (existsSync(`${projectDir}/go.mod`)) {\n    logHook('full-test-suite', 'Detected Go project, running go test...');\n    try {\n      execSync('go test -v -timeout 5m ./...', {\n        cwd: projectDir,\n        encoding: 'utf8',\n        timeout: 300000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  // Rust project\n  if (existsSync(`${projectDir}/Cargo.toml`)) {\n    logHook('full-test-suite', 'Detected Rust project, running cargo test...');\n    try {\n      execSync('cargo test', {\n        cwd: projectDir,\n        encoding: 'utf8',\n        timeout: 300000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      exitCode = 1;\n    }\n  }\n\n  return exitCode === 0;\n}\n\n/**\n * Full test suite runner\n */\nexport function fullTestSuite(input: HookInput): HookResult {\n  logHook('full-test-suite', '=== Full Test Suite Started ===');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const logDir = `${projectDir}/.claude/hooks/logs`;\n\n  // Ensure log directory exists\n  try {\n    mkdirSync(logDir, { recursive: true });\n  } catch {\n    // Ignore\n  }\n\n  const logFile = `${logDir}/full-test-suite.log`;\n\n  if (!shouldRunTests(projectDir)) {\n    return outputSilentSuccess();\n  }\n\n  const passed = runTests(projectDir, logFile);\n\n  if (passed) {\n    logHook('full-test-suite', '=== All tests passed ===');\n    // Update last run file\n    try {\n      writeFileSync(`${logDir}/.last-test-run`, String(Date.now()));\n    } catch {\n      // Ignore\n    }\n  } else {\n    logHook('full-test-suite', '=== Some tests failed ===');\n    // Don't block - just log the failure\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Issue Work Summary - Stop Hook\n * Posts consolidated progress comments to GitHub issues\n *\n * CC 2.1.7 Compliant: Uses suppressOutput for silent operation\n */\n\nimport { existsSync, readFileSync, unlinkSync, rmdirSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, getSessionId, outputSilentSuccess } from '../lib/common.js';\n\ninterface IssueProgress {\n  issues: {\n    [issueNum: string]: {\n      branch: string;\n      commits: Array<{ sha: string; message: string }>;\n      tasks_completed: string[];\n    };\n  };\n}\n\n/**\n * Check if gh CLI is available and authenticated\n */\nfunction isGhAvailable(): boolean {\n  try {\n    execSync('which gh', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n    execSync('gh auth status', { encoding: 'utf8', timeout: 5000, stdio: ['pipe', 'pipe', 'pipe'] });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Check if in a GitHub repository\n */\nfunction isGitHubRepo(projectDir: string): boolean {\n  try {\n    const remote = execSync('git remote get-url origin', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    return remote.includes('github');\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Generate markdown comment for an issue\n */\nfunction generateComment(issueNum: string, data: IssueProgress['issues'][string], sessionId: string): string {\n  const commits = data.commits || [];\n  if (commits.length === 0) {\n    return '';\n  }\n\n  const commitsSection = commits.map((c) => `- \\`${c.sha}\\`: ${c.message}`).join('\\n');\n  const tasksSection =\n    data.tasks_completed?.length > 0\n      ? `### Sub-tasks Completed\\n${data.tasks_completed.map((t) => `- [x] ${t}`).join('\\n')}`\n      : '';\n\n  return `## Claude Code Progress Update\n\n**Session**: \\`${sessionId.slice(0, 8)}...\\`\n**Branch**: \\`${data.branch || 'unknown'}\\`\n\n### Commits (${commits.length})\n${commitsSection}\n\n${tasksSection}\n---\n*Automated by [OrchestKit](https://github.com/yonatangross/orchestkit)*`;\n}\n\n/**\n * Post comment to GitHub issue\n */\nfunction postComment(issueNum: string, comment: string): boolean {\n  try {\n    execSync(`gh issue comment ${issueNum} --body \"${comment.replace(/\"/g, '\\\\\"')}\"`, {\n      encoding: 'utf8',\n      timeout: 30000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Issue work summary hook\n */\nexport function issueWorkSummary(input: HookInput): HookResult {\n  logHook('issue-work-summary', 'Session ending, checking for issue progress to post...');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const sessionId = input.session_id || getSessionId();\n\n  // Sanitize session ID to prevent path traversal\n  const safeSessionId = sessionId.replace(/[^a-zA-Z0-9_-]/g, '');\n  const sessionDir = `/tmp/claude-session-${safeSessionId}`;\n  const progressFile = `${sessionDir}/issue-progress.json`;\n\n  // Check if progress file exists\n  if (!existsSync(progressFile)) {\n    logHook('issue-work-summary', `No progress file found at ${progressFile}`);\n    return outputSilentSuccess();\n  }\n\n  // Check if gh CLI is available\n  if (!isGhAvailable()) {\n    logHook('issue-work-summary', 'gh CLI not available or not authenticated, skipping');\n    return outputSilentSuccess();\n  }\n\n  // Check if we're in a GitHub repo\n  if (!isGitHubRepo(projectDir)) {\n    logHook('issue-work-summary', 'Not a GitHub repository, skipping');\n    return outputSilentSuccess();\n  }\n\n  // Read progress file\n  let progressJson: IssueProgress;\n  try {\n    progressJson = JSON.parse(readFileSync(progressFile, 'utf-8'));\n  } catch {\n    logHook('issue-work-summary', 'Failed to read progress file');\n    return outputSilentSuccess();\n  }\n\n  const issues = progressJson.issues ? Object.keys(progressJson.issues) : [];\n  if (issues.length === 0) {\n    logHook('issue-work-summary', 'No issues to process');\n    return outputSilentSuccess();\n  }\n\n  // Process each issue\n  let postedCount = 0;\n  for (const issueNum of issues) {\n    const issueData = progressJson.issues[issueNum];\n    const commits = issueData.commits || [];\n\n    if (commits.length === 0) {\n      logHook('issue-work-summary', `No commits for issue #${issueNum}, skipping`);\n      continue;\n    }\n\n    // Verify issue exists\n    try {\n      execSync(`gh issue view ${issueNum} --json number`, {\n        encoding: 'utf8',\n        timeout: 10000,\n        stdio: ['pipe', 'pipe', 'pipe'],\n      });\n    } catch {\n      logHook('issue-work-summary', `Issue #${issueNum} not found or not accessible, skipping`);\n      continue;\n    }\n\n    // Generate and post comment\n    const comment = generateComment(issueNum, issueData, sessionId);\n    if (comment && postComment(issueNum, comment)) {\n      postedCount++;\n      logHook('issue-work-summary', `Successfully posted comment to issue #${issueNum}`);\n    }\n  }\n\n  logHook('issue-work-summary', `Posted progress comments to ${postedCount} issue(s)`);\n\n  // Clean up progress file\n  try {\n    unlinkSync(progressFile);\n    // Remove session dir if empty\n    try {\n      rmdirSync(sessionDir);\n    } catch {\n      // Directory not empty, leave it\n    }\n    logHook('issue-work-summary', 'Cleaned up progress file');\n  } catch {\n    // Ignore cleanup errors\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Mem0 Pre-Compaction Sync Hook\n * Prompts Claude to save important session context to Mem0 before compaction\n *\n * Features:\n * - Graph memory support\n * - Pending pattern sync\n * - Session summaries\n * - Batch operations for efficiency\n */\n\nimport { existsSync, readFileSync, mkdirSync, appendFileSync, writeFileSync } from 'node:fs';\nimport { spawn } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, getPluginRoot, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Count pending decisions not yet synced\n */\nfunction countPendingDecisions(decisionLog: string, syncState: string): number {\n  if (!existsSync(decisionLog)) {\n    return 0;\n  }\n\n  try {\n    const decisions = JSON.parse(readFileSync(decisionLog, 'utf-8'));\n    const decisionList = decisions.decisions || [];\n\n    if (existsSync(syncState)) {\n      const state = JSON.parse(readFileSync(syncState, 'utf-8'));\n      const syncedIds = state.synced_decisions || [];\n      return decisionList.filter((d: { decision_id: string }) => !syncedIds.includes(d.decision_id)).length;\n    }\n\n    return decisionList.length;\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Count pending patterns\n */\nfunction countPendingPatterns(patternsLog: string): { count: number; patterns: unknown[] } {\n  if (!existsSync(patternsLog)) {\n    return { count: 0, patterns: [] };\n  }\n\n  try {\n    const content = readFileSync(patternsLog, 'utf-8');\n    // Try parsing as JSONL (one object per line) or single JSON\n    let patterns: unknown[];\n    try {\n      patterns = content\n        .split('\\n')\n        .filter((line) => line.trim())\n        .map((line) => JSON.parse(line));\n    } catch {\n      patterns = [JSON.parse(content)];\n    }\n\n    const pending = patterns.filter((p: any) => p.pending_sync === true);\n    return { count: pending.length, patterns: pending };\n  } catch {\n    return { count: 0, patterns: [] };\n  }\n}\n\n/**\n * Get project ID from directory\n */\nfunction getProjectId(projectDir: string): string {\n  return projectDir.split('/').pop() || 'project';\n}\n\n/**\n * Extract session state info\n */\nfunction extractSessionInfo(projectDir: string): {\n  currentTask: string;\n  blockers: string;\n  nextSteps: string;\n} {\n  let currentTask = '';\n  let blockers = '';\n  let nextSteps = '';\n\n  const sessionState = `${projectDir}/.claude/context/session/state.json`;\n  if (existsSync(sessionState)) {\n    try {\n      const state = JSON.parse(readFileSync(sessionState, 'utf-8'));\n      currentTask = state.current_task || state.task || '';\n    } catch {\n      // Ignore\n    }\n  }\n\n  const blockersLog = `${projectDir}/.claude/logs/blockers.jsonl`;\n  if (existsSync(blockersLog)) {\n    try {\n      const content = readFileSync(blockersLog, 'utf-8');\n      const lines = content\n        .split('\\n')\n        .filter((line) => line.trim())\n        .map((line) => JSON.parse(line));\n      const unresolvedBlockers = lines.filter((b) => !b.resolved).slice(-5);\n      blockers = unresolvedBlockers.map((b) => b.description || '').join('; ');\n    } catch {\n      // Ignore\n    }\n  }\n\n  return { currentTask, blockers, nextSteps };\n}\n\n/**\n * Mem0 pre-compaction sync hook\n */\nexport function mem0PreCompactionSync(input: HookInput): HookResult {\n  // Gate: Skip entirely if mem0 is not configured\n  if (!process.env.MEM0_API_KEY) {\n    logHook('mem0-pre-compaction-sync', 'Mem0 not configured (no MEM0_API_KEY), skipping');\n    return outputSilentSuccess();\n  }\n\n  const projectDir = input.project_dir || getProjectDir();\n  const pluginRoot = getPluginRoot();\n\n  const decisionLog = `${pluginRoot}/.claude/coordination/decision-log.json`;\n  const patternsLog = `${projectDir}/.claude/logs/agent-patterns.jsonl`;\n  const syncState = `${pluginRoot}/.claude/coordination/.decision-sync-state.json`;\n\n  // Count pending items\n  const decisionCount = countPendingDecisions(decisionLog, syncState);\n  const { count: patternCount, patterns: pendingPatterns } = countPendingPatterns(patternsLog);\n\n  // Extract session info\n  const { currentTask, blockers, nextSteps } = extractSessionInfo(projectDir);\n\n  // If nothing to sync, silent exit\n  if (decisionCount === 0 && patternCount === 0 && !currentTask) {\n    return outputSilentSuccess();\n  }\n\n  const projectId = getProjectId(projectDir);\n  const logFile = `${projectDir}/.claude/logs/mem0-sync.log`;\n\n  // Ensure log directory exists\n  try {\n    mkdirSync(`${projectDir}/.claude/logs`, { recursive: true });\n  } catch {\n    // Ignore\n  }\n\n  // Build summary message parts\n  const msgParts: string[] = [];\n  if (decisionCount > 0) {\n    msgParts.push(`${decisionCount} decisions to sync`);\n  }\n  if (patternCount > 0) {\n    msgParts.push(`${patternCount} agent patterns pending`);\n\n    // Extract unique agents\n    const agentSet = new Set(pendingPatterns.map((p: any) => p.agent_id || p.agent).filter(Boolean));\n    const uniqueAgents = Array.from(agentSet).slice(0, 5);\n    if (uniqueAgents.length > 0) {\n      msgParts.push(`agents: ${uniqueAgents.join(', ')}`);\n    }\n  }\n\n  const summary = msgParts.length > 0 ? msgParts.join('; ') : 'No pending items';\n\n  // Build session text\n  let summaryText = currentTask || 'Session work';\n  if (decisionCount > 0) {\n    summaryText += ` (${decisionCount} decisions made)`;\n  }\n  if (patternCount > 0) {\n    summaryText += ` (${patternCount} patterns learned)`;\n  }\n\n  let sessionText = `Session Summary: ${summaryText}`;\n  if (blockers) {\n    sessionText += ` | Blockers: ${blockers}`;\n  }\n  if (nextSteps) {\n    sessionText += ` | Next: ${nextSteps}`;\n  }\n\n  // Try auto-sync if MEM0_API_KEY is available\n  const scriptPath = `${pluginRoot}/skills/mem0-memory/scripts/crud/add-memory.py`;\n  const mem0ApiKey = process.env.MEM0_API_KEY;\n\n  let skillMsg: string;\n\n  if (existsSync(scriptPath) && mem0ApiKey) {\n    const timestamp = new Date().toISOString();\n    try {\n      appendFileSync(logFile, `[${timestamp}] Auto-sync triggered for session summary\\n`);\n    } catch {\n      // Ignore\n    }\n\n    // Execute sync in background (non-blocking)\n    const sessionMetadata = JSON.stringify({\n      type: 'session_summary',\n      status: 'in_progress',\n      project: projectId,\n      has_blockers: !!blockers,\n      has_next_steps: !!nextSteps,\n      source: 'orchestkit-plugin',\n    });\n\n    const child = spawn(\n      'python3',\n      [\n        scriptPath,\n        '--text',\n        sessionText,\n        '--user-id',\n        `${projectId}-continuity`,\n        '--metadata',\n        sessionMetadata,\n        '--enable-graph',\n      ],\n      {\n        detached: true,\n        stdio: ['ignore', 'pipe', 'pipe'],\n      }\n    );\n\n    child.on('error', (err) => {\n      const errTimestamp = new Date().toISOString();\n      try {\n        appendFileSync(logFile, `[${errTimestamp}] Sync child process error: ${err.message}\\n`);\n      } catch {\n        // Best-effort logging\n      }\n    });\n\n    child.on('close', (code) => {\n      const closeTimestamp = new Date().toISOString();\n      try {\n        if (code === 0) {\n          appendFileSync(logFile, `[${closeTimestamp}] Sync completed successfully\\n`);\n        } else {\n          appendFileSync(logFile, `[${closeTimestamp}] Sync exited with code ${code}\\n`);\n        }\n      } catch {\n        // Best-effort logging\n      }\n    });\n\n    if (child.stderr) {\n      let stderrData = '';\n      child.stderr.on('data', (chunk: Buffer) => {\n        stderrData += chunk.toString();\n      });\n      child.stderr.on('end', () => {\n        if (stderrData.trim()) {\n          const errTimestamp = new Date().toISOString();\n          try {\n            appendFileSync(logFile, `[${errTimestamp}] Sync stderr: ${stderrData.trim()}\\n`);\n          } catch {\n            // Best-effort logging\n          }\n        }\n      });\n    }\n\n    child.unref();\n\n    // Mark patterns as synced\n    if (patternCount > 0 && existsSync(patternsLog)) {\n      try {\n        const content = readFileSync(patternsLog, 'utf-8');\n        const updated = content\n          .split('\\n')\n          .filter((line) => line.trim())\n          .map((line) => {\n            const obj = JSON.parse(line);\n            obj.pending_sync = false;\n            return JSON.stringify(obj);\n          })\n          .join('\\n');\n        writeFileSync(patternsLog, updated);\n      } catch {\n        // Ignore\n      }\n    }\n\n    skillMsg = `[Mem0 Sync] Auto-synced: ${summary}`;\n  } else {\n    skillMsg = `[Mem0 Sync] ${summary} - Execute /mem0-sync to persist session context`;\n  }\n\n  logHook('mem0-pre-compaction-sync', skillMsg);\n\n  return {\n    continue: true,\n    systemMessage: skillMsg,\n  };\n}\n", "/**\n * Multi-Instance Cleanup Hook\n * Runs on session stop to release locks and update instance status\n * CC 2.1.7 Compliant: JSON output on all exit paths\n */\n\nimport { existsSync, readFileSync, unlinkSync, rmdirSync, readdirSync, rmSync } from 'node:fs';\nimport { execSync, spawn } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\n/**\n * Execute SQLite command\n */\nfunction runSqlite(dbPath: string, sql: string): void {\n  try {\n    execSync(`sqlite3 \"${dbPath}\" \"${sql}\"`, {\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n  } catch {\n    // Ignore SQLite errors\n  }\n}\n\n/**\n * Check if table exists\n */\nfunction hasTable(dbPath: string, tableName: string): boolean {\n  try {\n    const result = execSync(\n      `sqlite3 \"${dbPath}\" \"SELECT count(*) FROM sqlite_master WHERE type='table' AND name='${tableName}';\"`,\n      { encoding: 'utf8', timeout: 5000, stdio: ['pipe', 'pipe', 'pipe'] }\n    ).trim();\n    return result === '1';\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Stop heartbeat process\n */\nfunction stopHeartbeat(instanceDir: string): void {\n  const pidFile = `${instanceDir}/heartbeat.pid`;\n  if (!existsSync(pidFile)) {\n    return;\n  }\n\n  try {\n    const pid = parseInt(readFileSync(pidFile, 'utf-8').trim(), 10);\n    try {\n      process.kill(pid, 0); // Check if process exists\n      process.kill(pid); // Kill it\n      logHook('multi-instance-cleanup', `Stopped heartbeat process (PID: ${pid})`);\n    } catch {\n      // Process doesn't exist\n    }\n    unlinkSync(pidFile);\n  } catch {\n    // Ignore errors\n  }\n}\n\n/**\n * Release all locks held by this instance\n */\nfunction releaseLocks(dbPath: string, instanceId: string): void {\n  logHook('multi-instance-cleanup', 'Releasing all locks...');\n  runSqlite(dbPath, `DELETE FROM file_locks WHERE instance_id = '${instanceId}';`);\n  logHook('multi-instance-cleanup', 'All locks released');\n}\n\n/**\n * Handle work claims\n */\nfunction handleWorkClaims(dbPath: string, instanceId: string): void {\n  logHook('multi-instance-cleanup', 'Handling work claims...');\n\n  if (hasTable(dbPath, 'work_claims')) {\n    runSqlite(\n      dbPath,\n      `UPDATE work_claims SET status = 'abandoned', completed_at = datetime('now') WHERE instance_id = '${instanceId}' AND status = 'active';`\n    );\n    logHook('multi-instance-cleanup', 'Work claims handled');\n  } else {\n    logHook('multi-instance-cleanup', 'No work_claims table, skipping');\n  }\n}\n\n/**\n * Update instance status\n */\nfunction updateInstanceStatus(dbPath: string, instanceId: string): void {\n  if (hasTable(dbPath, 'instances')) {\n    runSqlite(\n      dbPath,\n      `UPDATE instances SET status = 'terminated', last_heartbeat = datetime('now') WHERE id = '${instanceId}';`\n    );\n    logHook('multi-instance-cleanup', 'Instance status updated to terminated');\n  } else {\n    logHook('multi-instance-cleanup', 'No instances table, skipping status update');\n  }\n}\n\n/**\n * Broadcast shutdown message\n */\nfunction broadcastShutdown(dbPath: string, instanceId: string): void {\n  if (!hasTable(dbPath, 'messages')) {\n    logHook('multi-instance-cleanup', 'No messages table, skipping broadcast');\n    return;\n  }\n\n  const messageId = `msg-${Math.random().toString(36).slice(2, 18)}`;\n  const timestamp = new Date().toISOString();\n  const payload = JSON.stringify({ instance_id: instanceId, timestamp }).replace(/'/g, \"''\");\n\n  runSqlite(\n    dbPath,\n    `INSERT INTO messages (message_id, from_instance, to_instance, message_type, payload, expires_at) VALUES ('${messageId}', '${instanceId}', NULL, 'shutdown', '${payload}', datetime('now', '+1 hour'));`\n  );\n  logHook('multi-instance-cleanup', 'Shutdown broadcast sent');\n}\n\n/**\n * Cleanup instance-specific files\n */\nfunction cleanupInstanceFiles(instanceDir: string): void {\n  const filesToRemove = ['knowledge_cache.json', 'claims.json', 'session_discoveries.json'];\n\n  for (const file of filesToRemove) {\n    const filePath = `${instanceDir}/${file}`;\n    try {\n      if (existsSync(filePath)) {\n        unlinkSync(filePath);\n      }\n    } catch {\n      // Ignore\n    }\n  }\n\n  logHook('multi-instance-cleanup', 'Instance files cleaned up');\n}\n\n/**\n * Multi-instance cleanup hook\n */\nexport function multiInstanceCleanup(input: HookInput): HookResult {\n  const projectDir = input.project_dir || getProjectDir();\n  const instanceDir = `${projectDir}/.instance`;\n  const dbPath = `${projectDir}/.claude/coordination/.claude.db`;\n\n  // Check if coordination is enabled\n  if (!existsSync(dbPath)) {\n    logHook('multi-instance-cleanup', 'No coordination database, skipping cleanup');\n    return outputSilentSuccess();\n  }\n\n  // Check if we have instance identity\n  const idFile = `${instanceDir}/id.json`;\n  if (!existsSync(idFile)) {\n    logHook('multi-instance-cleanup', 'No instance identity, skipping cleanup');\n    return outputSilentSuccess();\n  }\n\n  // Get instance ID\n  let instanceId: string;\n  try {\n    const idData = JSON.parse(readFileSync(idFile, 'utf-8'));\n    instanceId = idData.instance_id;\n  } catch {\n    logHook('multi-instance-cleanup', 'Failed to read instance ID');\n    return outputSilentSuccess();\n  }\n\n  logHook('multi-instance-cleanup', `Starting multi-instance cleanup for ${instanceId}...`);\n\n  // Stop heartbeat first\n  stopHeartbeat(instanceDir);\n\n  // Release all locks\n  releaseLocks(dbPath, instanceId);\n\n  // Handle work claims\n  handleWorkClaims(dbPath, instanceId);\n\n  // Broadcast shutdown\n  broadcastShutdown(dbPath, instanceId);\n\n  // Update status\n  updateInstanceStatus(dbPath, instanceId);\n\n  // Cleanup files\n  cleanupInstanceFiles(instanceDir);\n\n  logHook('multi-instance-cleanup', '=== Cleanup Summary ===');\n  logHook('multi-instance-cleanup', `Instance: ${instanceId}`);\n  logHook('multi-instance-cleanup', 'Status: terminated');\n  logHook('multi-instance-cleanup', 'Multi-instance cleanup completed');\n\n  return outputSilentSuccess();\n}\n", "/**\n * Security Scan Aggregator - Stop Hook\n * CC 2.1.3 Compliant - Uses 10-minute hook timeout\n *\n * Runs multiple security tools in parallel and aggregates results.\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync, readdirSync } from 'node:fs';\nimport { execSync } from 'node:child_process';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, outputSilentSuccess } from '../lib/common.js';\n\ninterface SecurityResults {\n  npmAudit: { critical: number; high: number } | null;\n  pipAudit: number | null;\n  semgrep: number | null;\n  bandit: number | null;\n  secrets: number;\n}\n\n/**\n * Run npm audit\n */\nfunction runNpmAudit(projectDir: string, resultsDir: string): { critical: number; high: number } | null {\n  if (\n    !existsSync(`${projectDir}/package.json`) ||\n    (!existsSync(`${projectDir}/package-lock.json`) &&\n      !existsSync(`${projectDir}/yarn.lock`) &&\n      !existsSync(`${projectDir}/pnpm-lock.yaml`))\n  ) {\n    return null;\n  }\n\n  logHook('security-scan', 'Running npm audit...');\n  try {\n    execSync('npm audit --json', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 120000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n  } catch (error: any) {\n    // npm audit returns non-zero on vulnerabilities, capture output\n    if (error.stdout) {\n      writeFileSync(`${resultsDir}/npm-audit.json`, error.stdout);\n      try {\n        const result = JSON.parse(error.stdout);\n        return {\n          critical: result.metadata?.vulnerabilities?.critical || 0,\n          high: result.metadata?.vulnerabilities?.high || 0,\n        };\n      } catch {\n        // Ignore parse errors\n      }\n    }\n  }\n  logHook('security-scan', 'npm audit complete');\n  return { critical: 0, high: 0 };\n}\n\n/**\n * Run pip-audit\n */\nfunction runPipAudit(projectDir: string, resultsDir: string): number | null {\n  if (!existsSync(`${projectDir}/requirements.txt`) && !existsSync(`${projectDir}/pyproject.toml`)) {\n    return null;\n  }\n\n  try {\n    execSync('which pip-audit', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n  } catch {\n    logHook('security-scan', 'pip-audit not installed, skipping');\n    return null;\n  }\n\n  logHook('security-scan', 'Running pip-audit...');\n  try {\n    const result = execSync('pip-audit --format json', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 120000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    writeFileSync(`${resultsDir}/pip-audit.json`, result);\n    const parsed = JSON.parse(result);\n    logHook('security-scan', 'pip-audit complete');\n    return Array.isArray(parsed) ? parsed.length : 0;\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Run semgrep\n */\nfunction runSemgrep(projectDir: string, resultsDir: string): number | null {\n  try {\n    execSync('which semgrep', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n  } catch {\n    logHook('security-scan', 'semgrep not installed, skipping');\n    return null;\n  }\n\n  logHook('security-scan', 'Running semgrep...');\n  try {\n    const result = execSync('semgrep --config auto --json --quiet', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 300000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    writeFileSync(`${resultsDir}/semgrep.json`, result);\n    const parsed = JSON.parse(result);\n    const highSeverity = (parsed.results || []).filter((r: any) => r.extra?.severity === 'ERROR').length;\n    logHook('security-scan', 'semgrep complete');\n    return highSeverity;\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Run bandit\n */\nfunction runBandit(projectDir: string, resultsDir: string): number | null {\n  // Check for Python files\n  try {\n    const hasPython = execSync('find . -name \"*.py\" -maxdepth 2 | head -1', {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 5000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    }).trim();\n    if (!hasPython && !existsSync(`${projectDir}/backend`)) {\n      return null;\n    }\n  } catch {\n    return null;\n  }\n\n  try {\n    execSync('which bandit', { encoding: 'utf8', stdio: ['pipe', 'pipe', 'pipe'] });\n  } catch {\n    logHook('security-scan', 'bandit not installed, skipping');\n    return null;\n  }\n\n  logHook('security-scan', 'Running bandit...');\n  try {\n    execSync(`bandit -r . -f json -o ${resultsDir}/bandit.json`, {\n      cwd: projectDir,\n      encoding: 'utf8',\n      timeout: 120000,\n      stdio: ['pipe', 'pipe', 'pipe'],\n    });\n    logHook('security-scan', 'bandit complete');\n    return 0;\n  } catch {\n    // Bandit exits non-zero when issues found\n    return 0;\n  }\n}\n\n/**\n * Run secret detection\n */\nfunction runSecretScan(projectDir: string, resultsDir: string): number {\n  logHook('security-scan', 'Running secret detection...');\n\n  const secretPatterns = /(api[_-]?key|secret[_-]?key|password|token)\\s*[=:]\\s*[\"'][^\"']{8,}/i;\n  let secretsFound = 0;\n  const findings: Array<{ file: string; type: string }> = [];\n\n  const extensions = ['.py', '.js', '.ts', '.env'];\n\n  function scanDir(dir: string): void {\n    try {\n      const entries = readdirSync(dir, { withFileTypes: true });\n      for (const entry of entries) {\n        const fullPath = `${dir}/${entry.name}`;\n\n        // Skip node_modules and .git\n        if (entry.isDirectory()) {\n          if (!['node_modules', '.git', 'dist', 'build'].includes(entry.name)) {\n            scanDir(fullPath);\n          }\n          continue;\n        }\n\n        // Check file extension\n        if (!extensions.some((ext) => entry.name.endsWith(ext))) {\n          continue;\n        }\n\n        try {\n          const content = readFileSync(fullPath, 'utf-8');\n          if (secretPatterns.test(content)) {\n            findings.push({ file: fullPath, type: 'potential_secret' });\n            secretsFound++;\n          }\n        } catch {\n          // Ignore read errors\n        }\n      }\n    } catch {\n      // Ignore directory errors\n    }\n  }\n\n  scanDir(projectDir);\n\n  writeFileSync(\n    `${resultsDir}/secrets.json`,\n    JSON.stringify({ findings, count: secretsFound }, null, 2)\n  );\n\n  logHook('security-scan', `Secret detection complete: ${secretsFound} potential issues`);\n  return secretsFound;\n}\n\n/**\n * Aggregate results\n */\nfunction aggregateResults(resultsDir: string, results: SecurityResults): void {\n  logHook('security-scan', 'Aggregating results...');\n\n  let totalCritical = 0;\n  let totalHigh = 0;\n\n  if (results.npmAudit) {\n    totalCritical += results.npmAudit.critical;\n    totalHigh += results.npmAudit.high;\n  }\n  if (results.pipAudit !== null) {\n    totalHigh += results.pipAudit;\n  }\n  if (results.semgrep !== null) {\n    totalHigh += results.semgrep;\n  }\n\n  const scansCompleted = readdirSync(resultsDir)\n    .filter((f) => f.endsWith('.json') && !f.includes('aggregated'))\n    .map((f) => f.replace('.json', ''));\n\n  const report = {\n    timestamp: new Date().toISOString(),\n    summary: {\n      critical: totalCritical,\n      high: totalHigh,\n      medium: 0,\n    },\n    scans_completed: scansCompleted,\n  };\n\n  writeFileSync(`${resultsDir}/aggregated-report.json`, JSON.stringify(report, null, 2));\n\n  logHook('security-scan', '=== Security Scan Complete ===');\n  logHook('security-scan', `Critical: ${totalCritical}, High: ${totalHigh}`);\n\n  if (totalCritical > 0) {\n    console.error(`Security: ${totalCritical} critical, ${totalHigh} high vulnerabilities found`);\n  }\n}\n\n/**\n * Security scan aggregator hook\n */\nexport function securityScanAggregator(input: HookInput): HookResult {\n  logHook('security-scan', '=== Security Scan Started ===');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const resultsDir = `${projectDir}/.claude/hooks/logs/security`;\n\n  mkdirSync(resultsDir, { recursive: true });\n\n  const results: SecurityResults = {\n    npmAudit: null,\n    pipAudit: null,\n    semgrep: null,\n    bandit: null,\n    secrets: 0,\n  };\n\n  // Run scans (sequentially in TS to avoid complexity, but could be parallelized)\n  results.npmAudit = runNpmAudit(projectDir, resultsDir);\n  results.pipAudit = runPipAudit(projectDir, resultsDir);\n  results.semgrep = runSemgrep(projectDir, resultsDir);\n  results.bandit = runBandit(projectDir, resultsDir);\n  results.secrets = runSecretScan(projectDir, resultsDir);\n\n  // Aggregate results\n  aggregateResults(resultsDir, results);\n\n  return outputSilentSuccess();\n}\n", "/**\n * Session Patterns - Unified pattern learning at session end\n * Part of OrchestKit Plugin - Cross-Project Patterns (#48) + Best Practices (#49)\n *\n * This hook processes patterns at session end:\n * 1. Extracts workflow patterns (tool sequences, workflow types, languages)\n * 2. Merges queued patterns into learned-patterns.json\n * 3. Syncs to mem0 for cross-project learning\n * 4. Updates workflow profile for session analytics\n *\n * CC 2.1.7 Compliant: Uses suppressOutput for silent operation\n */\n\nimport { existsSync, mkdirSync, readFileSync, writeFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, getPluginRoot, getSessionId, outputSilentSuccess } from '../lib/common.js';\n\ninterface WorkflowProfile {\n  version: string;\n  last_updated: string | null;\n  sessions_count: number;\n  workflow_types: Record<string, number>;\n  common_tool_sequences: string[];\n  dominant_languages: Record<string, number>;\n  average_tools_per_session: number;\n  average_session_duration_seconds: number;\n  tool_frequency: Record<string, number>;\n}\n\ninterface LearnedPatterns {\n  version: string;\n  updated: string;\n  patterns: Array<{\n    text: string;\n    outcome: string;\n    category: string;\n    timestamp: string;\n  }>;\n  categories: Record<string, number>;\n  stats: {\n    total: number;\n    successes: number;\n    failures: number;\n  };\n}\n\ninterface SessionMetrics {\n  tools?: Record<string, number>;\n}\n\n/**\n * Extract tool usage sequence from session metrics\n */\nfunction extractToolSequence(metricsFile: string): string {\n  if (!existsSync(metricsFile)) {\n    return '';\n  }\n\n  try {\n    const metrics: SessionMetrics = JSON.parse(readFileSync(metricsFile, 'utf-8'));\n    const tools = metrics.tools || {};\n    const sorted = Object.entries(tools)\n      .sort(([, a], [, b]) => b - a)\n      .slice(0, 10)\n      .map(([tool]) => tool);\n    return sorted.join(',');\n  } catch {\n    return '';\n  }\n}\n\n/**\n * Get total tool invocations from metrics\n */\nfunction getToolCount(metricsFile: string): number {\n  if (!existsSync(metricsFile)) {\n    return 0;\n  }\n\n  try {\n    const metrics: SessionMetrics = JSON.parse(readFileSync(metricsFile, 'utf-8'));\n    const tools = metrics.tools || {};\n    return Object.values(tools).reduce((sum, count) => sum + count, 0);\n  } catch {\n    return 0;\n  }\n}\n\n/**\n * Detect workflow type based on tool usage patterns\n */\nfunction detectWorkflowType(tools: string): string {\n  if (tools.includes('Write') && tools.includes('Bash')) {\n    if (/test|pytest|jest|vitest/i.test(tools)) {\n      return 'test-driven-development';\n    }\n  }\n\n  if (tools.includes('Read') && tools.includes('Grep')) {\n    return 'code-exploration';\n  }\n\n  if (tools.includes('Edit') && !tools.includes('Write')) {\n    return 'refactoring';\n  }\n\n  if (tools.includes('Write') && tools.includes('Read')) {\n    return 'feature-development';\n  }\n\n  if (tools.includes('Bash') && /git|gh/i.test(tools)) {\n    return 'git-operations';\n  }\n\n  return 'general';\n}\n\n/**\n * Detect dominant language from tool sequence (simplified)\n */\nfunction detectDominantLanguage(tools: string): string {\n  // In a real implementation, this would analyze file extensions from hook logs\n  // For now, return 'unknown' as we don't have file access patterns in TS\n  return 'unknown';\n}\n\n/**\n * Initialize workflow profile if needed\n */\nfunction initWorkflowProfile(profilePath: string): WorkflowProfile {\n  if (existsSync(profilePath)) {\n    try {\n      return JSON.parse(readFileSync(profilePath, 'utf-8'));\n    } catch {\n      // Fall through to create new\n    }\n  }\n\n  return {\n    version: '1.0.0',\n    last_updated: null,\n    sessions_count: 0,\n    workflow_types: {\n      'test-driven-development': 0,\n      'code-exploration': 0,\n      refactoring: 0,\n      'feature-development': 0,\n      'git-operations': 0,\n      general: 0,\n    },\n    common_tool_sequences: [],\n    dominant_languages: {\n      python: 0,\n      typescript: 0,\n      javascript: 0,\n      go: 0,\n      rust: 0,\n      unknown: 0,\n    },\n    average_tools_per_session: 0,\n    average_session_duration_seconds: 0,\n    tool_frequency: {},\n  };\n}\n\n/**\n * Update workflow profile with session data\n */\nfunction updateWorkflowProfile(\n  profilePath: string,\n  workflowType: string,\n  dominantLang: string,\n  toolCount: number,\n  toolSequence: string\n): void {\n  const profile = initWorkflowProfile(profilePath);\n  const timestamp = new Date().toISOString();\n\n  profile.last_updated = timestamp;\n  profile.sessions_count += 1;\n\n  // Update workflow type counts\n  profile.workflow_types[workflowType] = (profile.workflow_types[workflowType] || 0) + 1;\n\n  // Update dominant language counts\n  profile.dominant_languages[dominantLang] = (profile.dominant_languages[dominantLang] || 0) + 1;\n\n  // Update running averages\n  profile.average_tools_per_session =\n    (profile.average_tools_per_session * (profile.sessions_count - 1) + toolCount) / profile.sessions_count;\n\n  // Add tool sequence if meaningful\n  const sequenceTools = toolSequence.split(',').filter(Boolean);\n  if (sequenceTools.length > 2) {\n    const seqSet = new Set([toolSequence, ...profile.common_tool_sequences]);\n    profile.common_tool_sequences = Array.from(seqSet).slice(0, 20);\n  }\n\n  mkdirSync(profilePath.replace(/\\/[^/]+$/, ''), { recursive: true });\n  writeFileSync(profilePath, JSON.stringify(profile, null, 2));\n}\n\n/**\n * Initialize learned patterns file if needed\n */\nfunction initPatternsFile(patternsPath: string): LearnedPatterns {\n  if (existsSync(patternsPath)) {\n    try {\n      return JSON.parse(readFileSync(patternsPath, 'utf-8'));\n    } catch {\n      // Fall through to create new\n    }\n  }\n\n  return {\n    version: '1.0',\n    updated: '',\n    patterns: [],\n    categories: {},\n    stats: {\n      total: 0,\n      successes: 0,\n      failures: 0,\n    },\n  };\n}\n\n/**\n * Merge queued patterns into learned patterns file\n */\nfunction mergePatterns(projectDir: string): void {\n  const queuePath = `${projectDir}/.claude/feedback/patterns-queue.json`;\n  const patternsPath = `${projectDir}/.claude/feedback/learned-patterns.json`;\n\n  if (!existsSync(queuePath)) {\n    logHook('session-patterns', 'No patterns queue found');\n    return;\n  }\n\n  let queue: { patterns: LearnedPatterns['patterns'] };\n  try {\n    queue = JSON.parse(readFileSync(queuePath, 'utf-8'));\n  } catch {\n    logHook('session-patterns', 'Failed to parse patterns queue');\n    return;\n  }\n\n  const queueCount = queue.patterns?.length || 0;\n  if (queueCount === 0) {\n    logHook('session-patterns', 'Patterns queue is empty');\n    return;\n  }\n\n  logHook('session-patterns', `Processing ${queueCount} queued patterns...`);\n\n  const existing = initPatternsFile(patternsPath);\n  const now = new Date().toISOString();\n\n  // Merge and deduplicate patterns by text (keep most recent)\n  const allPatterns = [...existing.patterns, ...queue.patterns];\n  const patternMap = new Map<string, (typeof allPatterns)[0]>();\n  for (const p of allPatterns) {\n    patternMap.set(p.text, p);\n  }\n  const mergedPatterns = Array.from(patternMap.values());\n\n  // Calculate stats\n  const successes = mergedPatterns.filter((p) => p.outcome === 'success').length;\n  const failures = mergedPatterns.filter((p) => p.outcome === 'failed').length;\n\n  // Group by category\n  const categories: Record<string, number> = {};\n  for (const p of mergedPatterns) {\n    categories[p.category] = (categories[p.category] || 0) + 1;\n  }\n\n  const updated: LearnedPatterns = {\n    version: '1.0',\n    updated: now,\n    patterns: mergedPatterns,\n    categories,\n    stats: {\n      total: mergedPatterns.length,\n      successes,\n      failures,\n    },\n  };\n\n  mkdirSync(patternsPath.replace(/\\/[^/]+$/, ''), { recursive: true });\n  writeFileSync(patternsPath, JSON.stringify(updated, null, 2));\n  logHook('session-patterns', 'Merged patterns successfully');\n\n  // Clear the queue\n  writeFileSync(queuePath, JSON.stringify({ patterns: [] }));\n}\n\n/**\n * Session patterns hook\n */\nexport function sessionPatterns(input: HookInput): HookResult {\n  logHook('session-patterns', 'Session ending, processing patterns...');\n\n  const projectDir = input.project_dir || getProjectDir();\n  const metricsFile = '/tmp/claude-session-metrics.json';\n  const workflowProfile = `${projectDir}/.claude/feedback/workflow-patterns.json`;\n\n  // Ensure directories exist\n  mkdirSync(`${projectDir}/.claude/feedback`, { recursive: true });\n  mkdirSync(`${projectDir}/.claude/logs`, { recursive: true });\n\n  // 1. Process workflow patterns\n  const toolCount = getToolCount(metricsFile);\n\n  if (toolCount >= 5) {\n    const toolSequence = extractToolSequence(metricsFile);\n    const workflowType = detectWorkflowType(toolSequence);\n    const dominantLang = detectDominantLanguage(toolSequence);\n\n    updateWorkflowProfile(workflowProfile, workflowType, dominantLang, toolCount, toolSequence);\n\n    logHook('session-patterns', `Workflow analyzed: type=${workflowType} lang=${dominantLang} tools=${toolCount}`);\n  } else {\n    logHook('session-patterns', `Session too short for workflow analysis (tools: ${toolCount})`);\n  }\n\n  // 2. Merge queued patterns\n  mergePatterns(projectDir);\n\n  logHook('session-patterns', 'Pattern processing complete');\n\n  return outputSilentSuccess();\n}\n", "/**\n * Task Completion Check - Verifies tasks are properly completed before stop\n * Hook: Stop\n * CC 2.1.20: Orphan detection and deletion support\n */\n\nimport { existsSync, readFileSync } from 'node:fs';\nimport type { HookInput, HookResult } from '../types.js';\nimport { logHook, getProjectDir, getSessionId, outputSilentSuccess, outputWithContext } from '../lib/common.js';\nimport { getOrphanedTasks, formatTaskDeleteForClaude } from '../lib/task-integration.js';\n\ninterface TodoItem {\n  status: string;\n  description?: string;\n}\n\n/**\n * Task completion check hook\n */\nexport function taskCompletionCheck(input: HookInput): HookResult {\n  logHook('task-completion-check', 'Stop hook - checking task completion');\n\n  const warnings: string[] = [];\n\n  // CC 2.1.20: Check orchestration registry for in_progress tasks\n  const projectDir = input.project_dir || getProjectDir();\n  const sessionId = input.session_id || getSessionId();\n  const registryFile = `${projectDir}/.claude/orchestration/task-registry-${sessionId}.json`;\n\n  if (existsSync(registryFile)) {\n    try {\n      const registry = JSON.parse(readFileSync(registryFile, 'utf-8'));\n      const inProgress = (registry.tasks || []).filter(\n        (t: { status: string }) => t.status === 'in_progress'\n      );\n      if (inProgress.length > 0) {\n        logHook('task-completion-check', `WARNING: ${inProgress.length} orchestration tasks still in progress`);\n        warnings.push(`${inProgress.length} orchestration task(s) still in progress at session stop`);\n      }\n    } catch (error) {\n      logHook('task-completion-check', `Error reading registry: ${error}`);\n    }\n  }\n\n  // CC 2.1.20: Check for orphaned tasks and generate deletion instructions\n  const orphans = getOrphanedTasks();\n  let orphanInstructions = '';\n  if (orphans.length > 0) {\n    logHook('task-completion-check', `Found ${orphans.length} orphaned tasks`);\n    orphanInstructions = '\\n\\n## Orphaned Tasks\\n\\nThe following tasks are orphaned (all blockers failed) and should be deleted:\\n';\n    for (const orphan of orphans) {\n      orphanInstructions += `\\n${formatTaskDeleteForClaude(orphan.taskId, 'All blocking tasks have failed')}`;\n    }\n  }\n\n  // Legacy fallback: check /tmp/claude-active-todos.json\n  const todosFile = '/tmp/claude-active-todos.json';\n  if (existsSync(todosFile)) {\n    try {\n      const todos: TodoItem[] = JSON.parse(readFileSync(todosFile, 'utf-8'));\n      const inProgress = todos.filter((t) => t.status === 'in_progress');\n      if (inProgress.length > 0) {\n        logHook('task-completion-check', `WARNING: ${inProgress.length} legacy tasks in progress at stop`);\n        warnings.push(`${inProgress.length} legacy task(s) still in progress`);\n      }\n    } catch (error) {\n      logHook('task-completion-check', `Error reading legacy todos: ${error}`);\n    }\n  }\n\n  if (warnings.length > 0 || orphanInstructions) {\n    let context = `## Task Completion Warning\\n\\n${warnings.map(w => `- ${w}`).join('\\n')}`;\n    if (orphanInstructions) {\n      context += orphanInstructions;\n    }\n    return outputWithContext(context);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Task Integration - Bridge to CC 2.1.16 Task Management System\n * Issue #197: Agent Orchestration Layer\n *\n * Provides utilities for:\n * - Generating task creation instructions\n * - Tracking task-to-agent relationships\n * - Managing task state for orchestration\n *\n * Note: This module generates INSTRUCTIONS for Claude to execute\n * task operations, as hooks cannot directly call CC tools.\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport type {\n  TaskCreateInstruction,\n  TaskUpdateInstruction,\n  TaskMetadata,\n  PipelineExecution,\n} from './orchestration-types.js';\n\n// -----------------------------------------------------------------------------\n// Types\n// -----------------------------------------------------------------------------\n\n/** Task tracking entry stored locally */\ninterface TaskEntry {\n  taskId: string;\n  agent: string;\n  confidence: number;\n  createdAt: string;\n  status: 'pending' | 'in_progress' | 'completed' | 'failed';\n  pipelineId?: string;\n  pipelineStep?: number;\n  blockedBy?: string[];\n  blocks?: string[];\n}\n\n/** Task registry for session */\ninterface TaskRegistry {\n  schemaVersion: string;\n  sessionId: string;\n  tasks: TaskEntry[];\n  pipelines: PipelineExecution[];\n  updatedAt: string;\n}\n\n// -----------------------------------------------------------------------------\n// Registry File Management\n// -----------------------------------------------------------------------------\n\nfunction getRegistryFile(): string {\n  const sessionId = getSessionId();\n  return `${getProjectDir()}/.claude/orchestration/task-registry-${sessionId}.json`;\n}\n\nfunction ensureDir(): void {\n  const dir = `${getProjectDir()}/.claude/orchestration`;\n  if (!existsSync(dir)) {\n    try {\n      mkdirSync(dir, { recursive: true });\n    } catch {\n      // Ignore\n    }\n  }\n}\n\nfunction loadRegistry(): TaskRegistry {\n  const file = getRegistryFile();\n\n  if (existsSync(file)) {\n    try {\n      return JSON.parse(readFileSync(file, 'utf8'));\n    } catch {\n      // Return default on error\n    }\n  }\n\n  return {\n    schemaVersion: '1.0.0',\n    sessionId: getSessionId(),\n    tasks: [],\n    pipelines: [],\n    updatedAt: new Date().toISOString(),\n  };\n}\n\nfunction saveRegistry(registry: TaskRegistry): void {\n  ensureDir();\n  const file = getRegistryFile();\n  registry.updatedAt = new Date().toISOString();\n\n  try {\n    writeFileSync(file, JSON.stringify(registry, null, 2));\n  } catch (err) {\n    logHook('task-integration', `Failed to save registry: ${err}`);\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Task Instructions Generators\n// -----------------------------------------------------------------------------\n\n/**\n * Get action-specific activeForm based on agent type\n */\nfunction getActiveFormForAgent(agent: string, description: string): string {\n  const actionMap: Record<string, string> = {\n    'backend-system-architect': 'Designing',\n    'frontend-ui-developer': 'Building',\n    'test-generator': 'Writing tests for',\n    'security-auditor': 'Auditing',\n    'workflow-architect': 'Architecting',\n    'database-engineer': 'Implementing database for',\n    'llm-integrator': 'Integrating LLM for',\n    'code-quality-reviewer': 'Reviewing',\n    'ux-researcher': 'Researching UX for',\n    'product-strategist': 'Strategizing',\n    'debug-investigator': 'Investigating',\n    'performance-engineer': 'Optimizing',\n    'accessibility-specialist': 'Auditing accessibility for',\n    'infrastructure-architect': 'Designing infrastructure for',\n    'data-pipeline-engineer': 'Building pipeline for',\n  };\n\n  const action = actionMap[agent] || 'Working on';\n  const shortDesc = description.slice(0, 40).toLowerCase();\n  return `${action} ${shortDesc}`;\n}\n\n/**\n * Generate TaskCreate instruction for an agent dispatch\n */\nexport function generateTaskCreateInstruction(\n  agent: string,\n  description: string,\n  confidence: number,\n  metadata?: Partial<TaskMetadata>\n): TaskCreateInstruction {\n  const agentTitle = agent\n    .split('-')\n    .map(w => w.charAt(0).toUpperCase() + w.slice(1))\n    .join(' ');\n\n  const fullMetadata: TaskMetadata = {\n    source: 'orchestration',\n    dispatchedAgent: agent,\n    dispatchConfidence: confidence,\n    ...metadata,\n  };\n\n  return {\n    subject: `${agentTitle}: ${description.slice(0, 50)}`,\n    description: `Agent dispatched automatically at ${confidence}% confidence.\\n\\n${description}`,\n    activeForm: getActiveFormForAgent(agent, description),\n    metadata: fullMetadata,\n  };\n}\n\n/**\n * Generate TaskUpdate instruction for status change\n */\nexport function generateTaskUpdateInstruction(\n  taskId: string,\n  status: 'pending' | 'in_progress' | 'completed' | 'deleted',\n  blockedBy?: string[],\n  blocks?: string[]\n): TaskUpdateInstruction {\n  const instruction: TaskUpdateInstruction = {\n    taskId,\n    status,\n  };\n\n  if (blockedBy && blockedBy.length > 0) {\n    instruction.addBlockedBy = blockedBy;\n  }\n\n  if (blocks && blocks.length > 0) {\n    instruction.addBlocks = blocks;\n  }\n\n  return instruction;\n}\n\n/**\n * Format TaskCreate instruction as markdown for Claude\n */\nexport function formatTaskCreateForClaude(instruction: TaskCreateInstruction): string {\n  return `### Create Task for Tracking\n\n\\`\\`\\`\nTaskCreate:\n  subject: \"${instruction.subject}\"\n  description: \"${instruction.description}\"\n  activeForm: \"${instruction.activeForm}\"\n  metadata:\n    source: \"${instruction.metadata.source}\"\n    dispatchedAgent: \"${instruction.metadata.dispatchedAgent || ''}\"\n    dispatchConfidence: ${instruction.metadata.dispatchConfidence || 0}\n\\`\\`\\``;\n}\n\n/**\n * Generate TaskUpdate instruction for task deletion (CC 2.1.20)\n */\nexport function generateTaskDeleteInstruction(\n  taskId: string,\n  _reason: string\n): TaskUpdateInstruction {\n  return {\n    taskId,\n    status: 'deleted',\n  };\n}\n\n/**\n * Format TaskDelete instruction as markdown for Claude (CC 2.1.20)\n */\nexport function formatTaskDeleteForClaude(taskId: string, reason: string): string {\n  return `### Delete Orphaned Task\n\n\\`\\`\\`\nTaskUpdate:\n  taskId: \"${taskId}\"\n  status: \"deleted\"\n\\`\\`\\`\n\n**Reason**: ${reason}`;\n}\n\n/**\n * Format TaskUpdate instruction as markdown for Claude\n */\nexport function formatTaskUpdateForClaude(instruction: TaskUpdateInstruction): string {\n  let md = `### Update Task\n\n\\`\\`\\`\nTaskUpdate:\n  taskId: \"${instruction.taskId}\"`;\n\n  if (instruction.status) {\n    md += `\\n  status: \"${instruction.status}\"`;\n  }\n\n  if (instruction.addBlockedBy && instruction.addBlockedBy.length > 0) {\n    md += `\\n  addBlockedBy: ${JSON.stringify(instruction.addBlockedBy)}`;\n  }\n\n  if (instruction.addBlocks && instruction.addBlocks.length > 0) {\n    md += `\\n  addBlocks: ${JSON.stringify(instruction.addBlocks)}`;\n  }\n\n  md += '\\n```';\n  return md;\n}\n\n// -----------------------------------------------------------------------------\n// Task Tracking Operations\n// -----------------------------------------------------------------------------\n\n/**\n * Register a new task for an agent\n */\nexport function registerTask(\n  taskId: string,\n  agent: string,\n  confidence: number,\n  pipelineId?: string,\n  pipelineStep?: number,\n  blockedBy?: string[],\n  blocks?: string[]\n): void {\n  const registry = loadRegistry();\n\n  // Check for duplicate\n  const existing = registry.tasks.find(t => t.taskId === taskId);\n  if (existing) {\n    logHook('task-integration', `Task ${taskId} already registered`);\n    return;\n  }\n\n  registry.tasks.push({\n    taskId,\n    agent,\n    confidence,\n    createdAt: new Date().toISOString(),\n    status: 'pending',\n    pipelineId,\n    pipelineStep,\n    blockedBy,\n    blocks,\n  });\n\n  saveRegistry(registry);\n  logHook('task-integration', `Registered task ${taskId} for agent ${agent}`);\n}\n\n/**\n * Update task status in registry\n */\nexport function updateTaskStatus(\n  taskId: string,\n  status: TaskEntry['status']\n): void {\n  const registry = loadRegistry();\n\n  const task = registry.tasks.find(t => t.taskId === taskId);\n  if (task) {\n    task.status = status;\n    saveRegistry(registry);\n    logHook('task-integration', `Updated task ${taskId} status to ${status}`);\n  }\n}\n\n/**\n * Get task by agent name\n */\nexport function getTaskByAgent(agent: string): TaskEntry | undefined {\n  const registry = loadRegistry();\n  return registry.tasks.find(\n    t => t.agent === agent && (t.status === 'pending' || t.status === 'in_progress')\n  );\n}\n\n/**\n * Get task by ID\n */\nexport function getTaskById(taskId: string): TaskEntry | undefined {\n  const registry = loadRegistry();\n  return registry.tasks.find(t => t.taskId === taskId);\n}\n\n/**\n * Get pending tasks blocked by a specific failed task (CC 2.1.20)\n */\nexport function getTasksBlockedBy(failedTaskId: string): TaskEntry[] {\n  const registry = loadRegistry();\n  return registry.tasks.filter(\n    t =>\n      t.status === 'pending' &&\n      t.blockedBy &&\n      t.blockedBy.includes(failedTaskId)\n  );\n}\n\n/**\n * Get orphaned tasks - pending tasks where all blockers have failed (CC 2.1.20)\n */\nexport function getOrphanedTasks(): TaskEntry[] {\n  const registry = loadRegistry();\n  const failedIds = new Set(\n    registry.tasks.filter(t => t.status === 'failed').map(t => t.taskId)\n  );\n\n  if (failedIds.size === 0) return [];\n\n  return registry.tasks.filter(t => {\n    if (t.status !== 'pending' || !t.blockedBy || t.blockedBy.length === 0) {\n      return false;\n    }\n    // Orphaned if ALL blockers are failed\n    return t.blockedBy.every(id => failedIds.has(id));\n  });\n}\n\n/**\n * Get all tasks for a pipeline\n */\nexport function getPipelineTasks(pipelineId: string): TaskEntry[] {\n  const registry = loadRegistry();\n  return registry.tasks\n    .filter(t => t.pipelineId === pipelineId)\n    .sort((a, b) => (a.pipelineStep || 0) - (b.pipelineStep || 0));\n}\n\n// -----------------------------------------------------------------------------\n// Pipeline Operations\n// -----------------------------------------------------------------------------\n\n/**\n * Register a pipeline execution\n */\nexport function registerPipeline(pipeline: PipelineExecution): void {\n  const registry = loadRegistry();\n\n  // Check for duplicate\n  const existing = registry.pipelines.find(p => p.pipelineId === pipeline.pipelineId);\n  if (existing) {\n    logHook('task-integration', `Pipeline ${pipeline.pipelineId} already registered`);\n    return;\n  }\n\n  registry.pipelines.push(pipeline);\n  saveRegistry(registry);\n  logHook('task-integration', `Registered pipeline ${pipeline.pipelineId} (${pipeline.type})`);\n}\n\n/**\n * Update pipeline state\n */\nexport function updatePipeline(\n  pipelineId: string,\n  updates: Partial<PipelineExecution>\n): void {\n  const registry = loadRegistry();\n\n  const pipeline = registry.pipelines.find(p => p.pipelineId === pipelineId);\n  if (pipeline) {\n    Object.assign(pipeline, updates);\n    saveRegistry(registry);\n    logHook('task-integration', `Updated pipeline ${pipelineId}`);\n  }\n}\n\n/**\n * Get active pipeline (if any)\n */\nexport function getActivePipeline(): PipelineExecution | undefined {\n  const registry = loadRegistry();\n  return registry.pipelines.find(p => p.status === 'running');\n}\n\n/**\n * Mark pipeline step complete and check for next\n */\nexport function completePipelineStep(pipelineId: string, step: number): number | null {\n  const registry = loadRegistry();\n\n  const pipeline = registry.pipelines.find(p => p.pipelineId === pipelineId);\n  if (!pipeline) return null;\n\n  if (!pipeline.completedSteps.includes(step)) {\n    pipeline.completedSteps.push(step);\n    pipeline.completedSteps.sort((a, b) => a - b);\n  }\n\n  // Find next unblocked step\n  const tasks = getPipelineTasks(pipelineId);\n  for (const task of tasks) {\n    const taskStep = task.pipelineStep;\n    if (taskStep === undefined) continue;\n    if (pipeline.completedSteps.includes(taskStep)) continue;\n    if (task.status !== 'pending') continue;\n\n    // Check if dependencies are met\n    // For now, assume sequential - previous steps must be complete\n    const prevStepsComplete = taskStep === 0 ||\n      pipeline.completedSteps.includes(taskStep - 1);\n\n    if (prevStepsComplete) {\n      pipeline.currentStep = taskStep;\n      saveRegistry(registry);\n      return taskStep;\n    }\n  }\n\n  // No more steps - pipeline complete\n  pipeline.status = 'completed';\n  saveRegistry(registry);\n  return null;\n}\n\n// -----------------------------------------------------------------------------\n// Cleanup\n// -----------------------------------------------------------------------------\n\n/**\n * Clean up completed tasks older than threshold\n */\nexport function cleanupOldTasks(maxAgeMs: number = 24 * 60 * 60 * 1000): void {\n  const registry = loadRegistry();\n  const cutoff = Date.now() - maxAgeMs;\n\n  registry.tasks = registry.tasks.filter(t => {\n    if (t.status === 'pending' || t.status === 'in_progress') return true;\n    const taskTime = new Date(t.createdAt).getTime();\n    return taskTime > cutoff;\n  });\n\n  registry.pipelines = registry.pipelines.filter(p => {\n    if (p.status === 'running') return true;\n    const pipelineTime = new Date(p.startedAt).getTime();\n    return pipelineTime > cutoff;\n  });\n\n  saveRegistry(registry);\n}\n", "/**\n * Orchestration State - Session state management for agent orchestration\n * Issue #197: Agent Orchestration Layer\n *\n * Manages:\n * - Active dispatched agents\n * - Injected skills tracking\n * - Prompt history for context continuity\n * - State persistence across hook invocations\n */\n\nimport { existsSync, readFileSync, writeFileSync, mkdirSync } from 'node:fs';\nimport { getProjectDir, getSessionId, logHook } from './common.js';\nimport type {\n  OrchestrationState,\n  DispatchedAgent,\n  OrchestrationConfig,\n  ClassificationResult,\n} from './orchestration-types.js';\n\n// -----------------------------------------------------------------------------\n// State File Management\n// -----------------------------------------------------------------------------\n\nfunction getStateDir(): string {\n  return `${getProjectDir()}/.claude/orchestration`;\n}\n\nfunction getStateFile(): string {\n  const sessionId = getSessionId();\n  return `${getStateDir()}/session-${sessionId}.json`;\n}\n\nfunction getConfigFile(): string {\n  return `${getProjectDir()}/.claude/orchestration/config.json`;\n}\n\n/**\n * Ensure state directory exists\n */\nfunction ensureStateDir(): void {\n  const dir = getStateDir();\n  if (!existsSync(dir)) {\n    try {\n      mkdirSync(dir, { recursive: true });\n    } catch {\n      logHook('orchestration-state', `Failed to create state dir: ${dir}`);\n    }\n  }\n}\n\n// -----------------------------------------------------------------------------\n// State Operations\n// -----------------------------------------------------------------------------\n\n/**\n * Load orchestration state for current session\n */\nexport function loadState(): OrchestrationState {\n  const stateFile = getStateFile();\n\n  if (existsSync(stateFile)) {\n    try {\n      const data = readFileSync(stateFile, 'utf8');\n      return JSON.parse(data) as OrchestrationState;\n    } catch (err) {\n      logHook('orchestration-state', `Failed to load state: ${err}`);\n    }\n  }\n\n  // Return default state\n  return {\n    sessionId: getSessionId(),\n    activeAgents: [],\n    injectedSkills: [],\n    promptHistory: [],\n    maxHistorySize: 10,\n    updatedAt: new Date().toISOString(),\n  };\n}\n\n/**\n * Save orchestration state\n */\nexport function saveState(state: OrchestrationState): void {\n  ensureStateDir();\n  const stateFile = getStateFile();\n\n  state.updatedAt = new Date().toISOString();\n\n  try {\n    writeFileSync(stateFile, JSON.stringify(state, null, 2));\n  } catch (err) {\n    logHook('orchestration-state', `Failed to save state: ${err}`);\n  }\n}\n\n/**\n * Update state with a mutation function\n */\nexport function updateState(\n  mutate: (state: OrchestrationState) => void\n): OrchestrationState {\n  const state = loadState();\n  mutate(state);\n  saveState(state);\n  return state;\n}\n\n// -----------------------------------------------------------------------------\n// Agent Tracking\n// -----------------------------------------------------------------------------\n\n/**\n * Add a dispatched agent to state\n */\nexport function trackDispatchedAgent(\n  agent: string,\n  confidence: number,\n  taskId?: string\n): DispatchedAgent {\n  const dispatched: DispatchedAgent = {\n    agent,\n    taskId,\n    confidence,\n    dispatchedAt: new Date().toISOString(),\n    status: 'pending',\n    retryCount: 0,\n    maxRetries: 3,\n  };\n\n  updateState(state => {\n    // Remove any existing entry for same agent\n    state.activeAgents = state.activeAgents.filter(a => a.agent !== agent);\n    state.activeAgents.push(dispatched);\n  });\n\n  logHook('orchestration-state', `Tracked dispatched agent: ${agent} (conf: ${confidence})`);\n  return dispatched;\n}\n\n/**\n * Update agent status\n */\nexport function updateAgentStatus(\n  agent: string,\n  status: DispatchedAgent['status'],\n  taskId?: string\n): void {\n  updateState(state => {\n    const entry = state.activeAgents.find(a => a.agent === agent);\n    if (entry) {\n      entry.status = status;\n      if (taskId) entry.taskId = taskId;\n      if (status === 'retrying') entry.retryCount++;\n    }\n  });\n\n  logHook('orchestration-state', `Updated agent status: ${agent} -> ${status}`);\n}\n\n/**\n * Remove completed/failed agent from tracking\n */\nexport function removeAgent(agent: string): void {\n  updateState(state => {\n    state.activeAgents = state.activeAgents.filter(a => a.agent !== agent);\n  });\n}\n\n/**\n * Get currently active agent (if any)\n */\nexport function getActiveAgent(): DispatchedAgent | undefined {\n  const state = loadState();\n  return state.activeAgents.find(a => a.status === 'in_progress');\n}\n\n/**\n * Check if an agent is currently dispatched\n */\nexport function isAgentDispatched(agent: string): boolean {\n  const state = loadState();\n  return state.activeAgents.some(\n    a => a.agent === agent && (a.status === 'pending' || a.status === 'in_progress')\n  );\n}\n\n// -----------------------------------------------------------------------------\n// Skill Tracking\n// -----------------------------------------------------------------------------\n\n/**\n * Track injected skill\n */\nexport function trackInjectedSkill(skill: string): void {\n  updateState(state => {\n    if (!state.injectedSkills.includes(skill)) {\n      state.injectedSkills.push(skill);\n    }\n  });\n}\n\n/**\n * Check if skill was already injected\n */\nexport function isSkillInjected(skill: string): boolean {\n  const state = loadState();\n  return state.injectedSkills.includes(skill);\n}\n\n/**\n * Get all injected skills\n */\nexport function getInjectedSkills(): string[] {\n  return loadState().injectedSkills;\n}\n\n// -----------------------------------------------------------------------------\n// Prompt History\n// -----------------------------------------------------------------------------\n\n/**\n * Add prompt to history (for context continuity)\n */\nexport function addToPromptHistory(prompt: string): void {\n  updateState(state => {\n    state.promptHistory.push(prompt);\n    // Trim to max size\n    if (state.promptHistory.length > state.maxHistorySize) {\n      state.promptHistory = state.promptHistory.slice(-state.maxHistorySize);\n    }\n  });\n}\n\n/**\n * Get recent prompt history\n */\nexport function getPromptHistory(): string[] {\n  return loadState().promptHistory;\n}\n\n// -----------------------------------------------------------------------------\n// Classification Caching\n// -----------------------------------------------------------------------------\n\n/**\n * Store last classification result\n */\nexport function cacheClassification(result: ClassificationResult): void {\n  updateState(state => {\n    state.lastClassification = result;\n  });\n}\n\n/**\n * Get last classification result\n */\nexport function getLastClassification(): ClassificationResult | undefined {\n  return loadState().lastClassification;\n}\n\n// -----------------------------------------------------------------------------\n// Configuration\n// -----------------------------------------------------------------------------\n\nconst DEFAULT_CONFIG_VALUES: OrchestrationConfig = {\n  enableAutoDispatch: true,\n  enableSkillInjection: true,\n  maxSkillInjectionTokens: 800,\n  enableCalibration: true,\n  enablePipelines: true,\n  maxRetries: 3,\n  retryDelayBaseMs: 1000,\n};\n\n/**\n * Load orchestration configuration\n */\nexport function loadConfig(): OrchestrationConfig {\n  const configFile = getConfigFile();\n\n  if (existsSync(configFile)) {\n    try {\n      const data = readFileSync(configFile, 'utf8');\n      return { ...DEFAULT_CONFIG_VALUES, ...JSON.parse(data) };\n    } catch {\n      // Return defaults on error\n    }\n  }\n\n  return DEFAULT_CONFIG_VALUES;\n}\n\n/**\n * Save orchestration configuration\n */\nexport function saveConfig(config: Partial<OrchestrationConfig>): void {\n  ensureStateDir();\n  const configFile = getConfigFile();\n  const current = loadConfig();\n  const merged = { ...current, ...config };\n\n  try {\n    writeFileSync(configFile, JSON.stringify(merged, null, 2));\n  } catch (err) {\n    logHook('orchestration-state', `Failed to save config: ${err}`);\n  }\n}\n\n// -----------------------------------------------------------------------------\n// Cleanup\n// -----------------------------------------------------------------------------\n\n/**\n * Clear session state (called on session end)\n */\nexport function clearSessionState(): void {\n  const stateFile = getStateFile();\n\n  try {\n    if (existsSync(stateFile)) {\n      const { unlinkSync } = require('node:fs');\n      unlinkSync(stateFile);\n      logHook('orchestration-state', 'Cleared session state');\n    }\n  } catch {\n    // Ignore cleanup errors\n  }\n}\n\n/**\n * Clean up old state files (keep last 5 sessions)\n */\nexport function cleanupOldStates(): void {\n  const dir = getStateDir();\n\n  if (!existsSync(dir)) return;\n\n  try {\n    const { readdirSync, statSync, unlinkSync } = require('node:fs');\n    const files = readdirSync(dir)\n      .filter((f: string) => f.startsWith('session-') && f.endsWith('.json'))\n      .map((f: string) => ({\n        name: f,\n        path: `${dir}/${f}`,\n        mtime: statSync(`${dir}/${f}`).mtime.getTime(),\n      }))\n      .sort((a: { mtime: number }, b: { mtime: number }) => b.mtime - a.mtime);\n\n    // Keep only last 5\n    for (const file of files.slice(5)) {\n      try {\n        unlinkSync(file.path);\n        logHook('orchestration-state', `Cleaned up old state: ${file.name}`);\n      } catch {\n        // Ignore\n      }\n    }\n  } catch {\n    // Ignore cleanup errors\n  }\n}\n", "/**\n * Calibration Persist - Stop Hook for Persisting Calibration Data\n * Issue #197: Agent Orchestration Layer\n *\n * End-of-session calibration operations:\n * - Applies decay to old adjustments\n * - Cleans up expired records\n * - Saves final calibration state\n *\n * CC 2.1.7 Compliant: Silent hook that persists in background\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { outputSilentSuccess, logHook } from '../lib/common.js';\nimport {\n  loadCalibrationData,\n  saveCalibrationData,\n  applyDecay,\n} from '../lib/calibration-engine.js';\nimport { loadConfig, clearSessionState, cleanupOldStates } from '../lib/orchestration-state.js';\nimport { cleanupOldTasks } from '../lib/task-integration.js';\n\n// -----------------------------------------------------------------------------\n// Constants\n// -----------------------------------------------------------------------------\n\n/** Maximum age for calibration records (30 days) */\nconst MAX_RECORD_AGE_MS = 30 * 24 * 60 * 60 * 1000;\n\n// -----------------------------------------------------------------------------\n// Helper Functions\n// -----------------------------------------------------------------------------\n\n/**\n * Clean up old calibration records\n */\nfunction cleanupOldRecords(data: ReturnType<typeof loadCalibrationData>): void {\n  const cutoff = Date.now() - MAX_RECORD_AGE_MS;\n\n  const before = data.records.length;\n  data.records = data.records.filter(r => {\n    const recordTime = new Date(r.timestamp).getTime();\n    return recordTime > cutoff;\n  });\n  const after = data.records.length;\n\n  if (before !== after) {\n    logHook('calibration-persist', `Cleaned up ${before - after} old records`);\n  }\n}\n\n/**\n * Generate calibration summary for logging\n */\nfunction generateSummary(data: ReturnType<typeof loadCalibrationData>): string {\n  const stats = data.stats;\n  const topAgents = stats.topAgents\n    .slice(0, 3)\n    .map(a => `${a.agent}(${Math.round(a.successRate * 100)}%)`)\n    .join(', ');\n\n  return `Calibration summary: ${stats.totalDispatches} dispatches, ` +\n    `${Math.round(stats.successRate * 100)}% success rate, ` +\n    `${data.adjustments.length} adjustments active. ` +\n    `Top agents: ${topAgents || 'none'}`;\n}\n\n// -----------------------------------------------------------------------------\n// Hook Implementation\n// -----------------------------------------------------------------------------\n\n/**\n * Calibration persist hook\n *\n * Runs at session end to:\n * 1. Apply decay to old adjustments\n * 2. Clean up expired records\n * 3. Save final calibration state\n * 4. Clean up session-specific state\n */\nexport function calibrationPersist(_input: HookInput): HookResult {\n  // Check if calibration is enabled\n  const config = loadConfig();\n  if (!config.enableCalibration) {\n    // Still do cleanup even if calibration disabled\n    clearSessionState();\n    cleanupOldStates();\n    return outputSilentSuccess();\n  }\n\n  logHook('calibration-persist', 'Running end-of-session calibration persistence...');\n\n  try {\n    // Load current calibration data\n    const data = loadCalibrationData();\n\n    // Apply decay to old adjustments\n    applyDecay(data);\n\n    // Clean up old records\n    cleanupOldRecords(data);\n\n    // Save updated calibration data\n    saveCalibrationData(data);\n\n    // Log summary\n    const summary = generateSummary(data);\n    logHook('calibration-persist', summary);\n\n  } catch (err) {\n    logHook('calibration-persist', `Error during calibration persist: ${err}`);\n  }\n\n  // Clean up session state\n  try {\n    clearSessionState();\n    cleanupOldStates();\n    cleanupOldTasks();\n    logHook('calibration-persist', 'Cleaned up session state');\n  } catch (err) {\n    logHook('calibration-persist', `Error during state cleanup: ${err}`);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Unified Stop Dispatcher\n * Issue #235: Hook Architecture Refactor\n *\n * Consolidates 4 async Stop hooks into a single dispatcher.\n * Reduces \"Async hook Stop completed\" messages from 4 to 1.\n *\n * CC 2.1.19 Compliant: Single async hook with internal routing\n */\n\nimport type { HookInput, HookResult } from '../types.js';\nimport { outputSilentSuccess, logHook } from '../lib/common.js';\n\n// Import individual hook implementations\nimport { autoSaveContext } from './auto-save-context.js';\nimport { sessionPatterns } from './session-patterns.js';\nimport { issueWorkSummary } from './issue-work-summary.js';\nimport { calibrationPersist } from './calibration-persist.js';\n\n// -----------------------------------------------------------------------------\n// Types\n// -----------------------------------------------------------------------------\n\ntype HookFn = (input: HookInput) => HookResult | Promise<HookResult>;\n\ninterface HookConfig {\n  name: string;\n  fn: HookFn;\n}\n\n// -----------------------------------------------------------------------------\n// Hook Registry\n// -----------------------------------------------------------------------------\n\n/**\n * Registry of all async Stop hooks consolidated into dispatcher\n */\nconst HOOKS: HookConfig[] = [\n  { name: 'auto-save-context', fn: autoSaveContext },\n  { name: 'session-patterns', fn: sessionPatterns },\n  { name: 'issue-work-summary', fn: issueWorkSummary },\n  { name: 'calibration-persist', fn: calibrationPersist },\n];\n\n/** Exposed for registry wiring tests */\nexport const registeredHookNames = () => HOOKS.map(h => h.name);\n\n// -----------------------------------------------------------------------------\n// Dispatcher Implementation\n// -----------------------------------------------------------------------------\n\n/**\n * Unified dispatcher that runs all Stop hooks in parallel\n */\nexport async function unifiedStopDispatcher(input: HookInput): Promise<HookResult> {\n  // Run all hooks in parallel\n  const results = await Promise.allSettled(\n    HOOKS.map(async hook => {\n      try {\n        const result = hook.fn(input);\n        if (result instanceof Promise) {\n          await result;\n        }\n        return { hook: hook.name, status: 'success' };\n      } catch (error) {\n        const message = error instanceof Error ? error.message : String(error);\n        logHook('stop-dispatcher', `${hook.name} failed: ${message}`);\n        return { hook: hook.name, status: 'error', message };\n      }\n    })\n  );\n\n  // Log summary for debugging (only errors)\n  const errors = results.filter(\n    r => r.status === 'rejected' || (r.status === 'fulfilled' && r.value.status === 'error')\n  );\n\n  if (errors.length > 0) {\n    logHook('stop-dispatcher', `${errors.length}/${HOOKS.length} hooks had errors`);\n  }\n\n  return outputSilentSuccess();\n}\n", "/**\n * Stop Hooks Entry Point\n *\n * Hooks that run when conversation stops (Stop event)\n * Bundle: stop.mjs (~25 KB estimated)\n */\n\n// Re-export types and utilities\nexport * from '../types.js';\nexport * from '../lib/common.js';\n\n// Re-export calibration engine for stop hooks\nexport * from '../lib/calibration-engine.js';\n\n// Stop hooks (12)\nimport { autoRememberContinuity } from '../stop/auto-remember-continuity.js';\nimport { autoSaveContext } from '../stop/auto-save-context.js';\nimport { cleanupInstance } from '../stop/cleanup-instance.js';\nimport { contextCompressor } from '../stop/context-compressor.js';\nimport { fullTestSuite } from '../stop/full-test-suite.js';\nimport { issueWorkSummary } from '../stop/issue-work-summary.js';\nimport { mem0PreCompactionSync } from '../stop/mem0-pre-compaction-sync.js';\nimport { multiInstanceCleanup } from '../stop/multi-instance-cleanup.js';\nimport { securityScanAggregator } from '../stop/security-scan-aggregator.js';\nimport { sessionPatterns } from '../stop/session-patterns.js';\nimport { taskCompletionCheck } from '../stop/task-completion-check.js';\nimport { calibrationPersist } from '../stop/calibration-persist.js';\nimport { unifiedStopDispatcher } from '../stop/unified-dispatcher.js';\n\nimport type { HookFn } from '../types.js';\n\n/**\n * Stop hooks registry\n */\nexport const hooks: Record<string, HookFn> = {\n  'stop/auto-remember-continuity': autoRememberContinuity,\n  'stop/auto-save-context': autoSaveContext,\n  'stop/cleanup-instance': cleanupInstance,\n  'stop/context-compressor': contextCompressor,\n  'stop/full-test-suite': fullTestSuite,\n  'stop/issue-work-summary': issueWorkSummary,\n  'stop/mem0-pre-compaction-sync': mem0PreCompactionSync,\n  'stop/multi-instance-cleanup': multiInstanceCleanup,\n  'stop/security-scan-aggregator': securityScanAggregator,\n  'stop/session-patterns': sessionPatterns,\n  'stop/task-completion-check': taskCompletionCheck,\n  'stop/calibration-persist': calibrationPersist,\n  'stop/unified-dispatcher': unifiedStopDispatcher,\n};\n\nexport function getHook(name: string): HookFn | undefined {\n  return hooks[name];\n}\n\nexport function listHooks(): string[] {\n  return Object.keys(hooks);\n}\n"],
  "mappings": ";;;0PAoNO,SAASA,GAAYC,EAA0C,CACpE,OAAO,OAAOA,EAAM,SAAY,QAClC,CAEO,SAASC,GAAaD,EAA2C,CACtE,OAAO,OAAOA,EAAM,WAAc,UAAY,OAAOA,EAAM,SAAY,QACzE,CAEO,SAASE,GAAYF,EAA0C,CACpE,OACE,OAAOA,EAAM,WAAc,UAC3B,OAAOA,EAAM,YAAe,UAC5B,OAAOA,EAAM,YAAe,QAEhC,CAEO,SAASG,GAAYH,EAA0C,CACpE,OAAO,OAAOA,EAAM,WAAc,UAAYA,EAAM,UAAY,MAClE,CCjOA,OAAS,kBAAAI,GAAgB,cAAAC,GAAY,YAAAC,GAAU,cAAAC,GAAY,aAAAC,GAAW,YAAAC,OAAgB,UACtF,OAAS,YAAAC,OAAgB,qBAWlB,SAASC,IAAoB,CAClC,OAAI,QAAQ,IAAI,mBACP,GAAG,QAAQ,IAAI,MAAQ,MAAM,oBAE/B,GAAGC,EAAc,CAAC,eAC3B,CAMO,SAASA,GAAwB,CACtC,OAAO,QAAQ,IAAI,oBAAsB,GAC3C,CAMO,SAASC,IAAwB,CACtC,OAAO,QAAQ,IAAI,oBAAsB,QAAQ,IAAI,oBAAsB,GAC7E,CAQO,SAASC,GAAuB,CACrC,OAAO,QAAQ,IAAI,mBAAqB,YAAY,QAAQ,GAAG,IAAI,KAAK,IAAI,CAAC,EAC/E,CAMO,SAASC,GAAgBC,EAA6B,CAC3D,GAAI,QAAQ,IAAI,kBACd,OAAO,QAAQ,IAAI,kBAGrB,GAAI,CACF,IAAMC,EAASP,GAAS,4BAA6B,CACnD,IAAKM,GAAcJ,EAAc,EACjC,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAAE,KAAK,EACR,eAAQ,IAAI,kBAAoBK,EACzBA,CACT,MAAQ,CACN,MAAO,SACT,CACF,CAKO,SAASC,IAAsB,CACpC,OAAO,QAAQ,IAAI,sBAAwB,MAC7C,CAKO,SAASC,GAAUC,EAAqD,CAC7E,IAAMC,EAAS,CAAC,QAAS,OAAQ,OAAQ,OAAO,EAChD,OAAOA,EAAO,QAAQD,CAAK,GAAKC,EAAO,QAAQH,GAAY,CAAC,CAC9D,CASO,SAASI,GAAkC,CAChD,MAAO,CAAE,SAAU,GAAM,eAAgB,EAAK,CAChD,CAKO,SAASC,IAAgC,CAC9C,MAAO,CACL,SAAU,GACV,eAAgB,GAChB,mBAAoB,CAAE,mBAAoB,OAAQ,CACpD,CACF,CAKO,SAASC,GAAYC,EAA4B,CACtD,MAAO,CACL,SAAU,GACV,WAAYA,EACZ,mBAAoB,CAClB,mBAAoB,OACpB,yBAA0BA,CAC5B,CACF,CACF,CAMO,SAASC,GAAkBC,EAAyB,CACzD,MAAO,CACL,SAAU,GACV,eAAgB,GAChB,mBAAoB,CAClB,cAAe,cACf,kBAAmBA,CACrB,CACF,CACF,CAMO,SAASC,GAAoBD,EAAyB,CAC3D,MAAO,CACL,SAAU,GACV,eAAgB,GAChB,mBAAoB,CAClB,cAAe,mBACf,kBAAmBA,CACrB,CACF,CACF,CAKO,SAASE,GAAuBF,EAAaG,EAAoC,CACtF,IAAMC,EAAqB,CACzB,SAAU,GACV,mBAAoB,CAClB,cAAe,aACf,kBAAmBJ,EACnB,mBAAoB,OACtB,CACF,EAEA,OAAIG,EACFC,EAAO,cAAgBD,EAEvBC,EAAO,eAAiB,GAGnBA,CACT,CAKO,SAASC,GAAYC,EAA6B,CACvD,MAAO,CAAE,SAAU,GAAM,cAAeA,CAAQ,CAClD,CAKO,SAASC,GAAcD,EAA6B,CACzD,MAAO,CAAE,SAAU,GAAM,cAAe,UAAUA,CAAO,EAAG,CAC9D,CAKO,SAASE,GAAWV,EAA4B,CACrD,MAAO,CACL,SAAU,GACV,WAAYA,EACZ,mBAAoB,CAClB,cAAe,aACf,mBAAoB,OACpB,yBAA0BA,CAC5B,CACF,CACF,CAMA,IAAMW,GAAwB,IAAM,KAC9BC,GAA0B,IAAM,KAKtC,SAASC,GAAcC,EAAiBC,EAAuB,CAC7D,GAAKnC,GAAWkC,CAAO,EAEvB,GAAI,CAEF,GADcjC,GAASiC,CAAO,EACpB,KAAOC,EAAS,CACxB,IAAMC,EAAU,GAAGF,CAAO,QAAQ,KAAK,IAAI,CAAC,GAC5ChC,GAAWgC,EAASE,CAAO,CAC7B,CACF,MAAQ,CAER,CACF,CAKA,SAASC,GAAUC,EAAmB,CAC/BtC,GAAWsC,CAAG,GACjBnC,GAAUmC,EAAK,CAAE,UAAW,EAAK,CAAC,CAEtC,CAMO,SAASC,EAAQC,EAAkBZ,EAAiBb,EAA6C,QAAe,CAErH,GAAI,CAACD,GAAUC,CAAK,EAClB,OAGF,IAAM0B,EAASnC,GAAU,EACnB4B,EAAU,GAAGO,CAAM,aAEzB,GAAI,CACFJ,GAAUI,CAAM,EAChBR,GAAcC,EAASH,EAAqB,EAE5C,IAAMW,EAAY,IAAI,KAAK,EAAE,YAAY,EAAE,QAAQ,IAAK,GAAG,EAAE,MAAM,EAAG,EAAE,EACxE3C,GAAemC,EAAS,IAAIQ,CAAS,MAAM3B,EAAM,YAAY,CAAC,MAAMyB,CAAQ,KAAKZ,CAAO;AAAA,CAAI,CAC9F,MAAQ,CAER,CACF,CAMO,SAASe,GACdC,EACAxB,EACAyB,EACM,CACN,IAAMJ,EAASnC,GAAU,EACnB4B,EAAU,GAAGO,CAAM,2BAEzB,GAAI,CACFJ,GAAUI,CAAM,EAChBR,GAAcC,EAASF,EAAuB,EAE9C,IAAMU,EAAY,IAAI,KAAK,EAAE,YAAY,EACnCI,EAAYD,GAAqB,WAAa,QAAQ,IAAI,gBAAkB,UAC5EE,EAAaF,GAAqB,YAAcpC,EAAa,EAEnEV,GACEmC,EACA,GAAGQ,CAAS,MAAME,CAAQ,MAAMxB,CAAM,WAAW0B,CAAQ,cAAcC,CAAS;AAAA,CAClF,CACF,MAAQ,CAER,CACF,CAUO,SAASC,IAA2B,CACzC,GAAI,CAEF,IAAMC,EAAmB,CAAC,EAEpBC,EAAM,OAAO,YAAY,GAAO,EAElCC,EACEC,EAAK,EAEX,OACE,GAAI,CAEF,GADAD,EAAY/C,GAASgD,EAAIF,EAAK,EAAG,IAAS,IAAI,EAC1CC,IAAc,EAAG,MACrBF,EAAO,KAAK,OAAO,KAAKC,EAAI,SAAS,EAAGC,CAAS,CAAC,CAAC,CACrD,MAAQ,CACN,KACF,CAGF,IAAMN,EAAQ,OAAO,OAAOI,CAAM,EAAE,SAAS,MAAM,EAAE,KAAK,EAC1D,OAAKJ,EAIE,KAAK,MAAMA,CAAK,EAHd,CAAE,UAAW,GAAI,WAAYpC,EAAa,EAAG,WAAY,CAAC,CAAE,CAIvE,MAAQ,CACN,MAAO,CAAE,UAAW,GAAI,WAAYA,EAAa,EAAG,WAAY,CAAC,CAAE,CACrE,CACF,CAKO,SAAS4C,GAAYR,EAAkBS,EAA6B,CACzE,IAAMC,EAAQD,EAAK,QAAQ,MAAO,EAAE,EAAE,MAAM,GAAG,EAC3CE,EAAiBX,EAErB,QAAWY,KAAQF,EAAO,CACxB,GAAIC,GAAU,KAA6B,OAC3CA,EAASA,EAAkCC,CAAI,CACjD,CAEA,OAAOD,CACT,CAUO,SAASE,GAAiBC,EAAyB,CACxD,OAAOA,EACJ,QAAQ,gBAAiB,GAAG,EAC5B,QAAQ,MAAO,GAAG,EAClB,QAAQ,OAAQ,GAAG,EACnB,KAAK,CACV,CAKO,SAASC,GAAYC,EAAqB,CAC/C,OAAOA,EAAI,QAAQ,sBAAuB,MAAM,CAClD,CCpWA,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UACnE,OAAS,cAAAC,OAAkB,cAc3B,IAAMC,GAAc,IAGdC,EAA6B,EAG7BC,GAAiB,GAGjBC,GAAkB,EAGlBC,GAAe,GAMrB,SAASC,IAA6B,CACpC,MAAO,GAAGC,EAAc,CAAC,yCAC3B,CAEA,SAASC,IAAkB,CACzB,IAAMC,EAAM,GAAGF,EAAc,CAAC,oBAC9B,GAAI,CAACG,GAAWD,CAAG,EACjB,GAAI,CACFE,GAAUF,EAAK,CAAE,UAAW,EAAK,CAAC,CACpC,MAAQ,CAER,CAEJ,CAKO,SAASG,GAAuC,CACrD,IAAMC,EAAOP,GAAmB,EAEhC,GAAII,GAAWG,CAAI,EACjB,GAAI,CACF,OAAO,KAAK,MAAMC,GAAaD,EAAM,MAAM,CAAC,CAC9C,MAAQ,CACNE,EAAQ,qBAAsB,iDAAiD,CACjF,CAGF,MAAO,CACL,cAAe,QACf,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,QAAS,CAAC,EACV,YAAa,CAAC,EACd,MAAO,CACL,gBAAiB,EACjB,YAAa,EACb,cAAe,EACf,UAAW,CAAC,CACd,CACF,CACF,CAKO,SAASC,EAAoBC,EAA6B,CAC/DT,GAAU,EACV,IAAMK,EAAOP,GAAmB,EAEhCW,EAAK,UAAY,IAAI,KAAK,EAAE,YAAY,EAExC,GAAI,CACFC,GAAcL,EAAM,KAAK,UAAUI,EAAM,KAAM,CAAC,CAAC,EACjDF,EAAQ,qBAAsB,wBAAwB,CACxD,OAASI,EAAK,CACZJ,EAAQ,qBAAsB,oCAAoCI,CAAG,EAAE,CACzE,CACF,CASO,SAASC,GAAWC,EAAwB,CACjD,OAAOC,GAAW,QAAQ,EAAE,OAAOD,EAAO,YAAY,EAAE,KAAK,CAAC,EAAE,OAAO,KAAK,EAAE,MAAM,EAAG,EAAE,CAC3F,CAKO,SAASE,GACdF,EACAG,EACAC,EACAC,EACAC,EACAC,EACAC,EACM,CACN,IAAMZ,EAAOL,EAAoB,EAE3BkB,EAA4B,CAChC,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,UAAWC,EAAa,EACxB,MAAAP,EACA,WAAYJ,GAAWC,CAAM,EAC7B,gBAAAI,EACA,mBAAoBC,EACpB,QAAAC,EACA,WAAAC,EACA,SAAAC,CACF,EAEAZ,EAAK,QAAQ,KAAKa,CAAM,EAGpBb,EAAK,QAAQ,OAAShB,KACxBgB,EAAK,QAAUA,EAAK,QAAQ,MAAM,CAAChB,EAAW,GAIhD+B,GAAkBf,EAAMa,CAAM,EAG9BG,GAAYhB,CAAI,EAEhBD,EAAoBC,CAAI,EAExBF,EACE,qBACA,qBAAqBS,CAAK,OAAOG,CAAO,WAAWD,CAAU,GAC/D,CACF,CASA,SAASM,GAAkBf,EAAuBa,EAAiC,CACjF,IAAMI,EAAaJ,EAAO,UAAY,UAChCK,EAAaL,EAAO,UAAY,WAAaA,EAAO,UAAY,WAEtE,GAAI,CAACI,GAAc,CAACC,EAElB,OAGF,IAAMC,EAAkBF,EAAa9B,GAAkB,CAACA,GAExD,QAAWiC,KAAWP,EAAO,gBAAiB,CAC5C,IAAMQ,EAAWrB,EAAK,YAAY,KAChCsB,GAAKA,EAAE,UAAYF,GAAWE,EAAE,QAAUT,EAAO,KACnD,EAEIQ,GAEFA,EAAS,WAAa,KAAK,IACzB,CAACnC,GACD,KAAK,IAAIA,GAAgBmC,EAAS,WAAaF,CAAe,CAChE,EACAE,EAAS,cACTA,EAAS,YAAc,IAAI,KAAK,EAAE,YAAY,GAG9CrB,EAAK,YAAY,KAAK,CACpB,QAAAoB,EACA,MAAOP,EAAO,MACd,WAAYM,EACZ,YAAa,EACb,YAAa,IAAI,KAAK,EAAE,YAAY,CACtC,CAAC,CAEL,CACF,CAKO,SAASI,GAAWvB,EAA6B,CACtD,IAAMwB,EAAM,KAAK,IAAI,EACfC,EAAQ,KAAU,GAAK,IAE7B,QAAWC,KAAO1B,EAAK,YAAa,CAClC,IAAM2B,EAAMH,EAAM,IAAI,KAAKE,EAAI,WAAW,EAAE,QAAQ,EACpC,KAAK,MAAMC,EAAMF,CAAK,EAExB,IAEZC,EAAI,WAAa,KAAK,MAAMA,EAAI,WAAatC,EAAY,EAGrD,KAAK,IAAIsC,EAAI,UAAU,EAAI,IAC7BA,EAAI,WAAa,GAGvB,CAGA1B,EAAK,YAAcA,EAAK,YAAY,OAAOsB,GAAKA,EAAE,aAAe,CAAC,CACpE,CASA,SAASN,GAAYhB,EAA6B,CAChD,IAAM4B,EAAU5B,EAAK,QACrB,GAAI4B,EAAQ,SAAW,EAAG,OAG1B5B,EAAK,MAAM,gBAAkB4B,EAAQ,OAGrC,IAAMC,EAAaD,EAAQ,OAAO,GAAK,EAAE,UAAY,SAAS,EAAE,OAChE5B,EAAK,MAAM,YAAc6B,EAAaD,EAAQ,OAG9C,IAAME,EAAUF,EAAQ,OAAO,CAACG,EAAKC,IAAMD,EAAMC,EAAE,mBAAoB,CAAC,EAAIJ,EAAQ,OACpF5B,EAAK,MAAM,cAAgB,KAAK,MAAM8B,CAAO,EAG7C,IAAMG,EAAa,IAAI,IACvB,QAAWpB,KAAUe,EAAS,CAC5B,IAAMM,EAAOD,EAAW,IAAIpB,EAAO,KAAK,GAAK,CAAE,MAAO,EAAG,QAAS,CAAE,EACpEqB,EAAK,QACDrB,EAAO,UAAY,WAAWqB,EAAK,UACvCD,EAAW,IAAIpB,EAAO,MAAOqB,CAAI,CACnC,CAEAlC,EAAK,MAAM,UAAY,MAAM,KAAKiC,EAAW,QAAQ,CAAC,EACnD,IAAI,CAAC,CAAC1B,EAAO2B,CAAI,KAAO,CACvB,MAAA3B,EACA,MAAO2B,EAAK,MACZ,YAAaA,EAAK,QAAUA,EAAK,KACnC,EAAE,EACD,KAAK,CAACZ,EAAGa,IAAMA,EAAE,MAAQb,EAAE,KAAK,EAChC,MAAM,EAAG,EAAE,CAChB,CASO,SAASc,IAA0C,CAIxD,OAHazC,EAAoB,EAGrB,YAAY,OAAO2B,GAAKA,EAAE,aAAerC,CAA0B,CACjF,CAKO,SAASoD,GAAoB9B,EAA8B,CAEhE,IAAM+B,EADO3C,EAAoB,EACP,QAAQ,OAAOqC,GAAKA,EAAE,QAAUzB,CAAK,EAE/D,OAAI+B,EAAa,OAASrD,EACjB,KAGUqD,EAAa,OAAON,GAAKA,EAAE,UAAY,SAAS,EAAE,OACjDM,EAAa,MACnC,CAKO,SAASC,IAAgD,CAC9D,OAAO5C,EAAoB,EAAE,KAC/B,CAKO,SAAS6C,IAAqC,CAEnD,OADa7C,EAAoB,EACrB,QAAQ,QAAUV,CAChC,CC3SO,SAASwD,GAAuBC,EAA8B,CACnEC,EAAQ,2BAA4B,gBAAgB,EAGpD,IAAMC,GADaF,EAAM,aAAeG,EAAc,GACzB,MAAM,GAAG,EAAE,IAAI,GAAK,UAI3CC,EADgB,CAAC,CAAC,QAAQ,IAAI,aAEhC,iFACA,GAEEC,EAAY;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAMIH,CAAS;AAAA;AAAA;AAAA;AAAA,WAItBE,CAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wDAkBjB,OAAAH,EAAQ,2BAA4B,0CAA0C,EAEvE,CACL,SAAU,GACV,eAAgB,EAElB,CACF,CCrDA,OAAS,cAAAK,GAAY,aAAAC,GAAW,gBAAAC,GAAc,iBAAAC,OAAqB,UA2B5D,SAASC,EAAgBC,EAA8B,CAC5DC,EAAQ,oBAAqB,gDAAgD,EAG7E,IAAMC,EAAa,GADAF,EAAM,aAAeG,EAAc,CACtB,2BAC1BC,EAAe,GAAGF,CAAU,cAGlC,GAAI,CACGG,GAAWH,CAAU,GACxBI,GAAUJ,EAAY,CAAE,UAAW,EAAK,CAAC,CAE7C,MAAQ,CAER,CAEA,IAAMK,EAAY,IAAI,KAAK,EAAE,YAAY,EAEzC,GAAI,CACF,GAAIF,GAAWD,CAAY,EAAG,CAE5B,IAAMI,EAAUC,GAAaL,EAAc,OAAO,EAC5CM,EAA+B,KAAK,MAAMF,CAAO,EAGjDG,EAAwB,CAC5B,QAASD,EAAM,SAAW,uBAC1B,MAAOA,EAAM,OAAS,CACpB,SAAU,MACV,aAAc,IACd,UAAW,SACX,SAAU,eACV,YAAa,8DACf,EACA,WAAYA,EAAM,YAAc,KAChC,QAASA,EAAM,SAAW,KAC1B,cAAeH,EACf,aAAcG,EAAM,cAAgB,CAAE,YAAa,iBAAkB,OAAQ,SAAU,EACvF,WAAYA,EAAM,YAAc,CAAC,EACjC,SAAUA,EAAM,UAAY,CAAC,CAC/B,EAEAE,GAAcR,EAAc,KAAK,UAAUO,EAAS,KAAM,CAAC,CAAC,EAC5DV,EAAQ,oBAAqB,iCAAiC,CAChE,MAsBEW,GAAcR,EAAc,KAAK,UApBF,CAC7B,QAAS,uBACT,MAAO,CACL,SAAU,MACV,aAAc,IACd,UAAW,SACX,SAAU,eACV,YAAa,8DACf,EACA,WAAY,KACZ,QAASG,EACT,cAAeA,EACf,aAAc,CACZ,YAAa,iBACb,OAAQ,SACV,EACA,WAAY,CAAC,EACb,SAAU,CAAC,CACb,EAEqD,KAAM,CAAC,CAAC,EAC7DN,EAAQ,oBAAqB,oDAAoD,CAErF,OAASY,EAAO,CACdZ,EAAQ,oBAAqB,yBAAyBY,CAAK,EAAE,CAC/D,CAEA,OAAOC,EAAoB,CAC7B,CCvGA,OAAS,cAAAC,GAAY,gBAAAC,OAAoB,UACzC,OAAS,YAAAC,MAAgB,qBAOzB,SAASC,GAAcC,EAAmC,CACxD,IAAMC,EAAS,GAAGD,CAAU,qBAC5B,GAAI,CACF,OAAKE,GAAWD,CAAM,GAGN,KAAK,MAAME,GAAaF,EAAQ,OAAO,CAAC,EACzC,aAAe,IAChC,MAAQ,CACN,OAAO,IACT,CACF,CAKA,SAASG,EAAUC,EAAgBC,EAAmB,CACpD,GAAI,CACFC,EAAS,YAAYF,CAAM,MAAMC,CAAG,IAAK,CACvC,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CAER,CACF,CAKO,SAASE,GAAgBC,EAA8B,CAC5D,IAAMT,EAAaS,EAAM,aAAeC,EAAc,EAChDL,EAAS,GAAGL,CAAU,mCAG5B,GAAI,CAACE,GAAWG,CAAM,EACpB,OAAAM,EAAQ,mBAAoB,4CAA4C,EACjEC,EAAoB,EAI7B,IAAMC,EAAad,GAAcC,CAAU,EAC3C,GAAI,CAACa,EACH,OAAAF,EAAQ,mBAAoB,4BAA4B,EACjDC,EAAoB,EAG7BD,EAAQ,mBAAoB,yBAAyBE,CAAU,EAAE,EAGjEF,EAAQ,mBAAoB,wBAAwB,EACpDP,EAAUC,EAAQ,+CAA+CQ,CAAU,IAAI,EAC/EF,EAAQ,mBAAoB,oBAAoB,EAGhD,GAAI,CACeJ,EACf,YAAYF,CAAM,oFAClB,CAAE,SAAU,OAAQ,QAAS,GAAK,CACpC,EAAE,KAAK,IAEU,MACfD,EACEC,EACA,oGAAoGQ,CAAU,0BAChH,EACAF,EAAQ,mBAAoB,qBAAqB,EAErD,MAAQ,CAER,CAGA,GAAI,CACeJ,EACf,YAAYF,CAAM,kFAClB,CAAE,SAAU,OAAQ,QAAS,GAAK,CACpC,EAAE,KAAK,IAEU,MACfD,EACEC,EACA,4FAA4FQ,CAAU,IACxG,EACAF,EAAQ,mBAAoB,uCAAuC,EAEvE,MAAQ,CAER,CAEA,OAAAA,EAAQ,mBAAoB,kCAAkC,EACvDC,EAAoB,CAC7B,CCvGA,OAAS,cAAAE,EAAY,aAAAC,GAAW,gBAAAC,GAAc,iBAAAC,MAAqB,UAKnE,IAAMC,EAAuB,GAe7B,SAASC,GAAeC,EAA0B,CAChD,IAAMC,EAAc,GAAGD,CAAU,sBACjC,GAAI,CAACE,EAAWD,CAAW,EAAG,CAC5BE,EAAQ,qBAAsB,6BAA6B,EAC3D,MACF,CAEA,GAAI,CACF,IAAMC,EAAUC,GAAaJ,EAAa,OAAO,EAC3CK,EAAwB,KAAK,MAAMF,CAAO,EAE1CG,EAAYD,EAAQ,YAAc,WAAW,IAAI,KAAK,EAAE,YAAY,EAAE,QAAQ,QAAS,GAAG,CAAC,GAC3FE,EAAa,GAAGR,CAAU,oBAChCS,GAAUD,EAAY,CAAE,UAAW,EAAK,CAAC,EAEzC,IAAME,EAAc,GAAGF,CAAU,IAAID,CAAS,QACxCI,EAAW,CACf,GAAGL,EACH,MAAO,IAAI,KAAK,EAAE,YAAY,EAC9B,SAAU,EACZ,EAEAM,EAAcF,EAAa,KAAK,UAAUC,EAAU,KAAM,CAAC,CAAC,EAC5DR,EAAQ,qBAAsB,uBAAuBO,CAAW,EAAE,EAgBlEE,EAAcX,EAAa,KAAK,UAbb,CACjB,QAAS,uBACT,MAAO,CAAE,SAAU,MAAO,aAAc,IAAK,UAAW,QAAS,EACjE,WAAY,KACZ,QAAS,KACT,aAAc,KACd,cAAe,CAAC,EAChB,uBAAwB,CAAC,EACzB,SAAU,CAAC,EACX,WAAY,CAAC,EACb,WAAY,CAAE,MAAO,CAAC,CAAE,CAC1B,EAEsD,KAAM,CAAC,CAAC,EAC9DE,EAAQ,qBAAsB,qBAAqB,CACrD,OAASU,EAAO,CACdV,EAAQ,qBAAsB,4BAA4BU,CAAK,EAAE,CACnE,CACF,CAKA,SAASC,GAAqBd,EAA0B,CACtD,IAAMe,EAAgB,GAAGf,CAAU,mCACnC,GAAKE,EAAWa,CAAa,EAI7B,GAAI,CACF,IAAMX,EAAUC,GAAaU,EAAe,OAAO,EAC7CC,EAAsB,KAAK,MAAMZ,CAAO,EACxCa,EAAYD,EAAK,WAAa,CAAC,EAErC,GAAIC,EAAU,QAAUnB,EACtB,OAGF,IAAMU,EAAa,GAAGR,CAAU,qBAChCS,GAAUD,EAAY,CAAE,UAAW,EAAK,CAAC,EAEzC,IAAMU,EAAM,IAAI,KACVR,EAAc,GAAGF,CAAU,IAAIU,EAAI,YAAY,CAAC,IAAI,OAAOA,EAAI,SAAS,EAAI,CAAC,EAAE,SAAS,EAAG,GAAG,CAAC,QAG/FC,EAAYF,EAAU,MAAM,EAAG,CAACnB,CAAoB,EAC1Dc,EAAcF,EAAa,KAAK,UAAUS,EAAW,KAAM,CAAC,CAAC,EAG7DH,EAAK,UAAYC,EAAU,MAAM,CAACnB,CAAoB,EACtDc,EAAcG,EAAe,KAAK,UAAUC,EAAM,KAAM,CAAC,CAAC,EAE1Db,EAAQ,qBAAsB,YAAYgB,EAAU,MAAM,gBAAgB,CAC5E,OAASN,EAAO,CACdV,EAAQ,qBAAsB,gCAAgCU,CAAK,EAAE,CACvE,CACF,CAMA,SAASO,GAAwBpB,EAA0B,CACzD,IAAMC,EAAc,GAAGD,CAAU,sBACjC,GAAKE,EAAWD,CAAW,EAI3B,GAAI,CACF,IAAMG,EAAUC,GAAaJ,EAAa,OAAO,EAC3CK,EAAU,KAAK,MAAMF,CAAO,EAE5BiB,EAAW,CACf,UAAWf,EAAQ,YAAc,UACjC,YAAa,IAAI,KAAK,EAAE,YAAY,EACpC,cAAeA,EAAQ,wBAA0B,CAAC,GAAG,MAAM,EAAE,EAC7D,cAAeA,EAAQ,eAAiB,CAAC,GAAG,MAAM,GAAG,EACrD,SAAUA,EAAQ,UAAY,CAAC,EAC/B,UAAWA,EAAQ,YAAc,CAAC,CACpC,EAEMgB,EAAc,GAAGtB,CAAU,WACjCS,GAAUa,EAAa,CAAE,UAAW,EAAK,CAAC,EAC1CV,EAAc,GAAGU,CAAW,4BAA6B,KAAK,UAAUD,EAAU,KAAM,CAAC,CAAC,EAC1FlB,EAAQ,qBAAsB,yCAAyCkB,EAAS,SAAS,EAAE,CAC7F,OAASR,EAAO,CACdV,EAAQ,qBAAsB,sCAAsCU,CAAK,EAAE,CAC7E,CACF,CAKO,SAASU,GAAkBC,EAA8B,CAC9DrB,EAAQ,qBAAsB,wCAAwC,EAGtE,IAAMH,EAAa,GADAwB,EAAM,aAAeC,EAAc,CACtB,WAEhC,OAAAL,GAAwBpB,CAAU,EAClCD,GAAeC,CAAU,EACzBc,GAAqBd,CAAU,EAE/BG,EAAQ,qBAAsB,qCAAqC,EAC5DuB,EAAoB,CAC7B,CCtJA,OAAS,cAAAC,EAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UACnE,OAAS,YAAAC,MAAgB,qBAOzB,SAASC,GAAeC,EAA6B,CACnD,IAAMC,EAAc,GAAGD,CAAU,qCAGjC,GAAI,CAACE,EAAWD,CAAW,EACzB,MAAO,GAIT,GAAI,CACF,IAAME,EAASC,EAAS,4BAA6B,CACnD,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAED,GAAI,sBAAsB,KAAKG,CAAM,EACnC,MAAO,EAEX,MAAQ,CAEN,MAAO,EACT,CAEA,OAAAE,EAAQ,kBAAmB,0CAA0C,EAC9D,EACT,CAKA,SAASC,GAASN,EAAoBO,EAA0B,CAC9D,IAAIC,EAAW,EAGf,GACEN,EAAW,GAAGF,CAAU,aAAa,GACrCE,EAAW,GAAGF,CAAU,iBAAiB,GACxCE,EAAW,GAAGF,CAAU,QAAQ,GAAKE,EAAW,GAAGF,CAAU,mBAAmB,EACjF,CACAK,EAAQ,kBAAmB,4CAA4C,EACvE,GAAI,CACFD,EAAS,qCAAsC,CAC7C,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNQ,EAAW,CACb,CACF,CAGA,GAAIN,EAAW,GAAGF,CAAU,eAAe,EAAG,CAC5CK,EAAQ,kBAAmB,6BAA6B,EACxD,GAAI,CAEF,GADoB,KAAK,MAAMI,GAAa,GAAGT,CAAU,gBAAiB,OAAO,CAAC,EAClE,SAAS,KAAM,CAC7BK,EAAQ,kBAAmB,qBAAqB,EAGhD,IAAIK,EAAM,iDACV,GAAI,CACFN,EAAS,aAAc,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EAC5EM,EAAM,6BACR,MAAQ,CACN,GAAI,CACFN,EAAS,aAAc,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EAC5EM,EAAM,6BACR,MAAQ,CAER,CACF,CAEAN,EAASM,EAAK,CACZ,IAAKV,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,CACF,MAAQ,CACNQ,EAAW,CACb,CACF,CAGA,GAAIN,EAAW,GAAGF,CAAU,SAAS,EAAG,CACtCK,EAAQ,kBAAmB,yCAAyC,EACpE,GAAI,CACFD,EAAS,+BAAgC,CACvC,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNQ,EAAW,CACb,CACF,CAGA,GAAIN,EAAW,GAAGF,CAAU,aAAa,EAAG,CAC1CK,EAAQ,kBAAmB,8CAA8C,EACzE,GAAI,CACFD,EAAS,aAAc,CACrB,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNQ,EAAW,CACb,CACF,CAEA,OAAOA,IAAa,CACtB,CAKO,SAASG,GAAcC,EAA8B,CAC1DP,EAAQ,kBAAmB,iCAAiC,EAE5D,IAAML,EAAaY,EAAM,aAAeC,EAAc,EAChDC,EAAS,GAAGd,CAAU,sBAG5B,GAAI,CACFe,GAAUD,EAAQ,CAAE,UAAW,EAAK,CAAC,CACvC,MAAQ,CAER,CAEA,IAAMP,EAAU,GAAGO,CAAM,uBAEzB,GAAI,CAACf,GAAeC,CAAU,EAC5B,OAAOgB,EAAoB,EAK7B,GAFeV,GAASN,EAAYO,CAAO,EAE/B,CACVF,EAAQ,kBAAmB,0BAA0B,EAErD,GAAI,CACFY,GAAc,GAAGH,CAAM,kBAAmB,OAAO,KAAK,IAAI,CAAC,CAAC,CAC9D,MAAQ,CAER,CACF,MACET,EAAQ,kBAAmB,2BAA2B,EAIxD,OAAOW,EAAoB,CAC7B,CCvKA,OAAS,cAAAE,GAAY,gBAAAC,GAAc,cAAAC,GAAY,aAAAC,OAAiB,UAChE,OAAS,YAAAC,MAAgB,qBAiBzB,SAASC,IAAyB,CAChC,GAAI,CACF,OAAAC,EAAS,WAAY,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EAC1EA,EAAS,iBAAkB,CAAE,SAAU,OAAQ,QAAS,IAAM,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,EACxF,EACT,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAaC,EAA6B,CACjD,GAAI,CAOF,OANeF,EAAS,4BAA6B,CACnD,IAAKE,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACa,SAAS,QAAQ,CACjC,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAgBC,EAAkBC,EAAuCC,EAA2B,CAC3G,IAAMC,EAAUF,EAAK,SAAW,CAAC,EACjC,GAAIE,EAAQ,SAAW,EACrB,MAAO,GAGT,IAAMC,EAAiBD,EAAQ,IAAKE,GAAM,OAAOA,EAAE,GAAG,OAAOA,EAAE,OAAO,EAAE,EAAE,KAAK;AAAA,CAAI,EAC7EC,EACJL,EAAK,iBAAiB,OAAS,EAC3B;AAAA,EAA4BA,EAAK,gBAAgB,IAAKM,GAAM,SAASA,CAAC,EAAE,EAAE,KAAK;AAAA,CAAI,CAAC,GACpF,GAEN,MAAO;AAAA;AAAA,iBAEQL,EAAU,MAAM,EAAG,CAAC,CAAC;AAAA,gBACtBD,EAAK,QAAU,SAAS;AAAA;AAAA,eAEzBE,EAAQ,MAAM;AAAA,EAC3BC,CAAc;AAAA;AAAA,EAEdE,CAAY;AAAA;AAAA,wEAGd,CAKA,SAASE,GAAYR,EAAkBS,EAA0B,CAC/D,GAAI,CACF,OAAAb,EAAS,oBAAoBI,CAAQ,YAAYS,EAAQ,QAAQ,KAAM,KAAK,CAAC,IAAK,CAChF,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACM,EACT,MAAQ,CACN,MAAO,EACT,CACF,CAKO,SAASC,EAAiBC,EAA8B,CAC7DC,EAAQ,qBAAsB,wDAAwD,EAEtF,IAAMd,EAAaa,EAAM,aAAeE,EAAc,EAChDX,EAAYS,EAAM,YAAcG,EAAa,EAI7CC,EAAa,uBADGb,EAAU,QAAQ,kBAAmB,EAAE,CACN,GACjDc,EAAe,GAAGD,CAAU,uBAGlC,GAAI,CAACE,GAAWD,CAAY,EAC1B,OAAAJ,EAAQ,qBAAsB,6BAA6BI,CAAY,EAAE,EAClEE,EAAoB,EAI7B,GAAI,CAACvB,GAAc,EACjB,OAAAiB,EAAQ,qBAAsB,qDAAqD,EAC5EM,EAAoB,EAI7B,GAAI,CAACrB,GAAaC,CAAU,EAC1B,OAAAc,EAAQ,qBAAsB,mCAAmC,EAC1DM,EAAoB,EAI7B,IAAIC,EACJ,GAAI,CACFA,EAAe,KAAK,MAAMC,GAAaJ,EAAc,OAAO,CAAC,CAC/D,MAAQ,CACN,OAAAJ,EAAQ,qBAAsB,8BAA8B,EACrDM,EAAoB,CAC7B,CAEA,IAAMG,EAASF,EAAa,OAAS,OAAO,KAAKA,EAAa,MAAM,EAAI,CAAC,EACzE,GAAIE,EAAO,SAAW,EACpB,OAAAT,EAAQ,qBAAsB,sBAAsB,EAC7CM,EAAoB,EAI7B,IAAII,EAAc,EAClB,QAAWtB,KAAYqB,EAAQ,CAC7B,IAAME,EAAYJ,EAAa,OAAOnB,CAAQ,EAG9C,IAFgBuB,EAAU,SAAW,CAAC,GAE1B,SAAW,EAAG,CACxBX,EAAQ,qBAAsB,yBAAyBZ,CAAQ,YAAY,EAC3E,QACF,CAGA,GAAI,CACFJ,EAAS,iBAAiBI,CAAQ,iBAAkB,CAClD,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CACNY,EAAQ,qBAAsB,UAAUZ,CAAQ,wCAAwC,EACxF,QACF,CAGA,IAAMS,EAAUV,GAAgBC,EAAUuB,EAAWrB,CAAS,EAC1DO,GAAWD,GAAYR,EAAUS,CAAO,IAC1Ca,IACAV,EAAQ,qBAAsB,yCAAyCZ,CAAQ,EAAE,EAErF,CAEAY,EAAQ,qBAAsB,+BAA+BU,CAAW,WAAW,EAGnF,GAAI,CACFE,GAAWR,CAAY,EAEvB,GAAI,CACFS,GAAUV,CAAU,CACtB,MAAQ,CAER,CACAH,EAAQ,qBAAsB,0BAA0B,CAC1D,MAAQ,CAER,CAEA,OAAOM,EAAoB,CAC7B,CCpLA,OAAS,cAAAQ,EAAY,gBAAAC,EAAc,aAAAC,GAAW,kBAAAC,EAAgB,iBAAAC,OAAqB,UACnF,OAAS,SAAAC,OAAa,qBAOtB,SAASC,GAAsBC,EAAqBC,EAA2B,CAC7E,GAAI,CAACC,EAAWF,CAAW,EACzB,MAAO,GAGT,GAAI,CAEF,IAAMG,EADY,KAAK,MAAMC,EAAaJ,EAAa,OAAO,CAAC,EAChC,WAAa,CAAC,EAE7C,GAAIE,EAAWD,CAAS,EAAG,CAEzB,IAAMI,EADQ,KAAK,MAAMD,EAAaH,EAAW,OAAO,CAAC,EACjC,kBAAoB,CAAC,EAC7C,OAAOE,EAAa,OAAQG,GAA+B,CAACD,EAAU,SAASC,EAAE,WAAW,CAAC,EAAE,MACjG,CAEA,OAAOH,EAAa,MACtB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASI,GAAqBC,EAA6D,CACzF,GAAI,CAACN,EAAWM,CAAW,EACzB,MAAO,CAAE,MAAO,EAAG,SAAU,CAAC,CAAE,EAGlC,GAAI,CACF,IAAMC,EAAUL,EAAaI,EAAa,OAAO,EAE7CE,EACJ,GAAI,CACFA,EAAWD,EACR,MAAM;AAAA,CAAI,EACV,OAAQE,GAASA,EAAK,KAAK,CAAC,EAC5B,IAAKA,GAAS,KAAK,MAAMA,CAAI,CAAC,CACnC,MAAQ,CACND,EAAW,CAAC,KAAK,MAAMD,CAAO,CAAC,CACjC,CAEA,IAAMG,EAAUF,EAAS,OAAQG,GAAWA,EAAE,eAAiB,EAAI,EACnE,MAAO,CAAE,MAAOD,EAAQ,OAAQ,SAAUA,CAAQ,CACpD,MAAQ,CACN,MAAO,CAAE,MAAO,EAAG,SAAU,CAAC,CAAE,CAClC,CACF,CAKA,SAASE,GAAaC,EAA4B,CAChD,OAAOA,EAAW,MAAM,GAAG,EAAE,IAAI,GAAK,SACxC,CAKA,SAASC,GAAmBD,EAI1B,CACA,IAAIE,EAAc,GACdC,EAAW,GACXC,EAAY,GAEVC,EAAe,GAAGL,CAAU,sCAClC,GAAIb,EAAWkB,CAAY,EACzB,GAAI,CACF,IAAMC,EAAQ,KAAK,MAAMjB,EAAagB,EAAc,OAAO,CAAC,EAC5DH,EAAcI,EAAM,cAAgBA,EAAM,MAAQ,EACpD,MAAQ,CAER,CAGF,IAAMC,EAAc,GAAGP,CAAU,+BACjC,GAAIb,EAAWoB,CAAW,EACxB,GAAI,CAOFJ,EANgBd,EAAakB,EAAa,OAAO,EAE9C,MAAM;AAAA,CAAI,EACV,OAAQX,GAASA,EAAK,KAAK,CAAC,EAC5B,IAAKA,GAAS,KAAK,MAAMA,CAAI,CAAC,EACA,OAAQY,GAAM,CAACA,EAAE,QAAQ,EAAE,MAAM,EAAE,EACtC,IAAKA,GAAMA,EAAE,aAAe,EAAE,EAAE,KAAK,IAAI,CACzE,MAAQ,CAER,CAGF,MAAO,CAAE,YAAAN,EAAa,SAAAC,EAAU,UAAAC,CAAU,CAC5C,CAKO,SAASK,GAAsBC,EAA8B,CAElE,GAAI,CAAC,QAAQ,IAAI,aACf,OAAAC,EAAQ,2BAA4B,iDAAiD,EAC9EC,EAAoB,EAG7B,IAAMZ,EAAaU,EAAM,aAAeG,EAAc,EAChDC,EAAaC,GAAc,EAE3B9B,EAAc,GAAG6B,CAAU,0CAC3BrB,EAAc,GAAGO,CAAU,qCAC3Bd,EAAY,GAAG4B,CAAU,kDAGzBE,EAAgBhC,GAAsBC,EAAaC,CAAS,EAC5D,CAAE,MAAO+B,EAAc,SAAUC,CAAgB,EAAI1B,GAAqBC,CAAW,EAGrF,CAAE,YAAAS,EAAa,SAAAC,EAAU,UAAAC,CAAU,EAAIH,GAAmBD,CAAU,EAG1E,GAAIgB,IAAkB,GAAKC,IAAiB,GAAK,CAACf,EAChD,OAAOU,EAAoB,EAG7B,IAAMO,EAAYpB,GAAaC,CAAU,EACnCoB,EAAU,GAAGpB,CAAU,8BAG7B,GAAI,CACFqB,GAAU,GAAGrB,CAAU,gBAAiB,CAAE,UAAW,EAAK,CAAC,CAC7D,MAAQ,CAER,CAGA,IAAMsB,EAAqB,CAAC,EAI5B,GAHIN,EAAgB,GAClBM,EAAS,KAAK,GAAGN,CAAa,oBAAoB,EAEhDC,EAAe,EAAG,CACpBK,EAAS,KAAK,GAAGL,CAAY,yBAAyB,EAGtD,IAAMM,EAAW,IAAI,IAAIL,EAAgB,IAAKpB,GAAWA,EAAE,UAAYA,EAAE,KAAK,EAAE,OAAO,OAAO,CAAC,EACzF0B,EAAe,MAAM,KAAKD,CAAQ,EAAE,MAAM,EAAG,CAAC,EAChDC,EAAa,OAAS,GACxBF,EAAS,KAAK,WAAWE,EAAa,KAAK,IAAI,CAAC,EAAE,CAEtD,CAEA,IAAMC,GAAUH,EAAS,OAAS,EAAIA,EAAS,KAAK,IAAI,EAAI,mBAGxDI,EAAcxB,GAAe,eAC7Bc,EAAgB,IAClBU,GAAe,KAAKV,CAAa,oBAE/BC,EAAe,IACjBS,GAAe,KAAKT,CAAY,sBAGlC,IAAIU,EAAc,oBAAoBD,CAAW,GAC7CvB,IACFwB,GAAe,gBAAgBxB,CAAQ,IAErCC,IACFuB,GAAe,YAAYvB,CAAS,IAItC,IAAMwB,GAAa,GAAGd,CAAU,iDAC1Be,GAAa,QAAQ,IAAI,aAE3BC,EAEJ,GAAI3C,EAAWyC,EAAU,GAAKC,GAAY,CACxC,IAAME,EAAY,IAAI,KAAK,EAAE,YAAY,EACzC,GAAI,CACFC,EAAeZ,EAAS,IAAIW,CAAS;AAAA,CAA6C,CACpF,MAAQ,CAER,CAGA,IAAME,EAAkB,KAAK,UAAU,CACrC,KAAM,kBACN,OAAQ,cACR,QAASd,EACT,aAAc,CAAC,CAAChB,EAChB,eAAgB,CAAC,CAACC,EAClB,OAAQ,mBACV,CAAC,EAEK8B,EAAQC,GACZ,UACA,CACEP,GACA,SACAD,EACA,YACA,GAAGR,CAAS,cACZ,aACAc,EACA,gBACF,EACA,CACE,SAAU,GACV,MAAO,CAAC,SAAU,OAAQ,MAAM,CAClC,CACF,EAwBA,GAtBAC,EAAM,GAAG,QAAUE,GAAQ,CACzB,IAAMC,EAAe,IAAI,KAAK,EAAE,YAAY,EAC5C,GAAI,CACFL,EAAeZ,EAAS,IAAIiB,CAAY,+BAA+BD,EAAI,OAAO;AAAA,CAAI,CACxF,MAAQ,CAER,CACF,CAAC,EAEDF,EAAM,GAAG,QAAUI,GAAS,CAC1B,IAAMC,EAAiB,IAAI,KAAK,EAAE,YAAY,EAC9C,GAAI,CACED,IAAS,EACXN,EAAeZ,EAAS,IAAImB,CAAc;AAAA,CAAiC,EAE3EP,EAAeZ,EAAS,IAAImB,CAAc,2BAA2BD,CAAI;AAAA,CAAI,CAEjF,MAAQ,CAER,CACF,CAAC,EAEGJ,EAAM,OAAQ,CAChB,IAAIM,EAAa,GACjBN,EAAM,OAAO,GAAG,OAASO,GAAkB,CACzCD,GAAcC,EAAM,SAAS,CAC/B,CAAC,EACDP,EAAM,OAAO,GAAG,MAAO,IAAM,CAC3B,GAAIM,EAAW,KAAK,EAAG,CACrB,IAAMH,EAAe,IAAI,KAAK,EAAE,YAAY,EAC5C,GAAI,CACFL,EAAeZ,EAAS,IAAIiB,CAAY,kBAAkBG,EAAW,KAAK,CAAC;AAAA,CAAI,CACjF,MAAQ,CAER,CACF,CACF,CAAC,CACH,CAKA,GAHAN,EAAM,MAAM,EAGRjB,EAAe,GAAK9B,EAAWM,CAAW,EAC5C,GAAI,CAEF,IAAMiD,EADUrD,EAAaI,EAAa,OAAO,EAE9C,MAAM;AAAA,CAAI,EACV,OAAQG,GAASA,EAAK,KAAK,CAAC,EAC5B,IAAKA,GAAS,CACb,IAAM+C,GAAM,KAAK,MAAM/C,CAAI,EAC3B,OAAA+C,GAAI,aAAe,GACZ,KAAK,UAAUA,EAAG,CAC3B,CAAC,EACA,KAAK;AAAA,CAAI,EACZC,GAAcnD,EAAaiD,CAAO,CACpC,MAAQ,CAER,CAGFZ,EAAW,4BAA4BL,EAAO,EAChD,MACEK,EAAW,eAAeL,EAAO,mDAGnC,OAAAd,EAAQ,2BAA4BmB,CAAQ,EAErC,CACL,SAAU,GACV,cAAeA,CACjB,CACF,CCxSA,OAAS,cAAAe,EAAY,gBAAAC,GAAc,cAAAC,OAAkD,UACrF,OAAS,YAAAC,OAAuB,qBAOhC,SAASC,EAAUC,EAAgBC,EAAmB,CACpD,GAAI,CACFC,GAAS,YAAYF,CAAM,MAAMC,CAAG,IAAK,CACvC,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,MAAQ,CAER,CACF,CAKA,SAASE,GAASH,EAAgBI,EAA4B,CAC5D,GAAI,CAKF,OAJeF,GACb,YAAYF,CAAM,sEAAsEI,CAAS,MACjG,CAAE,SAAU,OAAQ,QAAS,IAAM,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CACrE,EAAE,KAAK,IACW,GACpB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAcC,EAA2B,CAChD,IAAMC,EAAU,GAAGD,CAAW,iBAC9B,GAAKE,EAAWD,CAAO,EAIvB,GAAI,CACF,IAAME,EAAM,SAASC,GAAaH,EAAS,OAAO,EAAE,KAAK,EAAG,EAAE,EAC9D,GAAI,CACF,QAAQ,KAAKE,EAAK,CAAC,EACnB,QAAQ,KAAKA,CAAG,EAChBE,EAAQ,yBAA0B,mCAAmCF,CAAG,GAAG,CAC7E,MAAQ,CAER,CACAG,GAAWL,CAAO,CACpB,MAAQ,CAER,CACF,CAKA,SAASM,GAAab,EAAgBc,EAA0B,CAC9DH,EAAQ,yBAA0B,wBAAwB,EAC1DZ,EAAUC,EAAQ,+CAA+Cc,CAAU,IAAI,EAC/EH,EAAQ,yBAA0B,oBAAoB,CACxD,CAKA,SAASI,GAAiBf,EAAgBc,EAA0B,CAClEH,EAAQ,yBAA0B,yBAAyB,EAEvDR,GAASH,EAAQ,aAAa,GAChCD,EACEC,EACA,oGAAoGc,CAAU,0BAChH,EACAH,EAAQ,yBAA0B,qBAAqB,GAEvDA,EAAQ,yBAA0B,gCAAgC,CAEtE,CAKA,SAASK,GAAqBhB,EAAgBc,EAA0B,CAClEX,GAASH,EAAQ,WAAW,GAC9BD,EACEC,EACA,4FAA4Fc,CAAU,IACxG,EACAH,EAAQ,yBAA0B,uCAAuC,GAEzEA,EAAQ,yBAA0B,4CAA4C,CAElF,CAKA,SAASM,GAAkBjB,EAAgBc,EAA0B,CACnE,GAAI,CAACX,GAASH,EAAQ,UAAU,EAAG,CACjCW,EAAQ,yBAA0B,uCAAuC,EACzE,MACF,CAEA,IAAMO,EAAY,OAAO,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,MAAM,EAAG,EAAE,CAAC,GAC1DC,EAAY,IAAI,KAAK,EAAE,YAAY,EACnCC,EAAU,KAAK,UAAU,CAAE,YAAaN,EAAY,UAAAK,CAAU,CAAC,EAAE,QAAQ,KAAM,IAAI,EAEzFpB,EACEC,EACA,6GAA6GkB,CAAS,OAAOJ,CAAU,yBAAyBM,CAAO,iCACzK,EACAT,EAAQ,yBAA0B,yBAAyB,CAC7D,CAKA,SAASU,GAAqBf,EAA2B,CACvD,IAAMgB,EAAgB,CAAC,uBAAwB,cAAe,0BAA0B,EAExF,QAAWC,KAAQD,EAAe,CAChC,IAAME,EAAW,GAAGlB,CAAW,IAAIiB,CAAI,GACvC,GAAI,CACEf,EAAWgB,CAAQ,GACrBZ,GAAWY,CAAQ,CAEvB,MAAQ,CAER,CACF,CAEAb,EAAQ,yBAA0B,2BAA2B,CAC/D,CAKO,SAASc,GAAqBC,EAA8B,CACjE,IAAMC,EAAaD,EAAM,aAAeE,EAAc,EAChDtB,EAAc,GAAGqB,CAAU,aAC3B3B,EAAS,GAAG2B,CAAU,mCAG5B,GAAI,CAACnB,EAAWR,CAAM,EACpB,OAAAW,EAAQ,yBAA0B,4CAA4C,EACvEkB,EAAoB,EAI7B,IAAMC,EAAS,GAAGxB,CAAW,WAC7B,GAAI,CAACE,EAAWsB,CAAM,EACpB,OAAAnB,EAAQ,yBAA0B,wCAAwC,EACnEkB,EAAoB,EAI7B,IAAIf,EACJ,GAAI,CAEFA,EADe,KAAK,MAAMJ,GAAaoB,EAAQ,OAAO,CAAC,EACnC,WACtB,MAAQ,CACN,OAAAnB,EAAQ,yBAA0B,4BAA4B,EACvDkB,EAAoB,CAC7B,CAEA,OAAAlB,EAAQ,yBAA0B,uCAAuCG,CAAU,KAAK,EAGxFT,GAAcC,CAAW,EAGzBO,GAAab,EAAQc,CAAU,EAG/BC,GAAiBf,EAAQc,CAAU,EAGnCG,GAAkBjB,EAAQc,CAAU,EAGpCE,GAAqBhB,EAAQc,CAAU,EAGvCO,GAAqBf,CAAW,EAEhCK,EAAQ,yBAA0B,yBAAyB,EAC3DA,EAAQ,yBAA0B,aAAaG,CAAU,EAAE,EAC3DH,EAAQ,yBAA0B,oBAAoB,EACtDA,EAAQ,yBAA0B,kCAAkC,EAE7DkB,EAAoB,CAC7B,CCpMA,OAAS,cAAAE,EAAY,aAAAC,GAAW,gBAAAC,GAAc,iBAAAC,EAAe,eAAAC,OAAmB,UAChF,OAAS,YAAAC,MAAgB,qBAezB,SAASC,GAAYC,EAAoBC,EAA+D,CACtG,GACE,CAACC,EAAW,GAAGF,CAAU,eAAe,GACvC,CAACE,EAAW,GAAGF,CAAU,oBAAoB,GAC5C,CAACE,EAAW,GAAGF,CAAU,YAAY,GACrC,CAACE,EAAW,GAAGF,CAAU,iBAAiB,EAE5C,OAAO,KAGTG,EAAQ,gBAAiB,sBAAsB,EAC/C,GAAI,CACFC,EAAS,mBAAoB,CAC3B,IAAKJ,EACL,SAAU,OACV,QAAS,KACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,CACH,OAASK,EAAY,CAEnB,GAAIA,EAAM,OAAQ,CAChBC,EAAc,GAAGL,CAAU,kBAAmBI,EAAM,MAAM,EAC1D,GAAI,CACF,IAAME,EAAS,KAAK,MAAMF,EAAM,MAAM,EACtC,MAAO,CACL,SAAUE,EAAO,UAAU,iBAAiB,UAAY,EACxD,KAAMA,EAAO,UAAU,iBAAiB,MAAQ,CAClD,CACF,MAAQ,CAER,CACF,CACF,CACA,OAAAJ,EAAQ,gBAAiB,oBAAoB,EACtC,CAAE,SAAU,EAAG,KAAM,CAAE,CAChC,CAKA,SAASK,GAAYR,EAAoBC,EAAmC,CAC1E,GAAI,CAACC,EAAW,GAAGF,CAAU,mBAAmB,GAAK,CAACE,EAAW,GAAGF,CAAU,iBAAiB,EAC7F,OAAO,KAGT,GAAI,CACFI,EAAS,kBAAmB,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,CACnF,MAAQ,CACN,OAAAD,EAAQ,gBAAiB,mCAAmC,EACrD,IACT,CAEAA,EAAQ,gBAAiB,sBAAsB,EAC/C,GAAI,CACF,IAAMI,EAASH,EAAS,0BAA2B,CACjD,IAAKJ,EACL,SAAU,OACV,QAAS,KACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACDM,EAAc,GAAGL,CAAU,kBAAmBM,CAAM,EACpD,IAAME,EAAS,KAAK,MAAMF,CAAM,EAChC,OAAAJ,EAAQ,gBAAiB,oBAAoB,EACtC,MAAM,QAAQM,CAAM,EAAIA,EAAO,OAAS,CACjD,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAWV,EAAoBC,EAAmC,CACzE,GAAI,CACFG,EAAS,gBAAiB,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,CACjF,MAAQ,CACN,OAAAD,EAAQ,gBAAiB,iCAAiC,EACnD,IACT,CAEAA,EAAQ,gBAAiB,oBAAoB,EAC7C,GAAI,CACF,IAAMI,EAASH,EAAS,uCAAwC,CAC9D,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACDM,EAAc,GAAGL,CAAU,gBAAiBM,CAAM,EAElD,IAAMI,GADS,KAAK,MAAMJ,CAAM,EACH,SAAW,CAAC,GAAG,OAAQ,GAAW,EAAE,OAAO,WAAa,OAAO,EAAE,OAC9F,OAAAJ,EAAQ,gBAAiB,kBAAkB,EACpCQ,CACT,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAUZ,EAAoBC,EAAmC,CAExE,GAAI,CAOF,GAAI,CANcG,EAAS,4CAA6C,CACtE,IAAKJ,EACL,SAAU,OACV,QAAS,IACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EAAE,KAAK,GACU,CAACE,EAAW,GAAGF,CAAU,UAAU,EACnD,OAAO,IAEX,MAAQ,CACN,OAAO,IACT,CAEA,GAAI,CACFI,EAAS,eAAgB,CAAE,SAAU,OAAQ,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAAE,CAAC,CAChF,MAAQ,CACN,OAAAD,EAAQ,gBAAiB,gCAAgC,EAClD,IACT,CAEAA,EAAQ,gBAAiB,mBAAmB,EAC5C,GAAI,CACF,OAAAC,EAAS,0BAA0BH,CAAU,eAAgB,CAC3D,IAAKD,EACL,SAAU,OACV,QAAS,KACT,MAAO,CAAC,OAAQ,OAAQ,MAAM,CAChC,CAAC,EACDG,EAAQ,gBAAiB,iBAAiB,EACnC,CACT,MAAQ,CAEN,MAAO,EACT,CACF,CAKA,SAASU,GAAcb,EAAoBC,EAA4B,CACrEE,EAAQ,gBAAiB,6BAA6B,EAEtD,IAAMW,EAAiB,sEACnBC,EAAe,EACbC,EAAkD,CAAC,EAEnDC,EAAa,CAAC,MAAO,MAAO,MAAO,MAAM,EAE/C,SAASC,EAAQC,EAAmB,CAClC,GAAI,CACF,IAAMC,EAAUC,GAAYF,EAAK,CAAE,cAAe,EAAK,CAAC,EACxD,QAAWG,KAASF,EAAS,CAC3B,IAAMG,EAAW,GAAGJ,CAAG,IAAIG,EAAM,IAAI,GAGrC,GAAIA,EAAM,YAAY,EAAG,CAClB,CAAC,eAAgB,OAAQ,OAAQ,OAAO,EAAE,SAASA,EAAM,IAAI,GAChEJ,EAAQK,CAAQ,EAElB,QACF,CAGA,GAAKN,EAAW,KAAMO,GAAQF,EAAM,KAAK,SAASE,CAAG,CAAC,EAItD,GAAI,CACF,IAAMC,EAAUC,GAAaH,EAAU,OAAO,EAC1CT,EAAe,KAAKW,CAAO,IAC7BT,EAAS,KAAK,CAAE,KAAMO,EAAU,KAAM,kBAAmB,CAAC,EAC1DR,IAEJ,MAAQ,CAER,CACF,CACF,MAAQ,CAER,CACF,CAEA,OAAAG,EAAQlB,CAAU,EAElBM,EACE,GAAGL,CAAU,gBACb,KAAK,UAAU,CAAE,SAAAe,EAAU,MAAOD,CAAa,EAAG,KAAM,CAAC,CAC3D,EAEAZ,EAAQ,gBAAiB,8BAA8BY,CAAY,mBAAmB,EAC/EA,CACT,CAKA,SAASY,GAAiB1B,EAAoB2B,EAAgC,CAC5EzB,EAAQ,gBAAiB,wBAAwB,EAEjD,IAAI0B,EAAgB,EAChBC,EAAY,EAEZF,EAAQ,WACVC,GAAiBD,EAAQ,SAAS,SAClCE,GAAaF,EAAQ,SAAS,MAE5BA,EAAQ,WAAa,OACvBE,GAAaF,EAAQ,UAEnBA,EAAQ,UAAY,OACtBE,GAAaF,EAAQ,SAGvB,IAAMG,EAAiBV,GAAYpB,CAAU,EAC1C,OAAQ+B,GAAMA,EAAE,SAAS,OAAO,GAAK,CAACA,EAAE,SAAS,YAAY,CAAC,EAC9D,IAAKA,GAAMA,EAAE,QAAQ,QAAS,EAAE,CAAC,EAE9BC,EAAS,CACb,UAAW,IAAI,KAAK,EAAE,YAAY,EAClC,QAAS,CACP,SAAUJ,EACV,KAAMC,EACN,OAAQ,CACV,EACA,gBAAiBC,CACnB,EAEAzB,EAAc,GAAGL,CAAU,0BAA2B,KAAK,UAAUgC,EAAQ,KAAM,CAAC,CAAC,EAErF9B,EAAQ,gBAAiB,gCAAgC,EACzDA,EAAQ,gBAAiB,aAAa0B,CAAa,WAAWC,CAAS,EAAE,EAErED,EAAgB,GAClB,QAAQ,MAAM,aAAaA,CAAa,cAAcC,CAAS,6BAA6B,CAEhG,CAKO,SAASI,GAAuBC,EAA8B,CACnEhC,EAAQ,gBAAiB,+BAA+B,EAExD,IAAMH,EAAamC,EAAM,aAAeC,EAAc,EAChDnC,EAAa,GAAGD,CAAU,+BAEhCqC,GAAUpC,EAAY,CAAE,UAAW,EAAK,CAAC,EAEzC,IAAM2B,EAA2B,CAC/B,SAAU,KACV,SAAU,KACV,QAAS,KACT,OAAQ,KACR,QAAS,CACX,EAGA,OAAAA,EAAQ,SAAW7B,GAAYC,EAAYC,CAAU,EACrD2B,EAAQ,SAAWpB,GAAYR,EAAYC,CAAU,EACrD2B,EAAQ,QAAUlB,GAAWV,EAAYC,CAAU,EACnD2B,EAAQ,OAAShB,GAAUZ,EAAYC,CAAU,EACjD2B,EAAQ,QAAUf,GAAcb,EAAYC,CAAU,EAGtD0B,GAAiB1B,EAAY2B,CAAO,EAE7BU,EAAoB,CAC7B,CCzRA,OAAS,cAAAC,EAAY,aAAAC,EAAW,gBAAAC,EAAc,iBAAAC,OAAqB,UAwCnE,SAASC,GAAoBC,EAA6B,CACxD,GAAI,CAACC,EAAWD,CAAW,EACzB,MAAO,GAGT,GAAI,CAEF,IAAME,EAD0B,KAAK,MAAMC,EAAaH,EAAa,OAAO,CAAC,EACvD,OAAS,CAAC,EAKhC,OAJe,OAAO,QAAQE,CAAK,EAChC,KAAK,CAAC,CAAC,CAAEE,CAAC,EAAG,CAAC,CAAEC,CAAC,IAAMA,EAAID,CAAC,EAC5B,MAAM,EAAG,EAAE,EACX,IAAI,CAAC,CAACE,CAAI,IAAMA,CAAI,EACT,KAAK,GAAG,CACxB,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAaP,EAA6B,CACjD,GAAI,CAACC,EAAWD,CAAW,EACzB,MAAO,GAGT,GAAI,CAEF,IAAME,EAD0B,KAAK,MAAMC,EAAaH,EAAa,OAAO,CAAC,EACvD,OAAS,CAAC,EAChC,OAAO,OAAO,OAAOE,CAAK,EAAE,OAAO,CAACM,EAAKC,IAAUD,EAAMC,EAAO,CAAC,CACnE,MAAQ,CACN,MAAO,EACT,CACF,CAKA,SAASC,GAAmBR,EAAuB,CACjD,OAAIA,EAAM,SAAS,OAAO,GAAKA,EAAM,SAAS,MAAM,GAC9C,2BAA2B,KAAKA,CAAK,EAChC,0BAIPA,EAAM,SAAS,MAAM,GAAKA,EAAM,SAAS,MAAM,EAC1C,mBAGLA,EAAM,SAAS,MAAM,GAAK,CAACA,EAAM,SAAS,OAAO,EAC5C,cAGLA,EAAM,SAAS,OAAO,GAAKA,EAAM,SAAS,MAAM,EAC3C,sBAGLA,EAAM,SAAS,MAAM,GAAK,UAAU,KAAKA,CAAK,EACzC,iBAGF,SACT,CAKA,SAASS,GAAuBT,EAAuB,CAGrD,MAAO,SACT,CAKA,SAASU,GAAoBC,EAAsC,CACjE,GAAIZ,EAAWY,CAAW,EACxB,GAAI,CACF,OAAO,KAAK,MAAMV,EAAaU,EAAa,OAAO,CAAC,CACtD,MAAQ,CAER,CAGF,MAAO,CACL,QAAS,QACT,aAAc,KACd,eAAgB,EAChB,eAAgB,CACd,0BAA2B,EAC3B,mBAAoB,EACpB,YAAa,EACb,sBAAuB,EACvB,iBAAkB,EAClB,QAAS,CACX,EACA,sBAAuB,CAAC,EACxB,mBAAoB,CAClB,OAAQ,EACR,WAAY,EACZ,WAAY,EACZ,GAAI,EACJ,KAAM,EACN,QAAS,CACX,EACA,0BAA2B,EAC3B,iCAAkC,EAClC,eAAgB,CAAC,CACnB,CACF,CAKA,SAASC,GACPD,EACAE,EACAC,EACAC,EACAC,EACM,CACN,IAAMC,EAAUP,GAAoBC,CAAW,EACzCO,EAAY,IAAI,KAAK,EAAE,YAAY,EAiBzC,GAfAD,EAAQ,aAAeC,EACvBD,EAAQ,gBAAkB,EAG1BA,EAAQ,eAAeJ,CAAY,GAAKI,EAAQ,eAAeJ,CAAY,GAAK,GAAK,EAGrFI,EAAQ,mBAAmBH,CAAY,GAAKG,EAAQ,mBAAmBH,CAAY,GAAK,GAAK,EAG7FG,EAAQ,2BACLA,EAAQ,2BAA6BA,EAAQ,eAAiB,GAAKF,GAAaE,EAAQ,eAGrED,EAAa,MAAM,GAAG,EAAE,OAAO,OAAO,EAC1C,OAAS,EAAG,CAC5B,IAAMG,EAAS,IAAI,IAAI,CAACH,EAAc,GAAGC,EAAQ,qBAAqB,CAAC,EACvEA,EAAQ,sBAAwB,MAAM,KAAKE,CAAM,EAAE,MAAM,EAAG,EAAE,CAChE,CAEAC,EAAUT,EAAY,QAAQ,WAAY,EAAE,EAAG,CAAE,UAAW,EAAK,CAAC,EAClEU,GAAcV,EAAa,KAAK,UAAUM,EAAS,KAAM,CAAC,CAAC,CAC7D,CAKA,SAASK,GAAiBC,EAAuC,CAC/D,GAAIxB,EAAWwB,CAAY,EACzB,GAAI,CACF,OAAO,KAAK,MAAMtB,EAAasB,EAAc,OAAO,CAAC,CACvD,MAAQ,CAER,CAGF,MAAO,CACL,QAAS,MACT,QAAS,GACT,SAAU,CAAC,EACX,WAAY,CAAC,EACb,MAAO,CACL,MAAO,EACP,UAAW,EACX,SAAU,CACZ,CACF,CACF,CAKA,SAASC,GAAcC,EAA0B,CAC/C,IAAMC,EAAY,GAAGD,CAAU,wCACzBF,EAAe,GAAGE,CAAU,0CAElC,GAAI,CAAC1B,EAAW2B,CAAS,EAAG,CAC1BC,EAAQ,mBAAoB,yBAAyB,EACrD,MACF,CAEA,IAAIC,EACJ,GAAI,CACFA,EAAQ,KAAK,MAAM3B,EAAayB,EAAW,OAAO,CAAC,CACrD,MAAQ,CACNC,EAAQ,mBAAoB,gCAAgC,EAC5D,MACF,CAEA,IAAME,EAAaD,EAAM,UAAU,QAAU,EAC7C,GAAIC,IAAe,EAAG,CACpBF,EAAQ,mBAAoB,yBAAyB,EACrD,MACF,CAEAA,EAAQ,mBAAoB,cAAcE,CAAU,qBAAqB,EAEzE,IAAMC,EAAWR,GAAiBC,CAAY,EACxCQ,EAAM,IAAI,KAAK,EAAE,YAAY,EAG7BC,EAAc,CAAC,GAAGF,EAAS,SAAU,GAAGF,EAAM,QAAQ,EACtDK,EAAa,IAAI,IACvB,QAAWC,KAAKF,EACdC,EAAW,IAAIC,EAAE,KAAMA,CAAC,EAE1B,IAAMC,EAAiB,MAAM,KAAKF,EAAW,OAAO,CAAC,EAG/CG,EAAYD,EAAe,OAAQD,GAAMA,EAAE,UAAY,SAAS,EAAE,OAClEG,EAAWF,EAAe,OAAQD,GAAMA,EAAE,UAAY,QAAQ,EAAE,OAGhEI,EAAqC,CAAC,EAC5C,QAAWJ,KAAKC,EACdG,EAAWJ,EAAE,QAAQ,GAAKI,EAAWJ,EAAE,QAAQ,GAAK,GAAK,EAG3D,IAAMK,EAA2B,CAC/B,QAAS,MACT,QAASR,EACT,SAAUI,EACV,WAAAG,EACA,MAAO,CACL,MAAOH,EAAe,OACtB,UAAAC,EACA,SAAAC,CACF,CACF,EAEAjB,EAAUG,EAAa,QAAQ,WAAY,EAAE,EAAG,CAAE,UAAW,EAAK,CAAC,EACnEF,GAAcE,EAAc,KAAK,UAAUgB,EAAS,KAAM,CAAC,CAAC,EAC5DZ,EAAQ,mBAAoB,8BAA8B,EAG1DN,GAAcK,EAAW,KAAK,UAAU,CAAE,SAAU,CAAC,CAAE,CAAC,CAAC,CAC3D,CAKO,SAASc,EAAgBC,EAA8B,CAC5Dd,EAAQ,mBAAoB,wCAAwC,EAEpE,IAAMF,EAAagB,EAAM,aAAeC,EAAc,EAChD5C,EAAc,mCACd6C,EAAkB,GAAGlB,CAAU,2CAGrCL,EAAU,GAAGK,CAAU,oBAAqB,CAAE,UAAW,EAAK,CAAC,EAC/DL,EAAU,GAAGK,CAAU,gBAAiB,CAAE,UAAW,EAAK,CAAC,EAG3D,IAAMV,EAAYV,GAAaP,CAAW,EAE1C,GAAIiB,GAAa,EAAG,CAClB,IAAMC,EAAenB,GAAoBC,CAAW,EAC9Ce,EAAeL,GAAmBQ,CAAY,EAC9CF,EAAeL,GAAuBO,CAAY,EAExDJ,GAAsB+B,EAAiB9B,EAAcC,EAAcC,EAAWC,CAAY,EAE1FW,EAAQ,mBAAoB,2BAA2Bd,CAAY,SAASC,CAAY,UAAUC,CAAS,EAAE,CAC/G,MACEY,EAAQ,mBAAoB,mDAAmDZ,CAAS,GAAG,EAI7F,OAAAS,GAAcC,CAAU,EAExBE,EAAQ,mBAAoB,6BAA6B,EAElDiB,EAAoB,CAC7B,CCrUA,OAAS,cAAAC,GAAY,gBAAAC,OAAoB,UCOzC,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UAuCnE,SAASC,IAA0B,CACjC,IAAMC,EAAYC,EAAa,EAC/B,MAAO,GAAGC,EAAc,CAAC,wCAAwCF,CAAS,OAC5E,CAEA,SAASG,IAAkB,CACzB,IAAMC,EAAM,GAAGF,EAAc,CAAC,yBAC9B,GAAI,CAACG,GAAWD,CAAG,EACjB,GAAI,CACFE,GAAUF,EAAK,CAAE,UAAW,EAAK,CAAC,CACpC,MAAQ,CAER,CAEJ,CAEA,SAASG,IAA6B,CACpC,IAAMC,EAAOT,GAAgB,EAE7B,GAAIM,GAAWG,CAAI,EACjB,GAAI,CACF,OAAO,KAAK,MAAMC,GAAaD,EAAM,MAAM,CAAC,CAC9C,MAAQ,CAER,CAGF,MAAO,CACL,cAAe,QACf,UAAWP,EAAa,EACxB,MAAO,CAAC,EACR,UAAW,CAAC,EACZ,UAAW,IAAI,KAAK,EAAE,YAAY,CACpC,CACF,CAEA,SAASS,GAAaC,EAA8B,CAClDR,GAAU,EACV,IAAMK,EAAOT,GAAgB,EAC7BY,EAAS,UAAY,IAAI,KAAK,EAAE,YAAY,EAE5C,GAAI,CACFC,GAAcJ,EAAM,KAAK,UAAUG,EAAU,KAAM,CAAC,CAAC,CACvD,OAASE,EAAK,CACZC,EAAQ,mBAAoB,4BAA4BD,CAAG,EAAE,CAC/D,CACF,CAyHO,SAASE,GAA0BC,EAAgBC,EAAwB,CAChF,MAAO;AAAA;AAAA;AAAA;AAAA,aAIID,CAAM;AAAA;AAAA;AAAA;AAAA,cAILC,CAAM,EACpB,CAwHO,SAASC,IAAgC,CAC9C,IAAMC,EAAWC,GAAa,EACxBC,EAAY,IAAI,IACpBF,EAAS,MAAM,OAAOG,GAAKA,EAAE,SAAW,QAAQ,EAAE,IAAIA,GAAKA,EAAE,MAAM,CACrE,EAEA,OAAID,EAAU,OAAS,EAAU,CAAC,EAE3BF,EAAS,MAAM,OAAOG,GACvBA,EAAE,SAAW,WAAa,CAACA,EAAE,WAAaA,EAAE,UAAU,SAAW,EAC5D,GAGFA,EAAE,UAAU,MAAMC,GAAMF,EAAU,IAAIE,CAAE,CAAC,CACjD,CACH,CA0GO,SAASC,GAAgBC,EAAmB,KAAU,GAAK,IAAY,CAC5E,IAAMC,EAAWC,GAAa,EACxBC,EAAS,KAAK,IAAI,EAAIH,EAE5BC,EAAS,MAAQA,EAAS,MAAM,OAAOG,GACjCA,EAAE,SAAW,WAAaA,EAAE,SAAW,cAAsB,GAChD,IAAI,KAAKA,EAAE,SAAS,EAAE,QAAQ,EAC7BD,CACnB,EAEDF,EAAS,UAAYA,EAAS,UAAU,OAAOI,GACzCA,EAAE,SAAW,UAAkB,GACd,IAAI,KAAKA,EAAE,SAAS,EAAE,QAAQ,EAC7BF,CACvB,EAEDG,GAAaL,CAAQ,CACvB,CDpdO,SAASM,GAAoBC,EAA8B,CAChEC,EAAQ,wBAAyB,sCAAsC,EAEvE,IAAMC,EAAqB,CAAC,EAGtBC,EAAaH,EAAM,aAAeI,EAAc,EAChDC,EAAYL,EAAM,YAAcM,EAAa,EAC7CC,EAAe,GAAGJ,CAAU,wCAAwCE,CAAS,QAEnF,GAAIG,GAAWD,CAAY,EACzB,GAAI,CAEF,IAAME,GADW,KAAK,MAAMC,GAAaH,EAAc,OAAO,CAAC,EAClC,OAAS,CAAC,GAAG,OACvCI,GAA0BA,EAAE,SAAW,aAC1C,EACIF,EAAW,OAAS,IACtBR,EAAQ,wBAAyB,YAAYQ,EAAW,MAAM,wCAAwC,EACtGP,EAAS,KAAK,GAAGO,EAAW,MAAM,0DAA0D,EAEhG,OAASG,EAAO,CACdX,EAAQ,wBAAyB,2BAA2BW,CAAK,EAAE,CACrE,CAIF,IAAMC,EAAUC,GAAiB,EAC7BC,EAAqB,GACzB,GAAIF,EAAQ,OAAS,EAAG,CACtBZ,EAAQ,wBAAyB,SAASY,EAAQ,MAAM,iBAAiB,EACzEE,EAAqB;AAAA;AAAA;AAAA;AAAA;AAAA,EACrB,QAAWC,KAAUH,EACnBE,GAAsB;AAAA,EAAKE,GAA0BD,EAAO,OAAQ,gCAAgC,CAAC,EAEzG,CAGA,IAAME,EAAY,gCAClB,GAAIV,GAAWU,CAAS,EACtB,GAAI,CAEF,IAAMT,EADoB,KAAK,MAAMC,GAAaQ,EAAW,OAAO,CAAC,EAC5C,OAAQP,GAAMA,EAAE,SAAW,aAAa,EAC7DF,EAAW,OAAS,IACtBR,EAAQ,wBAAyB,YAAYQ,EAAW,MAAM,mCAAmC,EACjGP,EAAS,KAAK,GAAGO,EAAW,MAAM,mCAAmC,EAEzE,OAASG,EAAO,CACdX,EAAQ,wBAAyB,+BAA+BW,CAAK,EAAE,CACzE,CAGF,GAAIV,EAAS,OAAS,GAAKa,EAAoB,CAC7C,IAAII,EAAU;AAAA;AAAA,EAAiCjB,EAAS,IAAIkB,GAAK,KAAKA,CAAC,EAAE,EAAE,KAAK;AAAA,CAAI,CAAC,GACrF,OAAIL,IACFI,GAAWJ,GAENM,GAAkBF,CAAO,CAClC,CAEA,OAAOG,EAAoB,CAC7B,CEpEA,OAAS,cAAAC,GAAY,gBAAAC,GAAc,iBAAAC,GAAe,aAAAC,OAAiB,UAanE,SAASC,IAAsB,CAC7B,MAAO,GAAGC,EAAc,CAAC,wBAC3B,CAEA,SAASC,IAAuB,CAC9B,IAAMC,EAAYC,EAAa,EAC/B,MAAO,GAAGJ,GAAY,CAAC,YAAYG,CAAS,OAC9C,CAEA,SAASE,IAAwB,CAC/B,MAAO,GAAGJ,EAAc,CAAC,oCAC3B,CAuOA,IAAMK,GAA6C,CACjD,mBAAoB,GACpB,qBAAsB,GACtB,wBAAyB,IACzB,kBAAmB,GACnB,gBAAiB,GACjB,WAAY,EACZ,iBAAkB,GACpB,EAKO,SAASC,IAAkC,CAChD,IAAMC,EAAaC,GAAc,EAEjC,GAAIC,GAAWF,CAAU,EACvB,GAAI,CACF,IAAMG,EAAOC,GAAaJ,EAAY,MAAM,EAC5C,MAAO,CAAE,GAAGF,GAAuB,GAAG,KAAK,MAAMK,CAAI,CAAE,CACzD,MAAQ,CAER,CAGF,OAAOL,EACT,CAyBO,SAASO,IAA0B,CACxC,IAAMC,EAAYC,GAAa,EAE/B,GAAI,CACF,GAAIC,GAAWF,CAAS,EAAG,CACzB,GAAM,CAAE,WAAAG,CAAW,EAAI,GAAQ,SAAS,EACxCA,EAAWH,CAAS,EACpBI,EAAQ,sBAAuB,uBAAuB,CACxD,CACF,MAAQ,CAER,CACF,CAKO,SAASC,IAAyB,CACvC,IAAMC,EAAMC,GAAY,EAExB,GAAKL,GAAWI,CAAG,EAEnB,GAAI,CACF,GAAM,CAAE,YAAAE,EAAa,SAAAC,EAAU,WAAAN,CAAW,EAAI,GAAQ,SAAS,EACzDO,EAAQF,EAAYF,CAAG,EAC1B,OAAQK,GAAcA,EAAE,WAAW,UAAU,GAAKA,EAAE,SAAS,OAAO,CAAC,EACrE,IAAKA,IAAe,CACnB,KAAMA,EACN,KAAM,GAAGL,CAAG,IAAIK,CAAC,GACjB,MAAOF,EAAS,GAAGH,CAAG,IAAIK,CAAC,EAAE,EAAE,MAAM,QAAQ,CAC/C,EAAE,EACD,KAAK,CAACC,EAAsBC,IAAyBA,EAAE,MAAQD,EAAE,KAAK,EAGzE,QAAWE,KAAQJ,EAAM,MAAM,CAAC,EAC9B,GAAI,CACFP,EAAWW,EAAK,IAAI,EACpBV,EAAQ,sBAAuB,yBAAyBU,EAAK,IAAI,EAAE,CACrE,MAAQ,CAER,CAEJ,MAAQ,CAER,CACF,CC/UA,IAAMC,GAAoB,IAAU,GAAK,GAAK,IAS9C,SAASC,GAAkBC,EAAoD,CAC7E,IAAMC,EAAS,KAAK,IAAI,EAAIH,GAEtBI,EAASF,EAAK,QAAQ,OAC5BA,EAAK,QAAUA,EAAK,QAAQ,OAAOG,GACd,IAAI,KAAKA,EAAE,SAAS,EAAE,QAAQ,EAC7BF,CACrB,EACD,IAAMG,EAAQJ,EAAK,QAAQ,OAEvBE,IAAWE,GACbC,EAAQ,sBAAuB,cAAcH,EAASE,CAAK,cAAc,CAE7E,CAKA,SAASE,GAAgBN,EAAsD,CAC7E,IAAMO,EAAQP,EAAK,MACbQ,EAAYD,EAAM,UACrB,MAAM,EAAG,CAAC,EACV,IAAIE,GAAK,GAAGA,EAAE,KAAK,IAAI,KAAK,MAAMA,EAAE,YAAc,GAAG,CAAC,IAAI,EAC1D,KAAK,IAAI,EAEZ,MAAO,wBAAwBF,EAAM,eAAe,gBAC/C,KAAK,MAAMA,EAAM,YAAc,GAAG,CAAC,mBACnCP,EAAK,YAAY,MAAM,oCACXQ,GAAa,MAAM,EACtC,CAeO,SAASE,EAAmBC,EAA+B,CAGhE,GAAI,CADWC,GAAW,EACd,kBAEV,OAAAC,GAAkB,EAClBC,GAAiB,EACVC,EAAoB,EAG7BV,EAAQ,sBAAuB,mDAAmD,EAElF,GAAI,CAEF,IAAML,EAAOgB,EAAoB,EAGjCC,GAAWjB,CAAI,EAGfD,GAAkBC,CAAI,EAGtBkB,EAAoBlB,CAAI,EAGxB,IAAMmB,EAAUb,GAAgBN,CAAI,EACpCK,EAAQ,sBAAuBc,CAAO,CAExC,OAASC,EAAK,CACZf,EAAQ,sBAAuB,qCAAqCe,CAAG,EAAE,CAC3E,CAGA,GAAI,CACFP,GAAkB,EAClBC,GAAiB,EACjBO,GAAgB,EAChBhB,EAAQ,sBAAuB,0BAA0B,CAC3D,OAASe,EAAK,CACZf,EAAQ,sBAAuB,+BAA+Be,CAAG,EAAE,CACrE,CAEA,OAAOL,EAAoB,CAC7B,CCvFA,IAAMO,GAAsB,CAC1B,CAAE,KAAM,oBAAqB,GAAIC,CAAgB,EACjD,CAAE,KAAM,mBAAoB,GAAIC,CAAgB,EAChD,CAAE,KAAM,qBAAsB,GAAIC,CAAiB,EACnD,CAAE,KAAM,sBAAuB,GAAIC,CAAmB,CACxD,EAYA,eAAsBC,GAAsBC,EAAuC,CAmBjF,IAAMC,GAjBU,MAAM,QAAQ,WAC5BC,GAAM,IAAI,MAAMC,GAAQ,CACtB,GAAI,CACF,IAAMC,EAASD,EAAK,GAAGH,CAAK,EAC5B,OAAII,aAAkB,SACpB,MAAMA,EAED,CAAE,KAAMD,EAAK,KAAM,OAAQ,SAAU,CAC9C,OAASE,EAAO,CACd,IAAMC,EAAUD,aAAiB,MAAQA,EAAM,QAAU,OAAOA,CAAK,EACrE,OAAAE,EAAQ,kBAAmB,GAAGJ,EAAK,IAAI,YAAYG,CAAO,EAAE,EACrD,CAAE,KAAMH,EAAK,KAAM,OAAQ,QAAS,QAAAG,CAAQ,CACrD,CACF,CAAC,CACH,GAGuB,OACrBE,GAAKA,EAAE,SAAW,YAAeA,EAAE,SAAW,aAAeA,EAAE,MAAM,SAAW,OAClF,EAEA,OAAIP,EAAO,OAAS,GAClBM,EAAQ,kBAAmB,GAAGN,EAAO,MAAM,IAAIC,GAAM,MAAM,mBAAmB,EAGzEO,EAAoB,CAC7B,CChDO,IAAMC,GAAgC,CAC3C,gCAAiCC,GACjC,yBAA0BC,EAC1B,wBAAyBC,GACzB,0BAA2BC,GAC3B,uBAAwBC,GACxB,0BAA2BC,EAC3B,gCAAiCC,GACjC,8BAA+BC,GAC/B,gCAAiCC,GACjC,wBAAyBC,EACzB,6BAA8BC,GAC9B,2BAA4BC,EAC5B,0BAA2BC,EAC7B,EAEO,SAASC,GAAQC,EAAkC,CACxD,OAAOf,GAAMe,CAAI,CACnB,CAEO,SAASC,IAAsB,CACpC,OAAO,OAAO,KAAKhB,EAAK,CAC1B",
  "names": ["isBashInput", "input", "isWriteInput", "isEditInput", "isReadInput", "appendFileSync", "existsSync", "statSync", "renameSync", "mkdirSync", "readSync", "execSync", "getLogDir", "getProjectDir", "getPluginRoot", "getSessionId", "getCachedBranch", "projectDir", "branch", "getLogLevel", "shouldLog", "level", "levels", "outputSilentSuccess", "outputSilentAllow", "outputBlock", "reason", "outputWithContext", "ctx", "outputPromptContext", "outputAllowWithContext", "systemMessage", "result", "outputError", "message", "outputWarning", "outputDeny", "LOG_ROTATION_MAX_SIZE", "PERMISSION_LOG_MAX_SIZE", "rotateLogFile", "logFile", "maxSize", "rotated", "ensureDir", "dir", "logHook", "hookName", "logDir", "timestamp", "logPermissionFeedback", "decision", "input", "toolName", "sessionId", "readHookInput", "chunks", "buf", "bytesRead", "fd", "getField", "path", "parts", "value", "part", "normalizeCommand", "command", "escapeRegex", "str", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "createHash", "MAX_RECORDS", "MIN_SAMPLES_FOR_ADJUSTMENT", "MAX_ADJUSTMENT", "ADJUSTMENT_STEP", "DECAY_FACTOR", "getCalibrationFile", "getProjectDir", "ensureDir", "dir", "existsSync", "mkdirSync", "loadCalibrationData", "file", "readFileSync", "logHook", "saveCalibrationData", "data", "writeFileSync", "err", "hashPrompt", "prompt", "createHash", "recordOutcome", "agent", "matchedKeywords", "confidence", "outcome", "durationMs", "feedback", "record", "getSessionId", "updateAdjustments", "updateStats", "isPositive", "isNegative", "adjustmentDelta", "keyword", "existing", "a", "applyDecay", "now", "dayMs", "adj", "age", "records", "successful", "avgConf", "sum", "r", "agentStats", "stat", "b", "getAdjustments", "getAgentSuccessRate", "agentRecords", "getCalibrationStats", "hasMinimalCalibrationData", "autoRememberContinuity", "input", "logHook", "projectId", "getProjectDir", "mem0Hint", "promptMsg", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "autoSaveContext", "input", "logHook", "sessionDir", "getProjectDir", "sessionState", "existsSync", "mkdirSync", "timestamp", "content", "readFileSync", "state", "updated", "writeFileSync", "error", "outputSilentSuccess", "existsSync", "readFileSync", "execSync", "getInstanceId", "projectDir", "idFile", "existsSync", "readFileSync", "runSqlite", "dbPath", "sql", "execSync", "cleanupInstance", "input", "getProjectDir", "logHook", "outputSilentSuccess", "instanceId", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "MAX_ACTIVE_DECISIONS", "archiveSession", "contextDir", "sessionFile", "existsSync", "logHook", "content", "readFileSync", "session", "sessionId", "archiveDir", "mkdirSync", "archiveFile", "archived", "writeFileSync", "error", "compressOldDecisions", "decisionsFile", "data", "decisions", "now", "toArchive", "writeCompactionManifest", "manifest", "manifestDir", "contextCompressor", "input", "getProjectDir", "outputSilentSuccess", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "execSync", "shouldRunTests", "projectDir", "lastRunFile", "existsSync", "result", "execSync", "logHook", "runTests", "logFile", "exitCode", "readFileSync", "cmd", "fullTestSuite", "input", "getProjectDir", "logDir", "mkdirSync", "outputSilentSuccess", "writeFileSync", "existsSync", "readFileSync", "unlinkSync", "rmdirSync", "execSync", "isGhAvailable", "execSync", "isGitHubRepo", "projectDir", "generateComment", "issueNum", "data", "sessionId", "commits", "commitsSection", "c", "tasksSection", "t", "postComment", "comment", "issueWorkSummary", "input", "logHook", "getProjectDir", "getSessionId", "sessionDir", "progressFile", "existsSync", "outputSilentSuccess", "progressJson", "readFileSync", "issues", "postedCount", "issueData", "unlinkSync", "rmdirSync", "existsSync", "readFileSync", "mkdirSync", "appendFileSync", "writeFileSync", "spawn", "countPendingDecisions", "decisionLog", "syncState", "existsSync", "decisionList", "readFileSync", "syncedIds", "d", "countPendingPatterns", "patternsLog", "content", "patterns", "line", "pending", "p", "getProjectId", "projectDir", "extractSessionInfo", "currentTask", "blockers", "nextSteps", "sessionState", "state", "blockersLog", "b", "mem0PreCompactionSync", "input", "logHook", "outputSilentSuccess", "getProjectDir", "pluginRoot", "getPluginRoot", "decisionCount", "patternCount", "pendingPatterns", "projectId", "logFile", "mkdirSync", "msgParts", "agentSet", "uniqueAgents", "summary", "summaryText", "sessionText", "scriptPath", "mem0ApiKey", "skillMsg", "timestamp", "appendFileSync", "sessionMetadata", "child", "spawn", "err", "errTimestamp", "code", "closeTimestamp", "stderrData", "chunk", "updated", "obj", "writeFileSync", "existsSync", "readFileSync", "unlinkSync", "execSync", "runSqlite", "dbPath", "sql", "execSync", "hasTable", "tableName", "stopHeartbeat", "instanceDir", "pidFile", "existsSync", "pid", "readFileSync", "logHook", "unlinkSync", "releaseLocks", "instanceId", "handleWorkClaims", "updateInstanceStatus", "broadcastShutdown", "messageId", "timestamp", "payload", "cleanupInstanceFiles", "filesToRemove", "file", "filePath", "multiInstanceCleanup", "input", "projectDir", "getProjectDir", "outputSilentSuccess", "idFile", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "readdirSync", "execSync", "runNpmAudit", "projectDir", "resultsDir", "existsSync", "logHook", "execSync", "error", "writeFileSync", "result", "runPipAudit", "parsed", "runSemgrep", "highSeverity", "runBandit", "runSecretScan", "secretPatterns", "secretsFound", "findings", "extensions", "scanDir", "dir", "entries", "readdirSync", "entry", "fullPath", "ext", "content", "readFileSync", "aggregateResults", "results", "totalCritical", "totalHigh", "scansCompleted", "f", "report", "securityScanAggregator", "input", "getProjectDir", "mkdirSync", "outputSilentSuccess", "existsSync", "mkdirSync", "readFileSync", "writeFileSync", "extractToolSequence", "metricsFile", "existsSync", "tools", "readFileSync", "a", "b", "tool", "getToolCount", "sum", "count", "detectWorkflowType", "detectDominantLanguage", "initWorkflowProfile", "profilePath", "updateWorkflowProfile", "workflowType", "dominantLang", "toolCount", "toolSequence", "profile", "timestamp", "seqSet", "mkdirSync", "writeFileSync", "initPatternsFile", "patternsPath", "mergePatterns", "projectDir", "queuePath", "logHook", "queue", "queueCount", "existing", "now", "allPatterns", "patternMap", "p", "mergedPatterns", "successes", "failures", "categories", "updated", "sessionPatterns", "input", "getProjectDir", "workflowProfile", "outputSilentSuccess", "existsSync", "readFileSync", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "getRegistryFile", "sessionId", "getSessionId", "getProjectDir", "ensureDir", "dir", "existsSync", "mkdirSync", "loadRegistry", "file", "readFileSync", "saveRegistry", "registry", "writeFileSync", "err", "logHook", "formatTaskDeleteForClaude", "taskId", "reason", "getOrphanedTasks", "registry", "loadRegistry", "failedIds", "t", "id", "cleanupOldTasks", "maxAgeMs", "registry", "loadRegistry", "cutoff", "t", "p", "saveRegistry", "taskCompletionCheck", "input", "logHook", "warnings", "projectDir", "getProjectDir", "sessionId", "getSessionId", "registryFile", "existsSync", "inProgress", "readFileSync", "t", "error", "orphans", "getOrphanedTasks", "orphanInstructions", "orphan", "formatTaskDeleteForClaude", "todosFile", "context", "w", "outputWithContext", "outputSilentSuccess", "existsSync", "readFileSync", "writeFileSync", "mkdirSync", "getStateDir", "getProjectDir", "getStateFile", "sessionId", "getSessionId", "getConfigFile", "DEFAULT_CONFIG_VALUES", "loadConfig", "configFile", "getConfigFile", "existsSync", "data", "readFileSync", "clearSessionState", "stateFile", "getStateFile", "existsSync", "unlinkSync", "logHook", "cleanupOldStates", "dir", "getStateDir", "readdirSync", "statSync", "files", "f", "a", "b", "file", "MAX_RECORD_AGE_MS", "cleanupOldRecords", "data", "cutoff", "before", "r", "after", "logHook", "generateSummary", "stats", "topAgents", "a", "calibrationPersist", "_input", "loadConfig", "clearSessionState", "cleanupOldStates", "outputSilentSuccess", "loadCalibrationData", "applyDecay", "saveCalibrationData", "summary", "err", "cleanupOldTasks", "HOOKS", "autoSaveContext", "sessionPatterns", "issueWorkSummary", "calibrationPersist", "unifiedStopDispatcher", "input", "errors", "HOOKS", "hook", "result", "error", "message", "logHook", "r", "outputSilentSuccess", "hooks", "autoRememberContinuity", "autoSaveContext", "cleanupInstance", "contextCompressor", "fullTestSuite", "issueWorkSummary", "mem0PreCompactionSync", "multiInstanceCleanup", "securityScanAggregator", "sessionPatterns", "taskCompletionCheck", "calibrationPersist", "unifiedStopDispatcher", "getHook", "name", "listHooks"]
}
